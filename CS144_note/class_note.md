### 1 简单了解网络

* 本小节,我们将简单了解一下,或者说见识一下网络究竟是什么,以及常见的思想

#### 1.1 网络通信的本质

* 在现代设计中,网络通信绝大多数都是以字节流进行通信的
* 网络通信本质上其实是多主机之间进行通信,每个主机拥有自己的独立IP地址(严格意义上不能这么形容,但是我们可以大概这么理解),通过这个独立的IP地址,每个接入网络的设备就可以通过这个IP访问其他设备

#### 1.2 通信方案举例

##### 1.2.1 `HTTP`

* 比方说网页页面的获取,就是使用`HTTP`协议进行的

* 假设我们需要获取一个网页,本质上就是向某个IP地址的主机发送一串字节,这个字节流全是以`ASCII`字符构成,所以这些内容完全是可读的

* 然后该主机会接收这串字节,并做检验,完全通过后就可以回传一串字节,表示允许获取内容,然后表示允许获取的字节后面将会紧接着网页页面文件的文本一并以字节流/二进制返回,写入到用户的浏览器或者说内存中,浏览器将这一大片文本(本质上是前端代码)渲染成实际的图形页面,这样用户就能访问网页了

##### 1.2.2 `BitTorrent`(`BT`协议)

* 这种通信方式也是一种常用的通信方式,迅雷本质上也是用这种方式,实现网络通信的
* 在`BitTorrent`协议中,本质上不存在严格意义上的"服务端",所有主机都作为客户端,更严格意义上说,所有主机都是客户端,也都是服务端
* 我们知道,从迅雷等等以`BitTorrent`协议为基础的软件中下载东西,都需要一个叫做磁力链接的东西,这个磁力链接会直接以`Hash`的方式直接和文件进行对应
* 然后我们会在互联网中寻找谁在线且有这个`Hash`,只要找到一个人有这个`Hash`,我们就会寻找该主机中,曾今还访问过哪些其他主机的`Hash`,这样,即便我们没有进行下载,我们也知道互联网中有谁还有这个文件(当然,前提是这些主机都在线)
* 接着就建立连接,开始在各个主机中下载文件
* 当然,这样有利也有弊,因为所有主机既是客户端又是服务端,那么意味着每台主机的上传量都不低
* 同时,并不是所有主机中,都完整存有这个文件,于是每个文件都会被切分成若干个`piece`,我们在与其他主机建立连接后,会交换主机拥有的`piece`信息
* 优先下载所有建立联系的主机中,最稀有的`piece`,尽可能保证该`piece`不会缺失
* 只要所有`piece`都存在,就一定能获取完整的文件,同时还能并行下载,提高下载速度

* 我们再说得更详细些
* 如果我们需要通过一个磁力链接/种子文件下载文件,这个链接/文件多数情况下是你通过`HTTP`下载网页或是下载文件得到的,而使用它,首先必须要经过一个有`tacker`的主机(一个主机可能会存放多个`tracker`),每个磁链链接或者说每个`Hash`会对应一个`tracker`,这个`tracker`不包含文件本身,所以说`tracker`其实不提供下载服务,但他能告诉用户,当前`tracker`中,有哪些用户在线
* 换句话说,这个磁力链接/种子文件告诉你的其实不是文件本身,也不是某个在线的用户地址,而是一个`tracker`的位置信息,通过`tracker`来找到其他用户
* 所以,宏观来看,这所有的用户共同构成了一个集群,而`tracker`扮演的角色仅仅只是记录用户在线情况,还有`Hash`对应哪部分文件,且帮助用户找资源,仅此而已
* 至于交换信息,则是集群中的用户该干的事情,他们使用双向的`byte`流进行数据交换,`tracker`本身不参与实际的数据交换

* 这也是为什么`BitTorrent`协议的核心思想是`P2P`(`peer to peer`)

* 值得注意的是,磁力链接其实仅记录`tracker`的位置,而种子文件则在此基础上,还会记录文件结构和`piece`情况等等
* 而用户第一次通过磁力链接或是种子文件与`tracker`建立联系时,也是通过`HTTP`协议进行沟通的,至于用户与用户之间沟通,则是用的`BitTorrent`的专有协议

* 所以,我们在使用诸如`qBittorrent`等工具的时候,可以通过一些渠道获取足够的`tracker`,以提升某个文件的下载速度和同时在线的用户量

##### 1.2.3 `Skype`独特的通信方式

* 在了解`skype`的通信机制之前,我们首先需要了解一个概念,即`NAT`
* `NAT`,本质上就是家里的路由器,路由器为你分配私有IP地址,且如果主机通过路由器接入互联网,那么外界的陌生主机无法主动获取私有主机的数据,因为会被`NAT`拦截
* 如果私有主机通过了`NAT`访问了外部设备,那么这个外部设备不再设为陌生设备,而是类似于进入`NAT`的白名单中,于是这个外部设备也能够获取私有主机的数据了,实现了既保证用户安全,又能实现数据交换的设想

* 但问题来了,这里我们要讨论一个问题,即"如果主机在`NAT`后,还能不能实现`P2P`?"
* 我们来看一个图
![[Pasted image 20250901171758.png]]

* 首先,`NAT`后的`client B`登录并上线`skype`,此时`client B`主动与`server`交流,于是`server`与`client B`允许交换资源
* 然后不在`NAT`后的`client A`也登录并上线`skype`,此时`client A`与`server`也可以交换资源
* 此时`client A`拨打电话给`client B`,因为`client B`在`NAT`后,所以`client A`不能直接给`client B`打电话,因为`NAT`认为`client A`是一个陌生设备
* 所以由已经不是陌生设备的`server`帮忙转发`call`给`client B`,此时`client B`会提示有人拨打电话给自己
* 如果`client B`接听了电话,此时`client B`会发送一个请求给`client A`,那么`client B`和`client A`的第一次有效沟通其实是由`client B`主动完成的
* 此时`client A`和`client B`就可以实现`P2P`式的数据交换了
* 所以你发现了吗,即便是`client B`在`NAT`后,也可以实现`P2P`式数据交换,根本解决思路来自于:由已经允许数据交换的`server`代理转发"其他设备希望数据交换的任务",从而让`NAT`后的设备主动访问这个其他设备
* 非常巧妙
* 我们称这种代理`server`为`Rendezvous Server`(会合服务器)

* 如果`client A`也在`NAT`后还可以实现`P2P`吗?
* 答案是不行,因为让`client B`发送请求给`client A`,它也收不到,会被拦截
* 所以在这种情况下,会退化成中继服务器转发操作,即`client`只与`server`交换数据,转发数据给其他`client`由`Relay Server`完成

#### 1.3 计网的四层结构以及"跳转"

* 在现代计算机网络的概念中,我们将整个网络分为四个层,当然,了解完这个小节之后,你仍然可能云里雾里,这是正常的,我们只是了解一下大纲而已

* 在此之前,我们首先需要了解一个概念
* 现代计算机网络中,绝大部分情况下,数据的传输绝对不是两点一线地传输的,它更像是一张网,数据在网上的节点不停跳转,直到到达目的地
* 就像是现代的物流网络一样,包裹的下一站不一定就是目的地,也可能是另一个中转站点,计算机中的网络也一样,下一跳不一定是目的地,但一定会接近目的地

![[Pasted image 20250901212352.png]]

* 具体分为以下四层

![[Pasted image 20250901211220.png]]

1. `Link`: 这一层也被称为链路层,这一层负责实际的传输任务,它不在乎究竟怎么传数据,仅负责传输功能本身
2. `Network`: 这一层也被称为网络层,这一层负责检测/指定传输目标,换句话说就是将`data`和目的地打包成一个`packet`,或者解包`packet`并分析目的地,换句话说,规定目的地的是`Network`,`Link`仅为`Network`提供发送服务,具体要发送到哪里取决于`Network`是怎样设定的
3. `Transport`: 也被称为传输层,这一层的设计初衷其实很简单,是为了弥补`Network`层的一些设计缺陷,计网功能的设计中,很多地方秉承着尽可能解耦的原则,换句话说,`Transport`层其实更像是`Network`层的插件(可以从这个角度看但不能严格这么理解),以实现更多复杂的功能,`Network`层其实不能保证传输一定不会失败,`Network`只能保证传输尽可能成功,如果拥塞非常严重,那么数据丢失也是板上钉钉的事情,所以需要`Transport`层做更多的功能,比方说检测到丢包就进行重传操作等等,这种重传操作的规范,我们称作`TCP`协议,比方说我们看视频的时候,为了保证每一个视频片段都能完整播放,就需要使用`TCP`协议保证`packet`能完整传输,当然也有不需要完整传输的情况,比方说视频电话,这种情况下,重传其实是没有任何意义的,因为视频电话讲究严格同步,不能延迟太高,所以不如直接让其丢失,反映在用户上则可能就是视频卡顿或者模糊等等,这种允许不保证`packet`完整传输的规范称为`UDP`协议
4. `Application`: 这一层也被称为应用层,用于规范数据如何交换,或者说作为数据交换的架构,比方说我们之前聊的`HTTP`协议和`Bittorrent`协议都在这一层,或者说这一层是用于规范数据交换策略的

* 值得一提的是,我们所说的路由器,也在这个传输网络中
* 路由器中只存在`Link`和`Network`这两层(这个地方其实不太准确,我们会进行补充),`Network`用于解包`packet`并计算下一跳的位置,而`Link`则负责传输,至于其他两层,路由器不需要也不在乎,因为路由器的本职工作是"路由",即找到下一跳位置并进行传输

![[Pasted image 20250901220412.png]]

* `Application`层负责宏观控制如何进行数据交换,然后向下,以指定的`Transport`协议进行数据传输,同样的,`Transport`也会向下指定`Network`进行对应的数据封装形成`packet`,并同样向下要求`Link`传输包到下一跳(事实上`Application`和`Transport`多半也是封装包的过程,只是封装的内容除了接收者,其他中继的硬件看见了也没有任何意义,如果中继硬件能够看到,反倒会使中继硬件维护/设计成本增加,也不够解耦,所以中继硬件被设计成非常傻瓜解耦的仅支持寻找地址+转发的模式)
* 所以说,对于数据的发送者而言,这四层其实就是一个层层打包的过程
* 而对于接收者而言,则就是层层解包的过程

* 在这里我们就有必要提一提"端到端"(end-to-end)和"跳到跳"(hop-to-hop)的概念了
* 端到端本质的服务对象其实是数据的发送者和接收者,即通信链路的两端,端到端思想本身不在乎中间经过了多少跳,而只在乎数据是否完整,数据符合什么应用层协议
* 跳到跳服务的对象则是所有作为跳的中继硬件,即通信链路属于中间的部分,该思想不在乎具体有没有丢失数据,也不在乎怎么处理数据,只负责定位+转发
* 所以说,本质上围绕端到端的是`Application`和`Transport`,而围绕跳到跳的则是`Network`和`Link`

* 我们视野拉开些看,目前我们所知道的协议

* `Application`: `HTTP`,`Bittorrent`等等
* `Transport`: `TCP`,`UDP`等等

* 我们知道,一个数据在`Network`被打包的时候会添加进目的地址(当然,其实还会添加发送地址),这个过程我们称为`IP`(Internet protocol)协议,`IP`协议不保证一定能不丢失数据,不保证顺序正确,也不保证数据不会重复,并且,整个`Network`就只有这一个协议,没有其他个性化的方案,因为仅使用这个方案就完全足够了,简单,统一,傻瓜,易用!

* 至于`Link`,也有很多其他的协议,比方说`4G`,`5G`,`WIFI`等等

* 所以宏观来看,整个自上而下的四层就像是一个漏斗一样,上下都可以走各式各样功能丰富的协议,但中间的`Network`一定只能走`IP`协议
* 这也是`IP`为什么这么重要的原因

#### 1.4 浅谈`IP`协议

* 在了解`IP`协议本身之前,我们先来谈谈`IP`协议的几个特点(虽然上一小节已经谈论过一部分了),以及这些特点为`IP`协议带来了什么

* 显著的是,`IP`协议是面向跳到跳的协议,`IP`协议只负责转发相关的内容,完全不负责数据中存储了什么,也不负责如何处理数据
* 并且,`IP`协议不可靠,`IP`不会保证一定能不丢失数据,不保证一定不会重复数据,他只能尽可能保证数据正确,除非阻塞严重,一旦拥塞严重,`IP`协议认为丢失该包也是正常操作,它不会做检查,也不会重发
* 同时也正因如此,我们常说路由器参照`IP`协议用于转发包,但实际上路由器也可能会因为设置错误而导致转发到不该转发的机器上(本质上,关于路由器如何知道该怎么转发这一点,路由器自身内部有一个转发表,用于判断应该往哪个方向转发,但这个表终归还是人类设计的,不可能不出错对吧),所以`IP`协议也不能保证转发一定成功

* 所以,如你所见,这个我们所称的"`IP`协议"似乎一点也不"协议",它一点也不复杂,甚至说有些懒惰,它啥也不检查,啥也不关心,只是自顾自地转发数据报,转发不了就丢弃
* 但正是因为足够简单,足够傻瓜,才能让其能变成全球通用的互联网协议,才能让其能遍布全球,轻而易举地变成"网络"
* 同时因为足够简单,所以对于网络中的中继硬件来说,其构造也会足够简单,也会更容易维护,更加容易进行升级,至于更多的功能,放到传输的两个端点去进行吧

* 当然,这里我们提到了数据报(datagram),我们需要对其做一些解释
* 我们在之前的小节中提到过,数据在发送之前,会经过四层打包,最开始在`application`,`datagram`仅由需要传输的数据构成,本质上就是一个字符串或者说二进制串,向`transport`打包后,字符串的头会被添加一串字符/数据,用于标示使用的什么`transport`协议,同样的,在`Network`层,也会添加一串字符/数据用于标示数据来源(`IPSA` "IP source address")和目的地(`IPDA` "IP destination address"),`Link`层也是如此,添加一串用于标示传输方式的字符/数据
* 我们称数据报自上而下四层打包,最后在链路层被打包为`frame`(帧)

* 同时,`IP`协议其实也不在乎`Link`层是怎样传输的,能传输就行,所以,CS144课程中提到,你甚至可以用信鸽作为传输介质hh

* 我们简单谈一谈`IP`协议的一些细节问题
* 我们知道,数据包在网络中传输,所以势必的,可能就会出现无限循环传输的情况,所以`IP`协议用一个字段描述还剩下多少次跳转机会,称为`TTL`(Time To Live),初始值为`64`/`128`/`...`,每次跳转就会`-1`,如果为`0`时还没有送达到,那么这个`data packet`(数据包)就会被丢弃
* 同时,`IP`协议也会尽可能保证`data packet`被正确路由,为此`IP`协议再次添加了一个字段用于简单校验
* `IP`协议现在有两种,一种是`32 bit`的`IPV4`,另一种是`128 bit`的`IPV6`,因为网络发展非常快,所以现在,`IPV4`地址已经快要用完了,目前更多人都在转移到`IPV6`
* 当然,`IP`协议也不是不可扩展功能的,它也留有了一定字段允许扩展其功能,只是几乎没有人会这么干就是了

#### 1.5 简单看看网络中的"包"

* 如你所见,在上一小节中我们提到了很多类似于"包"的专有名词,我觉得有必要了解一下这些名词的区别,否则看懂上一节其实会相对困难一点点

1. `message`: 报文,这是我们最原始的数据,是最初的还没有被网络部分做任何打包的数据,可能由字符流或者二进制流构成,对于目标主机的对应进程而言,它是完全可读的
2. `datagram`: 数据报,对于`Transport`和`Network`这两层而言,`datagram`是基本传输单位,当然我们只是叫他这个名字而已,实际运用还是很简单的,所以根据协议类型,我们可以在`Transport`中分为`UDP datagram`之类的(严格来说没有`TCP datagram`),然后向下被打包成`IP datagram`
3. `frame`: 帧,这是`Link`传输的基本单位,由`datagram`打包而成
4. `data packet`: 数据包,这其实是一个泛称,用来指所有在网络中传输的东西

#### 1.6 包是怎样传输的

* 我们知道,`data packet`会从某个主机发送给另一个主机,当然这个`data packet`可能多半是一个`frame`,因为`frame`是`Link`层的基本传输单位

* 当我们将其传输到一个路由中,路由会将其解包(本质上其实不算是解包,而是读某一段固定区间),然后路由会取出其中的`IPDA`,并查一个叫路由表的东西

* 这个表并不会记录完整的`IP`地址,而是记录一个相对模糊的方向,类似于这样

|类型|目标链路|
| :---: | :---: |
| default | Link0 |
| 类型1 | Link1 |
| 类型2 | Link2 |
| 类型3 | Link3 |
| 类型4 | Link4 |
| 类型5 | Link5 |

* 然后路由器会根据`IP`,找到最匹配的类型,然后发送给对应的下一跳或者对应的目标链路
* 但是,总会有完全不符合所有匹配类型的情况
* 此时,路由器会将其匹配到默认路由,也就是`default`,会将其发送给更大的网络以期望其能够正确匹配目标链路

* 我们就拿CS144课程的例子来说

* 一个`data packet`从学校机房中发出,他会经过机房的路由,路由中可能记录了学校内的部分其他路由,比方说餐厅的路由或者是图书馆的路由
* 如果我的目标就是学校内的其他设备,那我可以直接使用路由表中设定的类型,并下一跳到餐厅或者图书馆之类的路由,再由它们进行直接转达

* 但如果我的目标地址不是学校中的设备,且路由表中找不到任何能够匹配的类型,那么下一跳就会走默认路由,可能会发送给运营商的路由/数据中心的路由以期望在下一跳中能获取到更全面的路由表

#### 1.7 `TCP`协议在数据传输中的作用

* 在前面几个小节中,我们已经了解过了,`TCP`是一种可靠字节流的传输协议,底层的`IP`协议为其提供服务
* 你可能在学习或者一些科技向视频中有了解过,构建一个`TCP`传输"通道"之前,需要进行三次握手
* 就类似于这样：
	1. 客户端发送`SYN`(synchronize)标志位给服务器,表示我想和你建立连接
	2. 服务器发送`SYN`标志位和`ACK`(acknowledge)标志位回客户端,表示我也想和你建立连接,并且我已经准备好了
	3. 客户端发送`ACK`标志位给服务器,表示我也准备好了
* 至此,客户端和服务端就建立了可靠的`TCP`连接(当然,`TCP`的"可靠"不全部源自于三次握手,三次握手只是保障可靠的重要条件之一)

* 另一个问题,我们需要搞清楚"端口"(`port`)
* 我们已经知道,我们可以通过一个`IP`地址找到一个主机,但主机上可能跑着很多服务,我们怎么知道要访问哪个服务呢?
* 于是我们需要端口帮我们进行区分
* 同一个`IP`下,不同的`Transport`协议的不同端口可能对应着的不同的服务,这里我们仅拿`TCP`进行举例
* 比方说在`80`号端口,就是默认的`HTTP`服务的端口,又或者说我访问油管,其服务的默认端口可能是`443`这种

* 换句话说,我们需要获取到一个对应的服务,应该使用`IP`和`port`的组合,才能允许获取对应服务,至于具体是怎么获取到这个`IP`和`port`的,我们暂时不需要特别清楚,但可以提的是,这两个东西是通过解析域名得到的


#### 1.8 分组交换(Packet switching)

* 如你所见,如果我们直翻"Packet switching",那么应该叫包交换,但实际上这个词和中文语境下的"交换"没有啥关系,同时,"包"这个词在这里也有些出入
* 首先输出一个结论
	1. 在这个思想中,"包"是手段,"分组"是目的
	2. 在计算机网络的语境中,这里的"交换"其实指数据的转发

* 分组交换是现代计算机网络的设计思想
* 在更加早期的数据传输技术中,人们普遍是用电话线进行数据传输,换句话说就是打电话
* 电话线优势很明显,就是一旦建立连接,就几乎不存在数据中断,但缺点也很明显,这条电话线会被两个通信端点独占,其他任何人都没法共享这个电话线,那么,电话线这个资源就是不可分割的,即便你打电话的时候一句话都不说,电话线也会被你一直占用,这就导致资源的浪费,这种浪费在当今网络是非常致命的
* 试想一下,假设路由器的网络带宽也是一个不可分割资源,那么一旦你的室友在下载电影或者下载游戏,那么你的电脑就访问不到任何网络,只能等待你的室友断开网络连接
* 所以我们需要一种方式,能让信号的传输介质变得可共享
* 于是,分组交换思想就应运而生了
* 我们将数据切割成小块,然后打包,发送
* 于是,就会有一个现象,当你空闲的时候,路由就会停止向我转发数据包,如果此时有其他人需要路由转发数据包,那么路由就可以轻松帮助他转发
* 同时,如果两个人同时需要路由,那么路由器也会尽可能公平,他会尽可能保证公平地转发数据包,比方说当前`ms`可能向我转发数据包,那么下一`ms`,就会向共享路由的另一个人转发数据包,再下一次又是向我转发数据包
* 所以你发现了吗,路由此时在人类眼里看来,就像是一个可以分配的资源一样,或者说就像是蛋糕一样,可以被切分给所有共享者,这种将单一资源以概率或统计的方式在多个用户中共享的思想被称为"统计复用"(Statistic Multiplex)
* 我们换一个更加简单的场景,我们将路由器想象成`CPU`一样的资源,那么如果实现多线程,多线程会平分这个`CPU`资源,所以,核心思想其实一直都没有变,都是为了尽可能减少资源浪费,尽可能始终让设备一直高效运行,从而提高整体的运行效率
* 拆分成包的另一个优势是,我们在端点,不需要在乎组成一个文件的所有包,都是怎样在中途转发过来,换句话说,我们不需要在乎各个包在哪条路径上转发的,甚至不需要在乎包是否按顺序到达,只需要在端点解包并将打散的数据重排就行(重排是`Transport`层协议关心的事情)
* 并且,哪怕两端主机已经建立了TCP链接,实际数据包在中途的传输中,也不会按照既定线路,而可能会分发到多个路由,最后汇总到目标地址

* 来自维基百科:
![[Packet_Switching.gif]]

* 并且,`IP`协议就是严格按照该思想设计的
* 这使得每一跳的逻辑都很简单,路由也可以很简单,但却可以在底层这么简单的情况下构建成一个庞大,复杂,却又安全的网络

* 于是你会发现很有趣的事实,就是网络中可能会存在多个数据包并行地向你传输,就像是千万滴水汇聚的河流一样,我们称这种通信中的数据包集合为一种"流"(flow)


#### 1.9 分层(Layering)

* 那么,简单输出一个结论/事实,"分层思想"在现代程序设计亦或是计算机设计中,绝对有着不可或缺的作用,你能看到数不胜数的程序基于分层思想进行设计,我们简单打个比方

![[image-7.png]]

* 如你所见,这是`Linux`的系统层级
* 如果你深入了解过`Linux`,那么一定很熟悉这个东西
* 分层设计思想,对于开发者亦或是用户来说,都是极为重要的思想
* 我们聊聊CS144中的例子
* 假设我想邮寄一本书给朋友,那么势必会通过以下几个步骤:
	1. 将书打包并贴好发件地址和收件地址
	2. 将书投放进邮筒,书会在邮筒中等待邮递员
	3. 邮递员取到书,将书给到我附近的邮件中转站
	4. 中转站会通过各种方式发往朋友附近的邮件中转站
	5. 朋友附近的邮件中转站则会派邮递员向朋友住址的邮箱投递邮件
	6. 邮件会在邮箱中等待直到,朋友拿到邮件
	7. 朋友确认邮件无误后进行拆包
	8. 朋友获得这本书

* 于是你会发现一个很有意思的事情
* 我们在发邮件的过程中,所有组成部分只需要干好自己的活就行,我们无需关心底层究竟是怎样运作的

* 我们放在网络中,就是四层分层,放在`OS`中,就是图中展示的这六层

* 另一个有趣的事实是,一旦某个组件需要进行更新,那么其余所有的层其实都不需要变化,所以分层能让功能之间解耦
* 但同时也有缺点,你会发现如果有了分层,虽然对于用户而言,隐藏了绝大部分的底层信息,对用户而言降低了复杂性与学习成本,但实际上这样做会极大地损失灵活性,这里我们聊聊CS144课程的另一个例子

* 如果你使用过`Python`或者说`Java`之类的语言,你会发现很多接口都全部封装好了,所有的底层细节用户都不必了解,用户只需要知道怎么使用顶层接口就行了
* 但C语言则完全不一样,你甚至可以在`.c`文件中穿插汇编语言,因为比方说`Linux`的内核代码中,就会有部分代码是用汇编写的,因为C语言允许你更灵活地使用一些功能,这就使得C语言的灵活性非常高,理论上你可以用C语言手搓一个C++,亦或是Python,但相对的,很多东西都要手动造轮子,所有的底层细节都需要我去注意,这就导致开发效率低,学习成本直线上升
* 换句话说就是过渡的封装会降低复杂性,降低学习成本,但同时灵活性也会大大降低

* 我之前和一个很厉害的后端工程师聊过,他说做后端的最高境界,就是能管理好项目的所有后端服务以及做这些服务的人,他说服务和服务之间有着很复杂的依赖关系,这种将项目拆分成各个服务,并进行层层依赖,本质上也是分层思想的具体体现


#### 1.10 封装(Encapsulation)

* 在网络中,封装也是一种常见思想
* 这里我们可以说得简单一些,因为在学习语言的过程中,我们或多或少学习过该思想

* 我们知道,一个`massage`,或者说数据,会从`Application`层层封装到`Link`,就像是这样
![[Pasted image 20250905110009.png]]

* 因为有这样的封装,所以每到一个设备中,该设备就只需要访问自己该访问的部分,就像是路由器,它只需要访问在`Network`和`Link`封装的头和尾,其他关于`massage`或者是其他层的细节不需要知道,依旧是解耦的思想,简单傻瓜易维护,但是不灵活
![[Pasted image 20250905110022.png]]

* 这里我们可以了解一个技术,当然这个技术的名字我们肯定是知道的,但具体做了什么,我们曾经可能从来没有了解过,这里我们借用这个技术来感受一下封装的优势
* 假设我们想在外部网络访问公司内网的服务器,我们可以在公司放一个既接通了外部网络,又连接公司内网的中继服务器
* 我们发送一个这样的包给中继服务器
![[Pasted image 20250905111735.png]]

* 对于中继服务器而言,他不知道具体要转发什么内容,他只知道接收的这个`packet`的`massage`中,存放了一个完整的`packet`,他要将这个"内部"`packet`解析一下,然后转发到内部网络
* 这种技术叫做"虚拟专用网络隧道"(Virtual Private Network,也就是我们知道的`VPN`技术)

#### 1.11 `IPv4`地址

* 相信你一定在某些电子游戏中遇见过要用`IP`地址访问某个服务器的情况,当然,你肯定知道这个`IP`地址代表着某一台服务器,不同服务器的地址是不一样的,而本小节将会详细解读一下`IPv4`地址的构成

* `IPv4`地址是由`32`个`bit`构成的一串数字,我们看`IPv4`地址的时候要将其按`8bit`拆分成4各部分看,即`a.b.c.d`的形式
* 这意味着一个`IP`地址最大可以是`255.255.255.255`,也可以是`0.0.0.0`

* 比方说`192.168.0.100`,`25.66.10.1`,`172.45.0.111`,这些都是一个`IPv4`地址

* 另一个值得要注意的东西叫子网掩码,他和我们在用的`IP`有很大的联系
* 我们输入以下命令会返回一堆东西,我们可以慢慢看(为了服务器的安全,我还是得打一下码的)
```shell
oldking@iZwz9b2bj2gor4d8h3rlx0Z:~/CS144-2024-winter-backup$ ifconfig
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 1o.x.x.x  netmask 255.x.x.x  broadcast 1x.x.x.x
        inet6 x::x:x:x:x  prefixlen x  scopeid 0x20<link>
        ether x:x:x:x:x:x  txqueuelen 1000  (Ethernet)
        RX packets 35883058  bytes 6550064423 (6.5 GB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 34958182  bytes 8303867503 (8.3 GB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```

* 我这个阿里云服务器有两个地址,一个`IPv4`,一个`IPv6`
* 其中`1o.x.x.x`就是`IPv4`地址,`255.x.x.x`则是子网掩码

* 子网掩码这个东西怎么用?我来实例一下
* 假设我的子网掩码是`255.255.255.0`,假设我的设备的`IPv4`地址是`192.168.1.100`,我舍友的设备的`IPv4`地址是`192.168.1.201`
* 那么将我的设备`IPv4`地址按位与(`&`)上子网掩码得到`192.168.1.0`,我室友的`IPv4`地址做同样操作,也会得到`192.168.1.0`,那么证明我们两台设备的在同一个位置下,则表示我们两个设备可以不经过路由器,可以直接进行连接通信

* 事实上,路由器在做转发的时候,也是会参考子网掩码的,他会优先选择可直连的设备转发

* 关于`IP`分配问题
* 最初,`IPv4`地址的分配其实规定得很死,`IPv4`地址被分为三个类别,其中具体的值被划分成了`Network`部分和`Host`部分

* 该图截自CS144课程
![[Pasted image 20250908103039.png]]

* `Network`部分表示所处在多大的网段,或者说处于同一区域下的`Host`有多少
* `Host`部分则表示具体的主机
* 换句话说,就是`Network`位数少就意味着`Host`位数多,表示该网段下的设备很多
* 换句话说,子网掩码就是一个"边界",用于划分哪个部分是`Network`,哪个部分是`Host`

* 关于网段,我们可以这样理解
* 我们知道公网`IP`其实是非常有限的,所以我们做不到为所有人都分配一个公网`IP`,那么该怎么让人人都用上网络呢?
* 于是我们可以在公网下搞一个私有地址,比方说我的小区的某个路由的公网`IPv4`地址是`205.104.36.5`,其中`205.104.36`表示`Network`部分,`.5`表示`Host`部分
* 表示这个设备是`205.104.36.0`这个区间中的第`5`个设备
* 但实际我们为每栋用户分配的却不是这个公网`IP`,因为公网`IP`有限,所以我们为整个小区分配了一个私有地址,这个私有地址`192.168.0.0`(`Network`部分),只有小区自己内部可以使用
* 所有的用户与公网的交流,全部通过这个拥有公网`IP`的路由器代为转发

* 所以,在这个场景中,`205.104.36.0`是一个"公有网段",而`192.168.0.0`则是一个私有的网段

* 但你一定也发现了一个问题,如果小区的网段是`205.104.36.0`,但我的小区只有`5`个路由,这不就导致有两百多个`Host`被浪费掉了吗?答案是,是的,全部被浪费掉了!

* 所以,当人们发现`IPv4`开始不太够用的时候,提出了一个新的方案,叫做`CIDR`(无类别域间路由, Classless Inter-Domain Routing)

* 这个方案让`Network`的长度可以不受原来的三种类型约束,而是可以自定义其长度,我们回到小区的例子来看看他是怎样做的
* 原先,小区分配的是`205.104.36.0`,表示该网段下可以分配大约两百多个公网`IP`设备,但现在我们知道该小区只有`5`个公网用的路由,于是我可以改成分配成`205.104.36.160/27`,这意味着这个网段可以分配`2^(32-27) = 32`个公网`IPv4`地址,换句话说,这个`/27`表示前`27`位属于`Network`,后面的`5`位表示`Host`地址,同时`/27`也代表着子网掩码,那第`5`个路由的`IP`可以表示为`205.104.36.5/27`

* 那么最后,我们来规范一下,类似于`205.104.36.0`这种,他一般只是被称为一个`IPv4`地址,但语义不明确,而类似于`205.104.36.0/24`这种,称为`CIDR`网络前缀

#### 1.12 最长前缀匹配(Longest Prefix Match, `LPM`)

* 前段时间我们聊过路由转发`packet`需要查路由表,寻找最匹配的路径进行转发,这里我们就来补全这个空缺,来深入聊一聊路由是如何做最匹配路径的寻找的

* 我们先来看看路由表的具体构造如何

| dest | link |
| :---: | :---: |
| 0.0.0.0/0 (default) | 1 |
| 172.10.0.0/16 | 1 |
| 172.10.8.0/24 | 2 |
| 26.64.0.0/16 | 2 |
| 79.0.0.0/8 | 3 |
| 13.230.9.0/24 | 2 |
| 174.25.0.0/16 | 4 |

* 其中,所有的`0`其实都表示此处是一个通配符,拿到的目标`IP`地址和该表中的地址后,依照子网掩码位数,比较最前位就可以找到最匹配的路径,如果没有最匹配的,就会走默认路由

* 我们举个例子,假设现在路由器拿到了一个`172.10.8.2`的包并需要将其转发
* 其中:
	1. 第一个地址不取任何数字,因为他是默认路由,一定是和需要转发的地址匹配的,然后做好记录,表示这个路径匹配过了
	2. 第二个地址取前`16`位和需要转发地址的前`16`位进行比较,发现也符合,那也把这个路径记录下来
	3. 第三个地址取前`24`位和需要转发地址的前`24`位进行比较,发现也符合,那也把这个路径记录下来
	4. 剩下的如法炮制...

* 于是最后发现,所有记录的`3`个匹配项中,`172.10.8.0/24`这个地址存在`24`位与需转发地址匹配,那么就会走`link 2`进行转发

#### 1.13 地址解析协议(Address Resolution Protocol, `ARP`)

* 在了解`ARP`之前,我们首先还需要了解一些前置知识

* 首先,`IP`地址是一个`Network`层地址,但实际传输却是在`Link`层传输,而`Link`层其实无权访问`Network`层的任何内容,所以势必的,`Link`层也需要有自己的"地址",这个地址我们称为`MAC`地址
* 另一个问题,公网`IP`地址其实不是物理意义上存在的,而是"受分配的",是虚拟的一个地址(只有某些互联网服务才可以申请某个固定的公网`IP`,造成这种受分配情况的原因还是因为`IPv4`地址太过于稀缺了),而`MAC`地址却是一个物理意义上存在的地址,是网卡出厂的时候就烧录进网卡的,所以理论上这个地址才是全球唯一的网卡地址
* 所以实际上,我们会将`datagram`在`Link`层中打包成帧,然后实际在`Link`层中转发的都是帧

* 另一个有意思的点是,一个路由器可以有多个网卡,并且可以有多个`IP`地址
* 首先我们要知道,因为路由器本质是在做转发操作,而一个网卡只能关联他所在的网段,所以如果我要从一个网段发送内容到路由器关联的另一个网段,就必须要用两个网卡

* 那么,以上是前置知识,现在我们将会举一个来自CS144的例子

1. A: 一台主机,`IP`地址为`192.168.10.100`,`mac`地址(用于辨认哪个网卡,属于链路层地址)为`AA:AA:AA:AA:AA:AA`
2. B: 一台主机,`IP`地址为`172.100.10.100`,`mac`地址(用于辨认哪个网卡,属于链路层地址)为`BB:BB:BB:BB:BB:BB` 
3. C: 一个网关,拥有两张网卡
	1. 一张网卡连接着A,该网卡的`IP`地址为`192.168.10.101`,mac地址为`CC:CC:CC:CC:CC:CC`
	2. 另一张网卡连着B,该网卡的地址为`172.100.10.101`,mac地址为`DD:DD:DD:DD:DD:DD`
	
* 那么,如果A需要发包给B,首先会参考子网掩码(A的子网掩码是`255.255.255.0`),但显然这里B不会和A在同一个网段下,那么此时A开始封装`packet`,源IP地址是A自己的,源`mac`地址也是A自己的,但目标IP地址是B的`IP`地址,目标`mac`地址是网关的`CC:CC:CC:CC:CC:CC` 发送帧给网关之后,网关会解包,并封装自己的`mac`地址(`DD:DD:DD:DD:DD:DD`)作为源`mac`地址放进帧的链路层中,还会封装B的`mac`地址作为目标`mac`地址放进帧的链路层中

* 这里这个网关其实就是路由啦

* 那么此时有一个很重要的问题出现了,A怎么知道网关的`mac`地址?当然不知道!所以我们需要`ARP`协议帮助我们获取网关的`mac`地址
* 此时,A会在当前网段中广播它所有能广播到的设备,向这些设备提问:"谁是`192.168.10.101`?告诉我你的`mac`地址!",在广播的时候,他会顺便把自己的`mac`地址附带进去,方便接收到的设备回传,那么C收到这个广播之后就会发回(非广播形式,或者说"私聊")它的`mac`地址给A,此时A就可以正确封装`packet`了,然后发送到C手上,然后C也做同样的事情获取B的`mac`地址,然后发包给B

* 注意,这里是在广播所有能广播到的当前网段设备,这意味着?!
* 我们是不是可以欺骗这个A,让A以为我们是一个路由器,而实际上我们是另外一台主机?!
* 当然可以!
* A中将会维护一张缓存表,映射C的`IP`和`mac`地址,只要在还没有实现映射的时候,抢在网关应答之前应答A,并把自己的`mac`地址当作一个网关`mac`地址发回给A,那么他就会把这个伪装的网关真的当作一个路由发包
* 恭喜你学会了`ARP`欺骗

* 现在我们来聊一聊一个`ARP`包的组成
* 如你所见,这个包由以下几个部分组成(虽然这个图看起来很立体,不说实际传输的时候却是一个连续的字符串)
![[Pasted image 20250909120836.png]]

* 解释:
	1. `Hardware`: 表示链路层协议类型
	2. `Protocol`: 表示网络层协议类型
	3. `Hardware Length`: 表示链路层协议的长度
	4. `Protocol Length`: 表示网络层协议的类型
	5. `Opcode`: 设置代码,表示该包的属性,是请求(`1`),还是发回(`2`)
	6. `Src Hardware Address`: 发送方链路层地址 
	7. `Src Protocol Address`: 发送方网络层地址
	8. `Dst Hardware Address`: 接收方链路层地址
	9. `Dst Protocol Address`: 接收方网络层地址

* 回到例子
* A请求的时候应该是这样的:
	1. `Hardware`: `0x 00 01` (表示以太网协议)
	2. `Protocol`: `0x 08 00` (表示`IP`协议)
	3. `Hardware Length`: `0x 06` (表示链路层协议有`6 Bytes`)
	4. `Protocol Length`: `0x 04` (表示网络层协议有`4 Bytes`)
	5. `Opcode`: `0x 01` (表示请求)
	6. `Src Hardware Address`: `0x AA AA AA AA AA AA` (源链路层地址)
	7. `Src Protocol Address`: `0x C0 A8 0A 64` (源网络层地址)
	8. `Dst Hardware Address`: `0x 00 00 00 00 00 00` (目标链路层地址,因为这里是请求地址,所以地址还不知道,所以填空)
	9. `Dst Protocol Address`: `0x C0 A8 0A 65` (目标网络层地址)

* 实际发送的时候,还会封装成一个以太网帧进行发送,因为广播行为是封装在以太网帧中的,所以实际发送的时候是这样

* 我们还得简单看看以太网帧是怎样封装的
![[Pasted image 20250909124206.png]]

* 所以实际发包的时候是这样的:
	1. `Dst Mac Address`: `0x FF FF FF FF FF FF` (全`F`表示广播)
	2. `Src Mac Address`: `0x AA AA AA AA AA AA`
	3. `Ether Type`: `0x 08 06` (表示发的是`ARP`协议的包)
	4. `Payload`: `...`(`48 bytes`,这里面放的是`ARP`协议的包)
	5. `FCS`: 一个校验码,根据算法生成的,用于检错,我们现阶段不用太在乎里面装的什么 

* C发回以太网帧的时候应该是这样的:
	1. `Dst Mac Address`: `0x AA AA AA AA AA AA`
	2. `Src Mac Address`: `0x CC CC CC CC CC CC`
	3. `Ether Type`: `0x 08 06`
	4. `Payload`:
		1. `Hardware`: `0x 00 01` (表示以太网协议)
		2. `Protocol`: `0x 08 00` (表示`IP`协议)
		3. `Hardware Length`: `0x 06` (表示链路层协议有`6 Bytes`)
		4. `Protocol Length`: `0x 04` (表示网络层协议有`4 Bytes`)
		5. `Opcode`: `0x 02` (表示发回)
		6. `Src Hardware Address`: `0x CC CC CC CC CC CC` (源链路层地址)
		7. `Src Protocol Address`: `0x C0 A8 0A 65` (源网络层地址)
		8. `Dst Hardware Address`: `0x AA AA AA AA AA AA` (目标链路层地址,因为这里是请求地址,所以地址还不知道,所以填空)
		9. `Dst Protocol Address`: `0x C0 A8 0A 64` (目标网络层地址)
	5. `FCS`: 现阶段不在乎 


### 2 `Transport`层

* 在本小节中,我们将会了解`Transport`层中各个协议的作用以及结构

#### 2.1 `TCP`

##### 2.1.1 `TCP`协议的作用

* 在前面的章节中,我们提到过`TCP`协议为应用层服务,绝大多数`Application`层协议都需要`TCP`协议的服务,因为其能够在一定程度上保证数据一定送达,不会丢失数据,也不会顺序错乱

* 同时,网络的设计使得`TCP`是端到端的,那么意味着没人会在某一跳读你`TCP`相关的内容,`TCP`只关心发送方和目标主机的交流,不关心中间是如何跳的

* 同时正因为`TCP`协议是端到端的,所以它必须保证传输的数据一定是有序的,所以所有以`TCP`发送的,分散的,乱序的包,都会再经过一次目标主机的`TCP`协议,他负责将这些乱数据重组成`Application`层读得懂的内容

* 同时,本质上`TCP`不管在发送方和接收方来看,都是一个字节流,所以本质上在发送方,就是分割字节流再打包发送,而在接收方,本质就是解包后重组字节流,这也是为什么我们可以像读写文件一样读写一个`TCP Socket`,因为它和内存里的字节流没啥区别,只是多了几个校验,重传,重组等等几个步骤,而这些步骤都是`TCP`需要干的


##### 2.1.2 `TCP`协议的封装

* 和所有`Transport`协议一样,`TCP`协议需要封装来自`Application`的数据,然后形成一个`TCP Segment`,即`TCP`段
* 然后交由`Network`封装`IP Datagram`
* 最后交由`Link`封装对应协议的`Frame`

##### 2.1.3 建立连接与断开连接

* 建立连接的过程我们之前已经了解过了,即三次握手,这里我们回顾一下

* 如果A要和B建立连接:
	1. 首先A会发送一个`SYN`给B表示请求同步
	2. 然后B会发回`ACK`给A表示同意同步,并附带`SYN`给A表示请求同步
	3. 然后A会发回`ACK`给A表示同意同步

* 至此,两台主机已经建立了可靠的`TCP`连接了

* 那么如何断开连接呢?

* 如果A请求和B断开连接:
	1. 首先A会发送一个`FIN`给B表示`finish`,表示A要准备断开链接了
	2. 此时B如果还有数据没有传输完毕,就会可能会发回一部分数据,末尾会携带一个`ACK`,表示我同意断开连接,但是我的数据还没有传输完毕,要等待一会儿
	3. 当B如果完成传输了,那么就会发回一个`FIN`给A,表示我也完事儿了,可以断开连接了
	4. A会发回一个`ACK`给B表示同意断开连接

* 至此,这两台主机就断开连接了
* 这就是我们所说的"四次挥手"

* 那么好,如果B在进行第二次挥手的时候,恶意地不发回`ACK`,此时怎么办,难道A会无限地等待下去吗?
* 当然不会,`TCP`设计了超时机制,如果B不发回`ACK`,A就会持续地发送`FIN`,到达一定次数之后,如果B还是不做回应,那么A就会强制与B断开连接

##### 2.1.4 尽可能保证数据正确送达

* 注意,虽然`TCP`协议能在`IP`协议的基础上"确保"能够送达,但这种"确保"不是一定会送达,比方说难道网络断开连接了也能送达吗,显然不可能
* 所以`TCP`的"确保"送达更像是一种兜底机制,如果连`TCP`都没法送达了,那估计换其他的协议估计也不太行
* 所以换句话说,没人会愿意自己的数据不被送达,所以在`IP`协议这里就已经在尽最大可能让数据送达了,至于`TCP`更像是一种添加了重排的兜底机制,`IP`协议尽最大可能送达,但自己却不会做绝大多数的完整性检查等等,所以`TCP`帮助数据在两端做完整性检查,做重发,做重排,以保证传输过程中不会因为一些非人为错误导致数据混乱或者发送失败,但归根结底底层还是用的`IP`协议,所以连`TCP`其实也是没法保证"一定"能够送达的

* 现在我们来谈谈`TCP`是怎样做到尽可能保证数据正确送达的:
	1. "应答机制":当一个`packet`被接收之后,目标主机应该发回一个`ACK`来告诉发送方已经正确接收了,不需要重发
	2. "校验和"(checknum):它是一串数字,用于送达之后校验数据是否正确,确保不会因为某一跳导致数据缺失了一部分
	3. "序列号"(Sequence number):之前我们提到过,本质上送达的是字节流,所以本质上就是个数组,所以我们需要记录每个数据段在这个数组中最开始的下标,以方便我们送达之后恢复成字节流,同时,如果某个部分丢失,目标主机也能够知道它丢失的是哪个部分
	4. "流量控制"(Flow-control):如果发送方比接收方发包的速度快非常多,那么接收方的缓冲区可能会在一瞬间被塞满,这时候发送方如果接着发送就可能会导致数据没法写进缓冲区,此时就需要通过同步接收方的缓冲区,以保证不把缓冲区塞满的情况

##### 2.1.5 一个`TCP Header`的结构

* 一个`TCP Header`包含如图的内容
![[Pasted image 20250910164055.png]]

* 以下来详细做些解释:
	1. `Src Port`:发送方端口号,用于指代发送方的某个进程/服务
	2. `Dst Port`:接收方端口号,用于指代接收方的某个进程/服务
	3. `Sequence`:序列号,我们会在后面详细解释这个东西
	4. `Acknowledge Sequence`:确认号,我们一样会在后面详细解释这个东西
	5. `Head Length`:表示该`TCP Header`的大小
	6. `RSVD`:保留位,一般不使用
	7. `Flag`:
		1. `CWR`:用于`ECN`机制,暂时不用了解
		2. `ECE`:同样用于`ECN`机制,暂时不用了解
		3. `URG`:表示紧急提示,为`1`则会处理`Urgent Pointer`部分现在一般不建议使用
		4. `ACK`:表示确认
		5. `PSH`:建议接收方立即响应送达信息,比方说送达的是延迟敏感的数据,那么就几乎不会走缓冲区,而是立刻应答
		6. `RST`:`Reset`,立刻重置连接,一般用在不可逆的严重错误中
		7. `SYN`:表示请求,用于建立连接
		8. `FIN`:表示结束连接请求
	8. `Window Size`:窗口大小,这个就是用于告诉发送方剩余的缓冲区大小的,防止数据堆积
	9. `Checksum`:校验和
	10. `Urgent Pointer`:紧急指针,几乎不用
	11. `TCP Options`:这是一个可选项,可以自定义`TCP`的一些功能,不过几乎没人会自定义功能
	12. `TCP Data`:`TCP`数据

##### 2.1.6 `Sequence`和`Acknowledge Sequence`

* 本小节会比较复杂,个人觉得`TCP`协议中最复杂的也是这个了

* 首先我们得带入一个场景
* 假设现在有A和B两台主机,A已经和B建立了`TCP`连接,那么A向B发送了一个包
* 现在这个包在传输途中,遇到了拥塞或者其他什么的问题,总之就是包没法正确递达
* 按理来说,A发送了一个包,B会应答这个包已经到了,A应该会收到一个来自B的应答信息,但这里没有
* 于是A认为`TCP`连接已经断开,于是开始和B做重连(重连这个步骤其实是`Application`层做的,`TCP`本身不会做重连)
* 那么很顺利,重连很快完成了,A重新发送了一个包给B,B也成功拿到了这个包
* 但很不巧,原来那个因为拥塞而没有递达的包,现在突然不拥塞了,于是这个包传递给了B
* B如何判断这个包该不该接收?B只看四个东西:
	1. 源`IP`
	2. 源`port`
	3. 目的`IP`
	4. 目的`port`

* 之后我们聊到`TCP`的封装的时候会详细聊一下这个
* 那么很显然,这个本应该丢弃的包传递到了B手上,这四个东西都能对的上,那么B理应接受这个包,一旦这个包被接受了,那么就会变成一个未定义行为

* 所以现在,我们需要一个标识符用来区分一个包是旧包还是新包
* 所以我们现在可以搞一个规定,规定发送方必须发送一个类似于随机匹配码的东西
* 当A和B三次握手连接的过程中,双方都会随机生成匹配码,且双方必须确认各自的随机匹配码
* 每次发包的时候都必须携带这个匹配码才可以发包

* 这个匹配码就是一个`ISN`(初始序列号),初始状态下是随机分配的
* 那么好,此时以后就几乎不会再误收包了

* 那么`Sequence`和`Acknowledge Sequence`还解决了另一个问题,即包重排问题
* 那么,`ISN`是随机的,但只在他身上附加随机的属性未免有点太浪费了,于是我们想到了一个很好的解决办法
* 一个随机数本身具有随机属性,那么一个随机数加上一个固定的数,也具有随机性
* 所以,我们可以规定一个`ISN`,但同时当作我们传输可靠数据的虚拟的起点位置,每做完一次传输,其加上传输的可靠数据的大小

* 所以,`Sequence`最开始在三次握手阶段会初始化并交换`ISN`,这个`ISN`作为特殊的`Sequence`发送给对方

* 我们可以想象成这是一个虚拟的队列,这个队列中的每一个字节都是可靠的,且队列中的每一个包都附带了编号
* 但这个队列实际不存在,我们仅仅只是给包进行了编号而已

* 同时,因为每个有效的数据都需要可靠传输,那么三次握手的`SYN`本质上也是有效数据,需要尽可能保障不被丢失,所以每次发送一个`SYN`都会让`Sequence``+1`
* 那么为什么`ACK`包不需要让`Sequence``+1`?因为`ACK`只是一个应答信息,就像是我询问你,你给个`OK`一样,其实是不包含有效信息的,如果迟迟收不到应答信息,那么发送方会直接尝试重新链接,所以完全不需要在`ACK`包的`Sequence``+1`

* 所以实际传输中,`Sequence`和`Acknowledge Sequence`该怎么设置呢?我们实际看个例子:
	1. 三次握手阶段:
		1. A发送带有以下信息的包给B:
			1. `Sequence`:设置为属于A的随机的`ISN`,我们假设设为了`5000`,表示我的`ISN`从`5000`开始
			2. `Acknowledge Sequence`:为空
			3. `SYN`:`1`
			4. `ACK`:`0`
		2. B接收到之后发送带有一下信息的包给B:
			1. `Sequence`:设置为属于B的随机的`ISN`,我们假设设为了`2300`,表示我的`ISN`从`2300`开始
			2. `Acknowledge Sequence`:`5001`,表示应答,你是从`5001`发包给我,期待你的`5001`
			3. `SYN`:`1`
			4. `ACK`:`1`
		3. A收到来自B的包之后发送一个应答信息给B
			1. `Sequence`:`5001`,我这里从`5001`发送给你(或者说准备从`5001`发东西给你了)
			2. `Acknowledge Sequence`:`2301`,确认了,你是从`2301`发包给我,期待你的`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		4. 至此成功建立`TCP`连接
	2. 实际传输数据阶段:
		1. A发送一个`200 Bytes`的包给B:
			1. `Sequence`:`5001`,我这个包在我这里是从`5001`开始编号
			2. `Acknowledge Sequence`:`2301`,期待你的`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		2. B应答A:
			1. `Sequence`:`2301`,我这个包从`2301`开始(当然,回应的包本身不包含有效数据,所以不会`+1`)
			2. `Acknowledge Sequence`:`5201`,我收到了你从`5001`~`5200`的内容,期待你的`5201`
			3. `SYN`:`0`
			4. `ACK`:`1`
		3. 至此完成一次发包
	3. 四次挥手阶段
		1. A发送关闭请求给B:
			1. `Sequence`:`5201`,我这个包从`5201`开始
			2. `Acknowledge Sequence`:`2301`,期待你的`2301`
			3. `FIN`:`1`
			4. `ACK`:`1`
		2. B回应A:
			1. `Sequence`:`2301`,表示我这个包从`2301`开始(回应不占空间,我还可以从`2301`补充内容给你)
			2. `Acknowledge Sequence`:`5202`,收到你的`5201`~`5201`了,期待你的`5202`
			3. `FIN`:`0`
			4. `ACK`:`1`
		3. B没有东西要补充给A了,所以也发送请求给A:
			1. `Sequence`:`2301`,我这个包从`2301`开始
			2. `Acknowledge Sequence`:`5202`,期待你的`5202`
			3. `FIN`:`1`
			4. `ACK`:`1`
		4. A应答B
			1. `Sequence`:`5202`,我这个包从`5202`开始(应答信息没有有效数据不占空间)
			2. `Acknowledge Sequence`:`2302`,期待你的`2302`
			3. `FIN`:`0`
			4. `ACK`:`1`
		5. 至此连接关闭

* 所以,我们简单来说:
	1. `Sequence`:我这个包从我的哪里起始
	2. `Acknowledge Sequence`:期待你从哪里开始的包

* 至于`Sequence`的重排功能,我们可以理解为一个包到达之后,其实不会立刻被放进字节流中,而是需要先放进缓冲区中,`TCP`会检查顺序,我们举个例子,假设现在A和B已经建立连接了,A的`ISN`是`5000`从`5001`发包,B的`ISN`是`2300`,从`2301`开始发包:
	1. 第一次A给B发包:
		1. A发送`200 Bytes`的包给B:
			1. `Sequence`:`5001`
			2. `Acknowledge Sequence`:`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		2. 但这个包因为一些原因没有送达
	1. 第二次A给B发包:
		1. A发送`400 Bytes`的包给B:
			1. `Sequence`:`5201`
			2. `Acknowledge Sequence`:`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		2. B对`5201`做检查,发现`5001`~`5200`这一段缺失了,所以暂时先把`5201`放进缓冲区,不放进字节流
		3. B回应A(这个步骤可能会重复1~3次甚至更多,意思是反复询问):
			1. `Sequence`:`2301`
			2. `Acknowledge Sequence`:`5001`,意思是,布什戈门,你的`5001`咋没了?
			3. `SYN`:`0`
			4. `ACK`:`1`
	2. B收到了A第一次延迟的包:
		1. B会一次性回应A的两次发包:
			1. `Sequence`:`2301`
			2. `Acknowledge Sequence`:`5601`,我收到你的`5201`了,期待你的`5601`
			3. `SYN`:`0`
			4. `ACK`:`1`

* 所以你发现了吗,`Sequence`用于表示当前包的起始字节的编号,然后接收端会根据这个包的有效数据大小和起始字节编号计算出我接下来期待哪个字节


##### 2.1.7 `TCP`的封装再谈

* 我们知道,四层结构是层层封装的,在`Network`层只存在一个`IP`协议,这意味着这个`TCP`段一定会封装进一个`IP`数据报中

![[Pasted image 20250911180315.png]]

* 一般一个机器是否会获取一个`TCP/IP`的包,取决于这个包中的这四个东西,其中`Src Port`和`Dst Port`来自于`TCP Header`,而`Src IP`和`Dst IP`来自于`IP Header`,当然准确来说需要取决于五个东西,最后一个是`Protocol ID`,用于检查这个`IP`数据报中存放的是什么类型的`Transport`层协议


#### 2.2 `UDP`

* 前面我们有简单提到过,`UDP`是一个不可靠传输协议,在本章节我们会详细了解一下

* 不过输出一个结论,`UDP`有点像是一个极其精简版的`TCP`,阉割了`TCP`中90%的机制,仅用于区分应该传输到目标机器的那个应用程序,其他的功能一概没有

##### 2.2.1  一个`UDP Header`的结构

* 可以先看一下这个图
![[Pasted image 20250921172153.png]]

* 没错,`UDP`就是这么简单,除了用于区分应该传输到目标主机的进程,几乎其他功能,我们现在来详细看一下:
	1. `Src Port`: 源端口号,可以告诉目标进程如果要回复的话应该往哪个进程回复
	2. `Dst Port`: 目标端口号,用于区分应该传输到目标主机的哪个进程
	3. `Checksum`: 检验和,用于校验数据是否损坏,这个在`IPv4`是可选的,但在`IPv6`是必须有的
	4. `Length`: 表示`UDP Header`+`UDP Data`的长度
	
* 为什么`UDP`要有`Checksum`?
* 主要是因为数据错误比错误丢失更可怕,数据错误可能会造成一些不可预见的问题,因为你都不知道递达的数据究竟会是什么样的,与其这样,不如直接丢弃数据,所以`UDP`还是有`Checksum`,目的是保证递达的数据要么绝对正确并接收,要么不正确并丢弃

* 另外,为什么`IPv4`可以没有`Checksum`,而`IPv6`一定要有`Checksum`呢?
* 因为`IPv4`协议自身就会校验自己的`IP Header`,而`IPv6`完全不会校验自己的`IP Header`,需要依赖`Transport`层的协议校验`IPv6`协议的`Header`

##### 2.2.2 多路分解协议

* 所以你能看到,`UDP`几乎只有"分辨要传给哪个端口"的功能,以及极其轻量化的校验机制
* 所以这个协议被理解成在目标主机用于"多进程划分数据"的协议也是可以的

##### 2.2.3 总结

* 所以,对于`UDP`来说,有以下几个性质:
	1. 不保证可靠传输,或者说可靠性没有`TCP`那么强
	2. 没有重排机制,所以如果一定要重排的话,得在`Application`层自己搞协议重排
	3. 没有重传通知机制,同样的,重传也得在`Application`层自己搞协议重传
	4. 没有建立连接机制,没有确认机制

* 那么那些地方用到了`UDP`呢,比方说`DNS`解析就用到了`UDP`,主要是轻量,相应快速,没有成功就在`Application`搞重传机制


#### 2.3 `ICMP`

* 这是一个`Network`层协议,用于反馈错误,全称是"Internet Control Message Protocol","互联网控制消息协议"

* 比方说,我试图在一个内部网络访问外部网络,于是主机会发包给路由器,但路由器因为没连接到外部网络,转发表里任何一个目标地址都不匹配,那么这个包就只能丢失,于是路由器会通过`ICMP`协议通知用户到底发生了什么故障导致传输失败

##### 2.3.1 一个`ICMP`消息的一生

* 我们回到例子,当一个路由器发现一个`IP`协议的包没法转发时,他会把这个`IP`的`Header`取出,并且顺带把`IP Data`的前面`8 Bytes`也取出,作为一个`ICMP`协议的`Data`
* 同时`ICMP`会在自己的`Header`中塞入`Type`和`Code`这两个东西,其中`Type`用于表示发生了什么类型的错误,`Code`表示在`Type`这个大类型之下具体发生了什么问题
* 然后将这个`ICMP`包封装进`IP`然后发回给源主机

* 大概就是这张图表示的这样
![[Pasted image 20250921190323.png]]

* 如你所见,`ICMP`会截取`IP Data`的原因在于,它可以通过这种方式,告诉源主机应该把这个错误信息发给哪个进程

* 这里再截一张来自于维基百科的图,这里列举了一些常见的错误信息
![[QQ图片20250921190757.png]]

* 路由器通过将`ICMP`数据报封装进`IP`数据报中实现发回问题给源主机的效果


##### 2.3.2 `ICMP`的应用

###### 2.3.2.1 `ping`命令

* 我们经常用的`ping`命令就是利用了`ICMP`协议实现"尝试通话"这个操作的
* 我们可以仔细看看常见错误信息的这个图,其中类型`8`就是我们所关注的核心,这个类型表示请求一个目标主机用`ICMP`回复源主机
* 所以源主机会打包一个几乎是空的的`ICMP`数据报,其中`Type`是`8`,`Code`是`0`,并封装进`IP`数据报中,然后发送给目标主机
* 目标主机接收之后就会发回一个`Type`是`0`,`Code`是`0`的`ICMP`数据报给源主机表示相应回显

###### 2.3.2.2 `Traceroute`工具

* 这个工具可以用于检测当前主机到目标主机会经过多少跳
* 他的实现方式也很简单,她用了一个很巧妙地技巧
* 我们知道,`IP`协议中会存一个叫`TTL`(Time To Live)的字段,用于描述这个包还能跳多少次
* 如果一个包因为`TTL`减到`0`而导致被丢弃,那么路由器会发送`ICMP`协议的包(`Type=11`表示`ICMP`超时,`Code=0`表示`TTL`超时)回来
* 所以我们可以利用这个机制,发送携带固定数字`TTL`的包(`UDP`+`IP`协议)出去,并等待接收`ICMP`协议的包回来,就可以知道现在是第几跳
* 比方说第一次发送`TTL=1`的包出去,那么回复的肯定是第一跳,第二次发送`TTL=2`的包出去,第二次回复的肯定是第二跳,循环往复我们就能找出来我们到目标主机到底经过了多少跳
* 那我们怎么知道什么时候到了目标主机了呢,这时候我们会用另一个巧妙的办法
* 每次我们发出去的包,其中`UDP`指定的目标端口号都是一个实际一定不会存在的端口号,于是目标主机识别到这个端口号发现这是一个完全错误的端口号,于是会通过`ICMP`+`IP`协议(`Type=3`表示目的不可达,`Code=3`表示目标端口不可达)发回给源主机
* 源主机的`Traceroute`接收到目标主机的包之后,他也就知道本次检测已经完成了,就会自己退出

##### 2.3.3 附加

* 不过本质上`ICMP`其实并不是一个`Transport`层的协议,而是`IP`协议的子协议,但他会返回`Transport`层的错误回来,服务于`Transport`层,就有点像是这个协议是一个`Transport`层协议的感觉


#### 2.4 `End-to-End`(端到端原则)

* 这里我们重谈一下端到端原则

* 所以,为什么我们的每一跳都要设计得这么简单?为什么一定不能添加其他的功能?为什么不添加功能反倒能保证数据要么能够完整递达,要么被丢弃?

* 原先斯坦福大学的学生试图每一跳中添加安全检查,用来防止出现传输中的错误,但事实证明在每一跳添加安全检查是一个完全错误的选择,因为当时出了一个问题,虽然每一跳都会做安全检查,但是检查的都是传输时发生的问题,而在每一跳的机器的内存中出的问题这个没法在中途进行检测,但当时他们认为,在中途检测之后,两端就不需要进行检测,对于程序设计来讲会更加简单,所以实际上他们也确实这么做了,但结果就是,他们无法规避某一跳的内存中的`bug`所导致的数据出错,又因为摒弃了两端检查,所以就导致了递达的数据是错误的,而且还实际使用了错误的数据
* 所以实际上,每一个机器的每一个内存,每一个传输过程,都有可能导致数据出错,这个没法避免,所以,我们必须在两端进行检查,既然都在两端进行检查了,那么在中间任何一跳进行检查都没有任何意义了

#### 2.5 跳到跳错误检测

* 虽然我们一直强调端到端原则,不过实际上,在跳到跳我们也还是会用一些错误检测机制,之前我们聊过的`Checksum`就是这种检测机制
* 值得注意的是,虽然跳到跳有检测机制,但实际上我们依旧需要在端到端做错误检测,特别是在`Application`,必须手动做检测,否则可能会出现我们上一小节聊到过的情况,特别是安全敏感场景,比方说银行系统,甚至需要做非常多种的检测才能保证完全不出错

##### 2.5.1 `Checksum`校验和

* 校验和用了一种非常简单的机制用于错误检测
* 该机制将数据分为一个个的`16 Bits`的段,然后将每个段相加得到`Sum`,并将`Sum`取反就得到了`Checksum`
* 比方说,我要发送一个`0xABCD77668080`,我们将其分为`3`个`16 Bits`段并相加,即`0xABCD + 0x7766 + 0x8080 = 1A3B3`,因为`Checksum`最大只有`16 Bits`,所以实际上如果超出的话会重新从`0`开始计算,此时就会变成`A3B4`,然后将其取反得到`Checksum = 5C4B`
* 那么接收端如果要使用`Checksum`进行检测,其方式也非常简单,只需要把所有数据按`16 Bits`相加,并同时加上`Checksum`就行,如果得到的结果是`0xFFFF`,那么表示数据没出错(不一定)
* 那么,为什么相加之后,如果没错就一定会等于`0xFFFF`?
* 因为我们之前把所有段相加得到的数是`Sum`,而`Checksum`是这个数的取反,那么相加之后就一定是`0xFFFF`,相加数据相当于再次计算一遍`Sum`

* 但细心的你肯定发现了,这种校验方式简单,但不是特别保证安全
* 假设我通过银行程序转账给别的账户,如果我转出的金额是`0x8000`,但传输过程中最前面的字节和最后面的字节发生了交换,此时我的求和是没有发生任何改变的,`Sum`依旧是`1`,这就导致接收端会认为数据没出错,但实际上数据已经从三万多变成了一块钱了

* 这种校验方式能检测出奇数个错误,不保证能检测出偶数个错误,不过虽然嘴上说这个校验算法非常简单也非常菜,但是实际上即便是这样,也能够检测出99%的错误了

##### 2.5.2 `CRC`循环冗余校验

* 我们先了解一下这个算法的原理,稍后详细解释为什么这么做
* 首先,我们知道,一个被除数除以一个除数可以得到一个结果和一个余数,如果这个被除数被改变了,那么得到的余数也会不一样
* `CRC`的本质就是这个,发送方与接收方约定一个除数,发送方将数据除以这个除数,得到一个余数,将这个余数作为校验码一并发给接收方,然后接收方再次计算一边得到的数据,对比一下校验码就知道数据有没有丢失了

* 接下来我们来详细解释一下原理
* 这里可能会有一点点复杂
* 我们将要传的数据转换成二进制,会得到一串类似于这样的二进制串
* `b_k-1 b_k-2 ... b_0`,这里的`b_k-p`代表第`k-p`个二进制数字
* 我们将其带入一个多项式,这个多项式不需要被算出来,因为我们只需要计算其系数,不需要算实际的值
* 将以上这个式子转换成这样:`b_k-1*X^(k-1) + b_k-2*X^(k-2) + ... + b_0*X^0 = M(X)`
* 我们假设双方约定了这样一个除数(也是一个多项式):`X^5 + X^2 + 1 = G(X)`
* 那么我们需要将`M(X)`左移`6`位(这个地方可能看起来很奇怪,不过我们会在后面进行解释)
* 发送方将这个`M(X) % G(X)`得到一个余数多项式,令这个余数多项式为`R(X)`,`R(X)`的表示形式也和`M(X)`一样,所以它也可以转化成一个普通的二进制序列
* 那么发送方只需要把`M(X) + R(X)`转化成的二进制序列发送给接收方,接收方就可以自己除一下判断有没有问题了

* 我们举个例子(这里所有的式子都用二进制序列表示)
* 假设发送方要发送`1001 1101`,双方约定了`100101`作为除数,那么左移后取模得到余数为`010101`
* 因为除数是一个`6`位数字,所以余数最多可以有`6`位,所以我们把要发送的左移`6`位,这样除数可以跟在发送数据的后面
* 所以最终会发送`0010 0111 0101 0101`给发送方
* 发送方根据约定的除数,判断后`6`位是余数,因为`0010 0111 0100 0000`除以`100101`后会得到一个余数,那么`0010 0111 0100 0000 + 010101`后,再除以`100101`,就一定不会得到余数,此时一定会整除,那么如果没有整除成功,证明有数据丢失

* 那么,我们将理论的时候,用的是多项式相除,为什么实际可以是二进制相除呢?
* 很简单,你令多项式的`X=2`,不就是二进制了吗(这里其实这么理解是不完全对的,本质上其实是:`CRC`的运算不是普通整数除法，而是在 `GF(2)`上的多项式除法)

* 这里要着重提的是,这个`G(X)`的选择其实很有讲究,因为不同的`G(X)`能够判断的数据丢失类型是不同的,强大的`G(X)`很长很长,能够判断几乎99.9999999999%的错误
* 这里的这个`G(X)`我们就称为`CRC`
* 这里贴一下维基百科关于`CRC`的表
![[QQ截图20250922180409.png]]

##### 2.5.3 `MAC`(Message authentication code, 消息认证码)

* 简单来说,`MAC`是一个密钥检测机制
* `MAC`的思想源自于密码学,也和数学相关,我们不会在本小节深入算法细节,因为这确实很麻烦
* 核心思想是这样的:
* 假设现在有两台主机`A`与`B`,两者存在一个相同的密钥`K`,当`A`准备发送包给`B`的时候,他会通过`MAC`算法,通过数据唯一的包`M`和唯一的密钥`K`计算出一个唯一的随机编码`T1`,严格来说这个`T`不是随机的,它是由`M`和`K`生成的,当`B`接收到`M`之后,他会做相同的操作,通过`M`和`K`计算出随机编码`T2`,通过比对`T1`和`T2`,就可以判断这个包在传输中途有没有被篡改

* 但因为这个随机编码`T`是通过算法算出来的,我们也不可以保证某种特定情况下,在发出方和接收方的`M`不同的情况下,依旧能生成同样的`T`,所以`MAC`不保证能检测到任何一种数据错误



#### 2.6 `FSM`(finite-state machine, 有限状态机)

* 简单来说,`FSM`是一个图,这个图描述了很多状态,方便程序员将简单的图例转化成复杂的逻辑,换句话说,就是让逻辑更清晰更可控一点
* 我们简单的描述一下一个`FSM`包含了什么,首先先看一下这个图例

![[Pasted image 20250926193410.png]]

* 类似于这种图示,我们就可以称作是有限状态机
* 一个状态因为某个事件变成了另一个状态,同时会做出一些操作或者行为
* 当然,这个对象接收到的事件可能是一个未定义的事件,那么这个行为的转换也是一个未定义行为,但我们这里是"有限"状态机,所以对于这种未定义行为肯定要做出一些限制
* 当然,一个状态机描述的状态可能会非常复杂,状态量非常多,直接画图可能会显得很乱,所以很多时候会省略一些不太常见的状态,仅描述核心的,常见的状态,至于其他状态可能会备注一些补充说明什么的
* 当然,对于未定义行为,你也可以专门为其设计一个状态,这个状态直接由用户规范他的事件和行为,这也是可行的

* 老实说,在学习这个部分的时候我觉得使用"状态机"这种东西其实可以用于写另一个"玩意",你可能听说过这个"玩意",叫做"元胞自动机",这是由冯诺依曼提出的模型,感兴趣的话可以搜一下(当然,实际上冯诺依曼提出的元胞自动机其实并没有实现出来,因为状态太复杂了)

* 接着我们可以来看一下`TCP`的`FSM`

![[Pasted image 20250926192210.png]]

* 我们来详细解说一下`client`和`server`的状态:
	1. `client`处于`CLOSED`状态,表示其连接关闭,`server`处于`LISTEN`状态,表示其正在监听是否有`client`发送请求
	2. `client`现在发送`SYN`请求,也就是做"Step 1 of the 3-way-handshake"这个步骤,也就是进入事件`CONNECT`,行为是发送`SYN`,然后`client`进入`SYN SENT`状态
	3. `server`收到事件`SYN`,然后做出发送`SYN+ACK`的行为,并转换状态到`SYN RECEIVED`
	4. `client`收到事件`SYN+ACK`,做出发送`ACK`的行为,并将状态转换到`ESTABLISHED`,表示连接已确立
	5. `server`收到事件`ACK`,不做出任何行为,将状态转换到`ESTABLISHED`,表示连接已确立
	6. `client`进入事件`CLOSE`,于是做出发送`FIN`的行为,并转化到状态`FIN WAIT 1`
	7. `server`接收到事件`FIN`,于是做出发送`ACK`的行为,并转换到状态`CLOSE WAIT`
	8. `client`接收到事件`ACK`,不做出任何行为,转换到状态`FIN WAIT 2`
	9. `server`也进入事件`CLOSE`,于是做出发送`FIN`的行为,并转化到状态`LAST ACK`
	9. `client`接收到事件`FIN`,于是做出发送`ACK`的行为,并转换状态到`TIME WAIT`
	10. `server`接收到事件`ACK`,不做出任何行为,转换状态到`CLOSED`
	11. `client`因为超时而转换状态到`CLOSED`

* 至此,一个完整的`TCP`过程结束


#### 2.7 流量控制

* 老实说,其实我们之前已经谈过流量控制的一部分内容了,只是当时大家还不太了解谈的东西关乎于流量控制

* 流量控制有两种策略:
	1. `Stop & Wait`: 基于一问一答模式的流量控制,优势是简单,不容易出错,缺点是效率过低
	2. `Sliding Window`: 基于滑动窗口的流量控制,优势是效率可以动态变化,效率可以非常高,缺点是更加复杂更容易出错

* 需要流量控制的原因也很简单,因为接收方接收的带宽可能是有限的,如果发送方的带宽过大,就会导致接收方来不及接收这么多数据,于是就会导致网络传输了毫无意义一定会被丢弃的数据,造成了资源的损耗

* 接下来我们详细聊一聊

##### 2.7.1 `Stop & Wait`

* 这个策略非常简单
* 就像是对讲机的一问一答一样,当发送方的数据包传输到之后,接收方会表示收到,然后发送方会发送下一个包
* 这样,对于这两台机器来说,发送方和接收方之间建立的网络连接中,只存在一个包在传输,这样就一定不会有资源损耗了

* 我们说得更复杂些:
	1. 发送方发送了包1
	2. 接收方接收了包并回复`ACK`
	3. 发送方发送了包2但是因为网络问题没有送达
	4. 超时之后发送方会重发包2
	5. 接收方接收了包2并回复`ACK`
	6. 发送方发送了包3
	7. 接收方接收了包3并回复`ACK`
	8. 回复的`ACK`因为网络问题没有送达
	9. 发送方以为没有送达,所以超时之后重发包3
	10. 接收方接收了包3并回复`ACK`
	11. 发送方发送了包4 
	12. 接收方接收了包4并回复`ACK`
	13. 回复的`ACK`因为网络问题没有送达
	14. 发送方以为没有送达,所以超时之后重发包4
	15. 接收方接收了包4并回复`ACK`
	16. 发送方发送了包5
	17. 突然间,之前没有接收成功的`ACK`突然恢复正常了,突然就被发送方接收了,那么发送方无法判断包5是否被接收!

* 以上,我们详细了解了可以解决的三种问题,即:
	1. 正常发送正常回复
	2. 发送失败
	3. 回复失败

* 现在有一个无法解决的问题: 即回复失败之后突然恢复正常

* 解决方式很简单,因为我们没法区分回复的`ACK`是针对哪个包的,所以只需要做区分就好了
* 发送方每次发送携带一个专用的识别码
* 接收方每次回复的时候携带相同的识别码回去
* 所以我们回到例子:
	1. 发送方发送了包4 
	2. 接收方接收了包4并回复`ACK`
	3. 回复的`ACK`因为网络问题没有送达
	4. 发送方以为没有送达,所以超时之后重发包4
	5. 接收方接收了包4并回复`ACK`
	6. 发送方发送了包5
	7. 突然间,之前没有接收成功的`ACK`突然恢复正常了,突然就被发送方接收了,那么发送方对比识别码发现这个识别码是一个已经应答的包4的识别码,所以发送方选择忽略这次重复`ACK`

* 那么,有没有办法给这个策略提速呢?肯定是有的,不过我们得谈谈导致这个策略速度慢的本质
* 我们知道网络是有延迟的
* 在这个策略中,我们采用的其实是串行传输,所以两个包发送的间隔取决于回复速度
* 而回复速度其实取决于延迟,毕竟发包的速度很快,慢的是传输嘛
* 所以解决速度慢问题的最简单的方式就是降低延迟

##### 2.7.2 `Sliding Window`

* 这种控制方式就比较麻烦了,不过这可以联系上我们之前了解过的`Sequence`和`Acknowledge Sequence`字段

* 先来讲讲滑动窗口方面(滑动窗口是一个很常用的算法,这里我们不深究算法内容)
* 为什么需要滑动窗口?
* 因为,传输延迟是不可避免的!所以不管你再怎么优化,远距离传输中`Stop & Wait`的上限其实并不是非常高
* 所以有了滑动窗口,因为滑动窗口策略是并行传输的!
* 滑动窗口策略允许两个端之间的网络中存在多个包!
* 对于发送方来说,他存在一个窗口,这个窗口中会维护多个包,也就是我们在`Sequence`和`Acknowledge Sequence`小节中提到过的`ISN`,这个窗口的下标会基于`ISN`设计
* 发送方会按顺序一次性发送窗口中维护的多个包
* 接收方接收的包不一定会按顺序抵达
* 假设发送方窗口大小是`6`,因为`ISN`导致窗口的起始位置是`1000`,单个包的大小是`2`,接收方窗口大小也是`6`,窗口起始位置是`3000`:
	1. 发送方发送`1000~1001`,`1002~1003`,`1004~1005`
	2. 此时接收方已经接受到了`1000~1001`,回复`ACK`并表示期待`1002`,同时其窗口后移接受到的包的大小,此时窗口起始位置是`3002`
	3. `1002~1003`传输过程中被遗失了,但接收方依旧收到了`1004~1005`,此时接收方会`ACK``1002`表示期待你的`1002`(或者说你的`1002`为什么没到?!),此时窗口里虽然有值(`1004~1005`那个包),但是因为窗口前面有空着的`3002~3003`,所以窗口不移动
	4. 发送方超时后,检查最后一个收到的`ACK`发现对方还在等我的`1002`,于是发送方重发一边`1002~1003`
	5. 这次接收方正常接收了,于是接收方回复`ACK``1006`,表示我期待你的`1006`且前面的内容我都已经收到了,于是窗口后移到`3006`
	6. 接收方接收了`ACK`后发现维护的窗口的所有内容对方都已经接受到了,所以也后移自己的窗口到`1006`

* 我们称"窗口前部有连续的存在字节就移动窗口"的这种策略为"累积确认"

* 那么,换句话说,其实接收方发送的期待值,其实某种角度也代表着自己的窗口的起始位置
* 另外发送方和接收方的窗口大小其实并不固定,接收方会告诉发送方自己还有多少剩余空间,也就是我们在`TCP Header`中学习的`Window Size`字段的功能
* 所以这个窗口大小其实是可以动态调整的

* 那么理论上,发送方应该维护这几个变量:
	1. `Send Window Size`(`SWS`): 即发送的包的窗口大小
	2. `Last Acknowledgement Received`(`LAR`): 最后一个回应的位置,即接收方最后期待的位置
	3. `Last Segment Sent`(`LSS`): 最后一个发送的位置

* 所以理论上,最差的情况就是其他包都到了,只有第一个包没有到,所以一定有`LSS - LAR <= SWS`

* 同时,接收方应该维护这几个变量:
	1. `Revive Window Size`(`RWS`): 即接收方的窗口大小
	2. `Last Acceptable Segment`(`LAS`): 即最后一个期待包的位置
	3. `Last Segment Received`(`LSR`): 即最后一个接收的包的位置

* 所以在最差的情况下,一定也会有`LSR - LAS <= RWS`

#### 2.8 重传策略

* 重传策略一般分为两种:
	1. `Go-Back-N`("回退N",`GBN`)
	2. `Selective Repeat`("选择重传",`SR`)

* 前者是一个极其悲观的策略,窗口中有任何一个包丢失,该策略都会直接重传整个窗口的所有包
* 后者则是非常乐观的策略,仅重传丢失的某个固定的包

* 我们在使用滑动窗口做流量控制的时候,一般会采用第二种策略,但如果接收端窗口大小是`1`,那么将会退化为第一种策略
* 主要原因是,如果接收端窗口为`1`,那么他无法缓存处于丢失的包之后的包(`index`位置的"之后"),所以如果丢包了,那么之后传的任何包丢直接丢失了,因为不在接收端窗口内

* 两种策略各有优劣 
* `GBN`更适合网络通信不太好的情况,因为他的重传检测很快,如果网络总是丢很多包,那么这种策略的"命中概率"会很高,那么可以节约很多关于`ACK`回复的延迟等待的时间,不过宏观来看,这种策略还是非常保守 
* `SR`则适合网络通信良好不容易丢包的场景,可以节约网络资源,如果网络不太好还使用`SR`,那么每个包都得一个个重传,同时还得一个个等待`ACK`,每等待一个`ACK`,都会造成一次端到端通信的延迟,那么宏观的看,就会造成很大的延迟,浪费时间


### 3 分组交换(`Packet Switching`)

#### 3.1 网络的历史

* 在CS144课程中花了一些篇幅聊网络的历史,固然这段历史很重要,但归根结底并不是这篇笔记的核心,所以我们仅作了解

#### 3.2 我们为什么需要分组交换

* 虽然在之前我们有简单了解过分组交换的相关概念,但在本章节我们会更加深入地理解分组交换的实质

* 在深入分析"我们为什么需要分组交换"这个话题之前,我觉得还是有必要讲一讲CS144中提到的例子,这对我们后续理解分组交换的意义有很大的帮助

##### 3.2.1 电话线路交换

* 不清楚你是否知道有个职业叫做"接线员",现在这个职业已经被彻底取代了,如果你是00后,哪怕你听说过这个职业,也可能不太清楚这个职业具体是做什么的

* 在发明线路电话的时候,很明显,一条电话线会被两个处于端点的人拥有
* 但很显然,我们无法为所有人分配一条电话线,毕竟这很昂贵,如果每个人都有电话线的话,那么每添加一个联系人,就需要新增一整条电话线
* 所以,后期的做法是,每个人会拥有一条电话线,但不是完整的,在没有拨通电话的时候,这条电话线连接的是"转接服务中心"
* 如果我要打给某个人,我就得告诉"服务中心的接线员"我要打给谁,然后接线员会在物理上帮我接电话线到对方
* 然后在通话的过程中,我和对方会独占这条电话线

* 所以你会发现一个有趣的事情,接线这个操作,本质上不就是"路由"吗?

* 而对于现代电话通信中,"路由"的操作通常就不是由人类来进行了,同时是通过电路来路由目的地,同时,传输过程中也不仅仅是只经过一次"路由",而可能会经过多次路由

* 另外,虽然现代电话线路中,其线路物理上可以被多个人共享,但是本质上所有的线路依旧被两个端点独占,所以我们依旧按照传统方式看待现代电话线路

* 但势必的,如果一条线路会被短暂独占,那么就需要为所有的路由增加"状态",一般我们简单地把路由看作有三个状态:
	1. 拨号
	2. 通话
	3. 断开

* 虽然新增状态可以让拨号这个操作变得自动化,但是可维护性却大大下降了

##### 3.2.2 网络中的分组交换

* 网络中的分组交换其实本质上也是路由,看起来比"电话路由"要更加复杂,但实际情况是,网络的交换其实更加简单,这点你应该可以在之前的小节中窥见
* 不使用电话的交换方式的主要原因其实很简单:电话线路交换需要维护状态!
* 换句话说,电话线路交换中,每条线路会维护单一的状态,那么一旦这么做,会导致线路被独占
* 那么,网络独占线路有什么错吗?这点我们之前也提到过,你正在打游戏,已经匹配上了,结果就因为室友在下电影,所以哪怕匹配进游戏了,也没法直接开打
* 更深入的说,互联网的连接讲究一个突发性,需要有很高的时效性,那么独占的思路必然是有问题,所以必须采用共享线路的思路
* 另外,一旦线路有了状态,那么维护线路将会是一个很麻烦的事情,并且维护状态造成的性能开销也可能会让延迟增加
* 同时,这也造成电话线路的灵活性较差,比方说通话过程中某个线路突然断开了,那么通话就直接没了,如果采用分组交换的话,就可一定程度上使用别的线路(本质就是使用转发表的其他下一跳来规避问题线路)

* 当然,另外一个需要提到的点是,因为路由器发包是串行的,所以如果路由器同时收到两个包,他得先存一个包,然后发另一个包,等到另一个包发完了才会发这个存的包,所以路由器或者说传输中间的任何一跳都是一定会有缓存的

#### 3.3 延迟&丢包

* 因为网络是一个突发敏感的传输方式,所以计算延迟是一个非常重要的步骤
* 我们来看看计算网络延迟大概需要哪些内容

##### 3.3.1 三种延迟

* 首先是物理延迟,或者说信号在介质中传输的延迟
* 要知道,电信号一般的传输速度都接近光速,我们按照`2 * 10^8 m/s`计算 
* 按照CS144课程中的例子,如果传输介质长`1000km`,在不考虑其他因素的前提下,那么信息从发送方传输到接收方所需时间大概是`1000km / (2 * 10^8 m/s) = 5ms`,那么,延迟至少是`5ms`起步

* 另一个值得注意的是"分组延迟",这个延迟其实很有意思
* 我们知道数据被转化成`0`&`1`,然后变成高低电平,也就是电信号,这些信号是串行的,因为某个时刻,某个数据线中的某一段的电平不可能有高低两种状态
* 所以发送方把数据传递给信号线也是需要时间的,我们把发送方从开始传递第一个`bit`到结束传递最后一个`bit`的过程称为"分组延迟"
* 换句话说,你知道你的电脑的网卡也是有旗舰款,中端款和低端款吗?
* 款式越低,那么网卡传递信号出去的效率也会越慢,然后分组延迟也就会越高
* 一般分组延迟是这样计算的,如果我我们知道网卡设备将数据塞进传输设备的速度,这里同样用CS144的例子,假设速度是`100Mb/s`,那么将一个`64byte`的包放进介质中需要约`64byte / 100Mb/s = 5.12μs`
* 如果速度是`1kb/s`,将`1kbit`的包放进介质中则需要约`1.024s`

* 所以,就以上两种延迟,我们来画个图(原图依旧是来自CS144)
![[Pasted image 20251002223038.png]]

* 在这个图中,我们假设有两台主机,中间有一台路由,`A`需要经过路由发包给`B`

* 那么,发送方不会在一瞬间就发送完整个包,于是就会有一种情况,在某个时刻,链路上存在着一个不完整的包,因为包还没有完全发送完毕
* 同时也会存在一个时刻,`A`认为自己已经发完了包,路由认为`A`啥也没发给他,因为包还在路上
* 同时也会存在一个时刻,会有一部分不完整的包还在链路中,剩下的内容已经被路由拿到了
* 只有当路由中的包完整了,路由才会选择转发出去

* 那么,一个包被路由接收之后,一定会立马被转发出去吗?
* 当然不会,如果这个路由在某个瞬间接收了太多包了,那么你的包有可能需要在路由的缓存中排队一段时间,然后才被发送到下一跳
* 那么,此时咱们的图就有可能变成这样
![[Pasted image 20251002231247.png]]

* 当然,如果这个路由在一瞬间有超出路由缓存上限的包试图进入路由,那么路由有可能会直接丢弃包, 如果你的学校人比较多的话,一般在大型的且没有意义的活动上可能就会这样,明明连接着5G,却什么也访问不了像是断网了一样,这时候我们可以尝试着切换到4G,这样排队的人会相对较少,至少能上网了

* 所以说,如果你交换信息的目标地址离你的物理距离特别远,那么传输介质的长度会很长,同时中间需要经过的跳的数量也会有极大概率显著增加,那么遇到排队的概率也会显著增加,这就也是我们访问远端主机的时候延迟非常大的原因之一

* 所以,就我们**现在了解的内容**综合来看,一个包的延迟为"传输延迟"+"分组延迟"+"可能的排队延迟"

##### 3.3.2 接收端缓冲

* 使用网络有着很多不同种类的场景
* 有些场景对于延迟极其敏感,而对于延迟敏感的场景,我们又可以分为需要与其他主机同步的场景与不需要与主机同步的场景
* 比方说网络游戏就对延迟非常敏感,并且需要与他人同步状态,所以对于网络的要求非常苛刻
* 又比方说在流媒体网站观看视频,如果体现在用户上,这种场景一样对于延迟非常敏感,但因为不需要与其他用户同步,所以他可以通过缓存来极大地提升体验
* 另外也有完全不在乎延迟的场景,比方说文件下载或者是网页加载这种
* 本小节着重了解第二种场景

* 我们假设视频文件的发送方按照某个固定速率发送视频,比方说发送方以`1Mb/s`的速率发送视频过来,用户也以`1Mb/s`的速率播放视频
![[Pasted image 20251003161041.png]]

* 那么,接收方接收到数据之后不会立马使用,就比方说我们在看长视频的时候,视频也不会立马播放,他可能会缓冲大概半秒钟左右才会播放
* 此时就是该进程正在接收数据并缓存的过程
* 缓存到一定程度之后,才会开始播放,此时就不会造成用户的卡顿
* 某个时刻,用户可能才看到大概第`1`分钟,但程序在后台已经缓存到大概第`2`分钟了

* 如果网络延迟太高,或者丢包率太高,就有可能会造成以下情况
![[Pasted image 20251003162158.png]]

* 当缓存量已经不满足用户播放的需求量时,就会造成赤字,于是用户就会卡顿直到留有一定缓存才会播放

* 所以换句话说,我们可以尽可能保证平均到达速率和播放速度差不多,或者说平均到达速度大于播放速度,但我们没法保证某个短时间内的到达速率(或者也可以说某个瞬间的接收端斜率)一定大于等于播放速度,所以我们需要缓存来提升用户体验,避免因为网络波动造成的卡顿

##### 3.3.3 排队模型(`queue models`)

* 这个小节的内容其实很简单,甚至说你可以通过之前学过的内容直接推断出来,所以本小节实际上几乎仅作为结论的输出
* 简单来说就是在路由中存在一个缓存,该缓存会被当作一个队列来使用:
* 这个队列会有的属性,包括某时刻的输入总量(可能来自不同机器),某时刻的缓存量,某时刻的输出总量,输出速率,根据这几个属性画了一个横坐标是时间,纵坐标是数据量的折线图,包括该缓存的接收折线与输出折线,于是我们可以根据这两个折线分析该缓存的属性与状态 
![[Pasted image 20251003212224.png]]
* 为什么包越小,延迟会越小?那么原因其实很简单,因为包越小,就越可以接近并行传输,缓存可以在接收一个包的时候发送另一个包 
![[Pasted image 20251003211936.png]]
* 另外,通过一个更复杂的折线图,我们可以了解到,只要一个缓存在某一时间段内的平均接收速率小于输出速率,且缓存始终没有吃满,那么就不会丢包,但可能会缓存,如果一个缓存的在某一时间段内的峰值接收速率小于输出速率,那么甚至连缓存都没有,一般可以直接输出

![[Pasted image 20251003213809.png]]
![[Pasted image 20251003213816.png]]

* 那么我们假设在`v2`开始缓存之前,`v1`缓存的数据已经全部被输出掉了,那么假设`v2`的大小已经大于了能够缓存的上限了,那么超出的部分将会被直接丢弃,也就是丢包了

##### 3.3.4 "随机"与延迟与泊松分布

* 首先复述一个之前我们已经了解过的结论
* 对于一个路由/交换机来说,包的抵达是一个非常随机的事情,如果有非常多的包在同一时间抵达,那么延迟就会非常高,甚至于丢包,以下我们会通过一个例子来说明这个问题

* 假设在一个路由中,`5s`内,平均`1s`就会有一个包到达,这里假设所有的包的大小都相同,假设一个包从介质中抵达路由需要`0.2s`(实际肯定要短得多,这里只是许个例子),一个包被路由输出的时间为`0.4s`
* 那么最好的情况应该是每隔`1s`就正好有`1`个包到达,那么在这`1s`中,前`0.2s`将会是接收包的过程,紧接着的`0.4s`应该是发送包的过程,剩下的`0.4s`,路由器什么都不做,处于等待/监听状态
* 在这种情况中,不会有包需要排队
* 但是,如果`5s`内,这`5`个包全部在同`1s`内全部被路由接收,那么先进的包不需要排队,第二个包需要等待`0.2s`,第三个包需要等待`0.4s`,如此递推
* 虽然平均接收的包并不多,但是仍然造成了延迟

* 我们很难估量某个时间段内会有多少数据包抵达,因为包的抵达几乎是纯随机的,所以我们需要借助泊松分布来衡量

* 因为我的数学其实学得并不是很好,甚至说非常差,所以在本小节我不会详细推导泊松分布(但会简单推导一下),但我会讲解为什么我们需要泊松分布公式,为什么他可以用在这里

* 简单来说,泊松分布用于计算"某一段时间内可能会发生若干次数的某个随机事件的概率",换句话说,就是计算"在这个时间段内,发生多少次这个事件的概率大概是多少"
* 他是怎样做到的?
* 因为事件在这个时间内会发生多次,所以事件不是独立的
* 所以我们可以通过把时间分片,以实现某个时间片中要么只发生一次时间,要么不发生,这样事件就是独立的了,然后可以用二项分布求概率,于是我们可以得到一个公式,用于表示在“在`n`个独立的小片中,每个小片事件发生概率为`p`,那么总共发生`k`次的概率是多少”

![[Pasted image 20251004235053.png]]

* 但时间片具体要分多细,这个我们不知道,所以我们最后要求极限,就可以假设时间片无限细的情况下,某一段时间内某随机事件发生的概率了,于是可以得到以下公式用于表示"在趋近于无限个独立的小片中,每个小片事件发生概率为`p`(因为时间片太多了,所以`p`这个概率会无限趋近于`0`),那么总共发生`k`次的概率是多少"
![[Pasted image 20251004235134.png]]
* PS:n->∞,p->0,np=λ

* 难道网络中的所有的包都可以是泊松的吗?
* 不能,因为泊松描述的是"随机",然而从宏观来看,网络中包数量的多少并不是泊松的
* 我们打个比方
* 我们知道有几个著名的时间段,人们会在这个时间段通过网购买特别多的东西,比方说618或者双十一
* 这几个时期是固定的,那么此时购物平台需要收发的数据包的数量将会提升几十甚至上百倍,所有卖家,买家,运营商,银行,购物平台,支付平台的数据包收发都会有风险因此垮掉,所以他们会针对这个时间段,像是应对大BOSS一样需要在短时间内应对如此大的流量
* 难道他们还属于泊松吗,显然是不可能的,这种情况是人为的,一定不属于泊松

* 所以说,从微观来看,比方说在几分钟或者说几秒内,包的传输无限趋近于泊松,但是宏观来看,包的传输很难称得上泊松

#### 3.5 以太网交换机和路由器

##### 3.5.1 工作原理简述

* 简单来说,以太网交换机是服务于`Link`层的,他的目的是用于转发以太网帧
* 首先我们可以见一见交换机长什么样,如果你家开过餐馆装过监控系统或者你有见到过商场装监控的话,你肯定看见过这个长着很多个输入输出口东西

![[69079ede-7b3c-4f04-83e6-11265cb6a4fa.png]]

* 我们看这些接口,粗略地看,我们把每一个接口都看作是一个端口

* 那么他的工作原理很简单:
	1. 检查到达的帧的`Header`
	2. 如果在转发表中存在这个`Header`中的目的以太网地址,那就直接转发
	3. 如果不存在,那么就会向除了接收该帧的端口外的所有帧全部广播地发送一遍这个帧
	4. 那么,交换机会学习,他会自行扩充转发表,比方说如果交换机接收到了一个没见过的`SRC MAC`的帧,那么他会将这个`MAC`地址与输出端口绑定,并塞进一个转发表中,如果下次从别的端口进来一个帧,他的目的`MAC`是之前存的这个`MAC`地址,那么他就会往之前记录的端口发送,我们在后面几个小节会更加深入探讨这个问题

* 接着我们来聊聊路由器
* 路由器你肯定见过
* 说不定你现在看这篇笔记的电脑的主机旁边就放着一个路由器

![[asus-rt-ax3000-wifi-router-01.jpg]]

* 路由器的本职不是转发`Link`层的帧的,他的本职其实是转发`IP Datagram`,所以他其实是工作在`Network`层的

* 路由器的工作原理:
	1. 检查一下这个包是不是专门发送给自己这个路由器的,如果是就接收,如果不是,那就是对方发错了,直接丢弃
	2. 如果自己是一个针对`IPv4`的路由器,那么得检查一下`IP`版本,防止接收到`IPv6`的包
	3. 把`TTL--`,并且检查`checksum`
	4. 检查`TTL`是否为`0`,如果是`0`,那么直接丢弃
	5. 查找转发表,如果转发表中存在这个`IP`范围,那么直接转发到目标端口,如果不存在,则通过默认路由转发,当然,还会检查一下是不是多播(简单来说就是群发),如果是,那么就转发到多个端口
	6. 如果能在`ARP`表中找到下一跳的以太网地址,那么将会直接封装一个以太网帧并通过目标端口转发
	7. 如果找不到下一跳以太网地址,那么将会先通过`ARP`广播获取下一跳的以太网地址

* 我知道现在咱看到这堆东西还是一头雾水,不过没有关系,有一些问题,我们会在后面解决

##### 3.5.2 查表

* 对于交换机来说,他的转发表其实很简单

* 大概长这样:

|目标`MAC`地址|目标端口|
| :---: | :---: |
|`0xA8B72340E678`|`port 7`|
|`0xB3D22571053B`|`port 3`|
|`...`|`...`|

* 当然,这个表实际上是放在一个双向的哈希表中的,这样会方便查找

* 对于路由器来说,查表会相对来说复杂一点,路由器会有两张表:

* 路由器的转发表:

|目标`IP`范围|下一跳`IP`|目标端口|
| :---: | :---: | :--: |
|`127.43.57.99`|`56.99.32.16`|`port 3`|
|`123.66.44.X`|`22.45.21.126`|`port 2`|
|`76.9.X.X`|`56.99.32.16`|`port 6`|
|`...`|`...`|`...`|

* 当然,一个路由表可能不仅仅包含这些信息,具体其实要取决于路由的协议
* 通过匹配最长前缀算法,我们可以知道哪个下一跳是最优的

* 因为路由器服务于`IP`协议,所以实际上路由器会解包一个帧,然后获取一个一个包的`IP Header`,但是实际传输肯定是跑在`Link`层的,所以解包之后,肯定还要再次封装一个`Link`帧,问题是`Link`帧中,下一跳的`MAC`地址我们是不知道的,所以需要缓存另一张表,映射下一跳`IP`和`MAC`地址

* 路由器的`ARP`表:

|下一跳`IP`|`MAC`地址|
| :--: | :--: |
|`56.99.32.16`|`0x76E309AB2CA1`|
|`22.45.21.126`|`0x43ED7D88A1B8`|
|`56.99.32.16`|`0x663ADD9B3771`|
|`...`|`...`|

##### 3.5.3 一些问题

* 这么说,路由器和交换机其实很像啊?
* 并非,从地位上讲他们两个完全不一样!

* 不知道你有没有发现一个细节
* 交换机的转发表中,存储的都是固定的`MAC`地址,以及对应的端口,他不会存储下一个机器的`MAC`地址,`IP`地址,以及某个`IP`范围或者是`MAC`地址范围

* 因为交换机根本就不会解包,换句话说,交换机的工作范围其实非常小
* 换句话说,他只负责某一个很小的网段内部的通信工作,而不负责转发到除了他负责的网段之外的其他网段

* 换句话说,这也体现了路由器其实是服务于更加上层的`Network`层的,而交换机是服务于更加底层的`Link`层的

* 那么实际的情况是怎样的?我们举个例子来说说:
	1. 比方说你的电脑,现在发一个包给主机旁边的路由器
	2. 然后路由器会解包,检查,查表,然后再封装转发给另一个路由(一般是运营商的路由)
	3. 那么运营商的路由可能会做同样的操作,但却不是转发给另一个路由,而是转发给这个路由器旁边的交换机,交换机经过多层转发,将包最终给到另一个路由器,然后由这个路由器转发给互联网服务商
	4. 服务商也会做一样的事情,路由接收,但是在服务商的数据中心却是经过交换机传输包,最终传输给服务器

* 另一个问题,一个路由的转发表有多少项?他是怎样查表的?

* 一个路由器大概有十万多个项,所以如果用暴力查找的话,其实非常浪费时间
* 所以他会做这样的事情:初始化一个深度是`32`的二叉树,每一个分支中,向左是`0`,向右是`1`
* 比方说我要查`0b 1100 0000 1010 1000`(`192.168.0.0/16`,只用查`16`位,后面的掩码掉了)这个地址,只需要这样索引"右右左左 左左左左 右左右左 右左左左",然后查看这个节点存的是哪个端口,哪个`IP`地址

* 当然,以上肯定不是找实际包里的`IP`地址,我们举个更详细的例子
* 现在路由表有`3`个项:
	1. `0.0.0.0/0`(`0b 0`)
	2. `192.168.0.0/16`(`0b 1100 0000 1010 1000`)
	3. `192.168.10.0/24`(`0b 1100 0000 1010 1000 0000 1010`)

* 现在包里的`IP`是`192.168.13.108`
* 转换成二进制是`0b 1100 0000 1010 1000 0000 1101 0110 1100`
* 所以我们按照左右一直从根往下找,直到找到匹配的`192.168.0.0/16`,当然,找到这个项之后其实不会停下来,而是会先缓存起来,因为其实现在还没到叶子节点,剩下还有整整`16 bits`没找,于是接着找`0000 1101 0110 1100`
* 结果发现,直到找到叶子节点,这个缓存的项再也没有更新过了,因为其他的节点全部都是空的,所以此时我们就直接使用找到的节点的内容`port X & IP 0x AA.BB.CC.DD`

* 所以在最差的情况下,这个路由表也只会查找`32`次,不会更多了!常数次的查找,能将查找时间控制到纳秒级别,这就很快了!!

##### 3.5.4 通用转发设备架构

* 本小节,我们来将之前聊过的交换机工作原理转化为架构
* 这里标题是"通用转发设备架构",主要原因是,本质上所有的交换设备的原理都差不多,所以这里取标题"通用转发设备架构"

* 我们来简单看看架构图(本小节所有架构图的原图全部来自于CS144,我只是自己全部画了一遍以便加深理解)
![[Pasted image 20251008131254.png]]

1. `Lookup Address`:查看目标地址,确定去向,当然,这个步骤肯定会查找转发表,也就是`Forwarding Table`
2. `Update Header`: 更新包头部内容,如果是路由器就会做`TTL--`,修改`MAC`地址之类的内容,如果是二层交换机(仅做某网段内的包转发的交换机)则没有这个功能,因为其不修改包头,如果是三层交换机(有部分路由功能的交换机,介于路由器和二层交换机的中间产物),则需要有这个功能
3. `Queue Packet`: 等待队列,如果需要,则会先塞进缓存中

* 当然,以上只是一个简单的架构,如你所见,这个架构其实是单入单出的,如果要实现多入多出,就会变成这样
![[Pasted image 20251008135538.png]]

* 这个架构有个简单的称呼,即"输出队列交换机","output queue packet switch",简称`OQPS`
* 因为缓存队列存在输出端中而不是输入端
* 这是一种"理想"的交换机架构,但他的问题其实比较大
* 正因为他的缓存释放在输出端的,所以这会导致一个很严重的问题:即如果这个交换机如果退化为N入单出,那么输出端用于缓存队列的硬件需要非常非常高的速率才能满足这种退化,换句话说,假设所有输入端口全部要往同一个输出端口输出,那么这个端口的缓存需要在非常短的时间内承受所有输入端的写入操作,这对缓存的读写能力的考验是极大的,几乎没有缓存能够承受住这种读写
* 假设单个输入与输出端口的速率全部为`R`,输入端口数量为`N`那么在这个架构下,交换机的缓存至少需要有`(N + 1) * R`的读写速率,这是非常恐怖的速率
* 所以我们说这种架构是理想的,但几乎是不可实现的

* 如果我们在`OQPS`上做一下修改,试图解决这个缓存速率问题,就会得到另一个架构
* "输入队列交换机","output queue packet switch",简称`IQPS`

![[Pasted image 20251008141554.png]]
* 这个解决思路其实很简单:既然输出端口的缓存可能会接收很多个输入端口的包,那么只要把缓存挪到输入端口不就行了,这样每个缓存就只需要接收一个输入端口的包了,所需读写效率直接变成`2R`了,远低于`(N + 1) * R`

* 但这又引入了另一个问题
* 我们可以把输入端简化成一个个队列
![[Pasted image 20251008142939.png]]

* 因为输入端的队列仍然是一个单队列,这就意味着,可能会有一种情况,输出端A堵住了,某个输入端的缓存队列中的首个包也是往A走的包,那么这个包也会被堵住,假设这个包后面还排了一堆往其他口走的包,那么哪怕其他口空闲了,这些包也走不了,因为在队头往A走的包走不动
* 这种现象称为头端阻塞
* 放在这个图中,第二个队列因为绿色的阻塞,导致后面的橙色和蓝色全都走不动,即便蓝色和橙色的输出端口全部是空的

* 于是我们需要在这基础上再做一些改进

* 于是我们得到了"基于输出队列的`IQPS`",也可以称作`VOQS`
![[Pasted image 20251008143513.png]]
* 他的每个缓存中,都存在"输出端口数量"个队列,这就不会造成常规`IQPS`的头端阻塞问题了

* `OQPS`是一种理想的架构,几乎无法实现,理性情况下,`VOQS`可以非常接近`OQPS`,而`IQPS`则只有`OQPS`效率的`58%`左右


##### 3.5.5 队列设计

* 请注意,个人认为本小节其实在文字上其实很难表述,从这个小节巨量的图就可以看出来,所以十分推荐先看课程

* 记得我们之前类比过网络资源和`CPU`资源吗?
* 网络资源和`CPU`资源其实很像,本质上,用户串行获取`CPU`资源,只不过在用户视角看起来太快了,就像是并行获取资源一样
* 那么,本质上路由或者交换机以串行服务用户,或者说以串行获取用户的包,这很好理解
* 那么问题来了,网络难道没有像`CPU`一样有优先级概念吗??
* 有的朋友,有的,我们本小节就来深入谈谈这个问题

* 那么,不知道你有没有遇到过一个非常有意思的事情,你的五个室友,一起开黑,车队满了所以你打算看看库里季度促销买了但没有玩过的3A单机
* 挑了个不错的开始下载,刚点击下载,你的室友们的网络集体爆炸,延迟飙升

* 在这个例子中,有两种网络使用场景:
	1. 延迟敏感但是流量不大的网络游戏场景
	2. 延迟不敏感但流量很大的下载场景

* 我们由浅入深地看,所以这里的图例其实是一个非常简单的图例,后面我们会过渡到之前的学到的架构中
![[Pasted image 20251008224202.png]]

* 那么我们知道,这个缓存队列中包的去向其实并不一致,那么,现在宿舍中有`6`个主机,那么去向就是`6`个?
* 其实不是的,本质上,其实所有人共享路由器的同一个网络端口,所以本质上,这个多入多出退化成了多入单出,除非你用有线连接到路由器
* 一开始的`5`个人全部都是在打网游,流量其实并不高,路由器需要接受的字节数和包的数量其实并不是非常多,他只需要在某个瞬间切换传输包的设备,然后传给他就行了
* 所以目前来看,路由器开能顶得住,秉承着`FIFO`的设计思想,一个包先到的话,就会先发送给你需要收这个包的室友
* 换句话说就是轮流给`5`个室友发包,固定时间内一人来一个包
* 但是,某个时刻你点了开始下载了
* 于是发生了一件非常抽象的事情,因为开始下载了,所以你的机器肯定会试图直接吃满你的路由,这就导致了其他人获得的路由器的时间片的数量被稀释了,因为现在路由器里`90%`都是你的包
* 这就像是我在`OS`中一直往死里开线程一样,本质上一直开线程可以用于掠夺其他进程的`CPU`时间片

* 所以,如果路由器性能不够强劲的话,就直接导致其他人的包得排到猴年马月才能被接收

* 所以我们迫切需要一种技术可以像`CPU`一样有一个优先级
* 那么分优先级也很简单,只需要把一个队列拆成两个就行了,`Low`代表不紧急的任务,`High`代表紧急的任务
![[Pasted image 20251008232313.png]]

* 下载东西的时候,走`Low`队列,游戏的时候,走`High`队列
* 当然,两者的效率可能也不太一样,我们假设`Low`的效率是`W`,`High`的效率是`2W`,那么,综合来看,`Low`队列会占用`1/3`的资源,而`High`会占用`2/3`的资源
* 那么,如果引入权重的概念,那么`Low`的权重应该是`1`,而`High`的权重则是`2`

* 那么,如果我们添加多个不同权重的队列呢?
![[Pasted image 20251008233258.png]]

* 那么,我们现在就拥有了一个多优先级的队列
* 一个队列的输出速度应该是这样计算的: `queue Ni 的输出速度 = N / 所有队列的权重相加 * R`
* 调度器会按轮一个一个检查每个队列,就像是`CPU`轮着服务进程一样
* 在每轮中,权重大的会多传不少,权重小的会少传很多,简单来说就是权重越大传得越多

* 那么,这里的输出速度是按包的数量来算的还是按照字节数来算的?
* 实际情况是,按照字节数来计算,如果按照包来计算的话,某些情况下其实会很亏,比方说多个高优先级的小包的优势体现不出来

* 那么,如果要按照字节数计算,那么肯定会有一种情况,某一轮输出时,一个包没有读完!
* 针对没有读完的包,我们要把它缓存起来,以便后续还可以把剩余部分拼接上
* 至于这个缓存,我们称作魔法队列
![[Pasted image 20251008234645.png]]

* 不过暂时的,我们的重点不是魔法队列,你只需要知道我们可以通过魔法队列来处理不完整包的输出,回到这个图
![[Pasted image 20251008234848.png]]

* 同时,会出现一个问题,一个不完整的包,什么时候会变得完整?这是我们值得去思考的,也是路由器应该提前思考的?
* 为什么路由器需要提前预测一个包在第几轮被完整读取了?

* 其实很简单,因为包不存在尾部标志位这一说,所以路由器才这么关注一个包什么时候被完整读取了,因为只要包被完整读取到了魔法队列中,这个包就已经被许可发送了!!

* 那么具体怎么计算呢?
* 其实很简单,我们假设一个包的头在第`S`轮被读取,这个包长`L`,该队列的权重是`W`,那么,这个包一定在末尾轮数`K = S + L / W`轮被读取走,那么意味着,在`S + L / W`,这个包被完整的读取走了
* 那么这也意味着,下一个包的开头,也就是下一个包的`S`已经被确定了,就是上一个包的`K`,那么,只要获得下一个包的`L`,就能直接推算出下一个包会在第几轮被完整传输完毕
* 至此,我们只需要一个递归,就可以一直推断下去!知道预测出所有已经缓存的包!

* 你肯定有疑惑,为什么这里可以直接用`L / W`就可以算出经过了多少轮

* 其实本质上,他计算的不是经过了多少轮的时间,而是在计算一个虚拟时间,所以,我们可以把权重直接看作是速率,因为这个速度中,`bit/time`中的`time`我们根本不在乎!只需要路由自己知道就好

* 那么,你肯定会想,如果一个包的前面没有任何包,该怎么计算时间?其实很简单,包头的读取的虚拟时间归零不就完了!!

* 那么,具体是怎么从这一个个队列中取走数据的呢?
* 路由器中会存在一个调度器的东西,这个东西会优先取剩余时间的那个,换句话说,如果一个包优先级够高,或者一个包足够小,那么他都有可能会成为调度器的选择!

* 那么,这意味着,本质上,调度器读取数据,其实是一个非常没有规律的事情,因为他其实本质上不是按照轮来计算的
* 那么这该怎么解释`K = S + L / W`是按照轮被读取走???

* 上面说的轮其实只是方便初学者理解的而已,实际上的时间计算根本不按轮来算,路由器自身其实会维护一个时间轴,每个包的每个部分都会直接被映射进这个时间轴中,一个包被缓存之后需要立马计算时间并且映射进时间轴中

* 以上的内容其实是`WFQ`的内容,有兴趣的话可以去网络上深入了解一下`WFQ`或者加权公平排队("weighted fair queueing")

* 那么我们长篇大论了这么多,其实就是在论证和学习两件事情,即:路由和交换机确实是有优先级算法的,我们学习了这种优先级算法的实现机制

* 那么回到最初的问题,我占用了路由的带宽,室友的网络延迟受到了较大影响
* 那么,问题来了,既然路由器有优先级算法,为什么室友的网络依旧受影响了??
* 其实原因很简单,因为一个包的优先级具体是多少,完全是由互联网厂商决定的,互联网厂商肯定要保证对于当下用户的服务,那么如果所有的互联网厂商全部都因为"保护用户的体验"而直接无脑把优先级拉到最高,那么此时优先级就完全没有任何意义了,之前学的内容也没有意义了,这里会直接退化成了普通队列的`FIFO`
* 我们称这种现象为`QoS`崩溃("Quality of Service",即服务质量)


##### 3.5.6 延迟保证

* 那么,之前我们有学到过延迟的计算公式:"总延迟" = "传输延迟"+"分组延迟"+"可能的排队延迟"

* 在这里面,"传输延迟"我们基本没法控制,因为它是物理限制,这个目前几乎没法突破
* 不过值得一提的是,在固定线路中,"传输延迟"+"分组延迟"基本是可以确定的,或者说是一个固定值
* 那么唯一不确定的因素就来自于"可能的排队延迟"
* 当然,不同转发设备的排队延迟肯定不太一样,所以我们需要一个方式,能够计算所有类型的转发设备的排队延迟
* 那么最简单的方式,我们假设现在有两个时间,`Ta`和`Tl`,如果在`Ta`时间下,输入端累计接收的数据量等于在`Tl`时间下输出端累计发送的数据量,那么我们可以称`Tl - Ta`可以是这个转发设备的延迟

* 其实原理很简单,我们把转发设备当作是一个视频播放器就行
* 之前我们有学过视频播放器其实会缓存一部分数据,然后才会播放
* 那么转发设备其实也是这种思想
* 转发设备也有缓存,然后他也会消耗数据,那么就和视频播放器的原理一模一样了
* 那么,我们怎么计算一个包在视频播放器中缓存了多久(这个包在缓存中经过了多少延迟)?
* 不就是"这个包被播放的时刻"-"这个包被接收的时刻"

* 为什么我们描述这个延迟的时候说的是"可以"是这个转发设备的延迟?
* 因为输入端的速率其实是很不固定的,所以我们如果要计算最大延迟,其实需要一个理想的输入端速率
* 那么,一个转发设备在某段时间内最多能接受多少流量?
* 这里我们有一个公式`A(t) = B + Rn * t`
* 其中,`B`是某个优先级的缓存大小,`Rn`表示第`n`优先级的输出速率,那么`Rn * t`就是在某个时间内该队列的累计输出量
* 那么,也就是说某时刻,该队列的累计输入量不允许大于`A(t)`,否则就会丢包
* 那么此时我们就得到了一个理想输入端累积量的图

![[Pasted image 20251010121207.png]]

* 这个理想输入端累积量不会一直延伸,如果队列中所有的包都已经离开,且没有任何包缓存,那么此时计算理想输入端累积量没有任何意义,直到某个时候有包进入了队列,此时才会重置理想输入端累积量
* 所以实际上应该是这样子的

![[Pasted image 20251013100321.png]]

* 所以你可以看到,理想输入端积累量会在队列中缓存了内容的时候重置
* 路由中专门为此做了一个协议,即资源预留协议,"Resource Reservation Protocol",简称`RSVP`

* 至此,我们只需要计算实际输出量(也有可能是理想输出量,某些设备可以计算这个的)减去理想输入积累量,就可以得到该转发设备的理论最大延迟

* 计算路径上所有的转发设备的理论最大延迟并相加,然后再加上传输延迟与转发延迟,就可以得到理论最大延迟,超过这个延迟值过多的包,我们都可以算作丢包


### 4 拥塞控制

* 那么很好,我们已经学到拥塞控制了,学完这个小节,你就已经学习完一半的`CS144`课程了,那么,本章我们将会了解拥塞控制的一些详细内容

#### 4.1 我们需要一个怎样的"拥塞控制"?

* 相信你应该很清楚,为什么网络需要有拥塞控制了,简单来说,如果网络没有拥塞控制,那么如果遇到传输瓶颈,那么可能将会造成上游传来的数据包丢失,这样就会浪费上游的网络带宽

* 在讨论一个实际的例子之前,我们需要做一个声明(这也是`CS144`课程中做的事情)

![[Pasted image 20251020105242.png]]

* 我们大概可以把拥塞控制分别放在4个粒度下: 
	1. 第一个图中,我们的粒度非常细,也就是我们需要拥塞控制非常灵敏
	2. 第二个图则是把粒度稍微放得更粗一点,这点粒度人类依旧比较难感受到,但是对于计算机来说则刚刚好,正好稍微比人类灵敏一点
	3. 第三个图则表示粒度比较粗的情况,常见于某天的时间段中,访问量突然增大,比如说下班回家之后,会有更多用户打开短视频平台
	4. 第四个图的粒度则极粗,常见于特殊节日,例如网购节日,游戏特卖什么的

* 对于第一种情况,如果我们要求拥塞控制在这么细的粒度下工作,那么会吃掉太多的性能,得不偿失
* 对于第三种情况,我如果此时做拥塞控制,那么灵敏度其实太低了,用户很容易感知到
* 而对于第二种情况则非常好,用户感知不到,也不会有特别高的性能开销
* 至于第四种情况,这种粒度下,从宏观来看也是有拥塞控制的,只不过这种拥塞控制一般是人为调控的,比如紧急增加并行路由数量这种

* 所以,这里我们讨论的拥塞控制,一般是第二种情况

* 那么,最简单的拥塞控制应该长成啥样?

![[Pasted image 20251020155828.png]]

* 如你所见,这种拥塞控制其实特别简单
* 对于设备A,B以及交换设备P来说,因为P的输出上限在`12 Mb/s`,所以设备A和B只有保持在各自`6 Mb/s`的输出上限才行,对于A,B和P来说,这种形式似乎可行

* 但如果对于P和Q来说,这就很难做了
* 因为Q不仅需要接收来自P的数据,还需要接收来自C和D的数据,但Q的输出效率依旧是`12 Mb/s`,那么如果只有D,那么我们将平分来自P和来自D的速度,那么对于P来说,他的实际输出数据其实已经坍缩成`6 Mb/s`了,D是`6 Mb/s`,对于A,B来说则会进一步坍缩成`3 Mb/s`,而我们希望A,B,C都能平分带宽变成`4 Mb/s`

* 如果引入一个输出效率更低的C,那么实际将会更难做,因为这种形式根本没法平衡各个设备的速率

* 并且,在这个例子中,如果A发送的效率是`12 Mb/s`那么就会造成至少`2/3`的数据被丢失,其实就会造成上游带宽做了无用功了,这是我们不希望看到的
* 更抽象的是,延迟也会奇高,因为`2/3`的包被丢失了

* 所以,我们需要的是一个相对更加公平的拥塞控制


#### 4.2 `max-min fair` (最大最小公平算法)

* 这是一种相对更加公平的算法
* 首先我们得看个例子来说明这个算法做了什么

![[Pasted image 20251020165318.png]]

* 在这个例子中,A,D的输出速率都是`12 Mb/s`,C的输出速率是`2 Mb/s`,那么结果是,A和D实际得到了`5 Mb/s`,C却能以`2 Mb/s`跑满

* 在`max-min fair`算法中,规定: 计算顺序必须按照设备输出速率的最小的那个逐渐递增,如果"一个设备的输出效率"小于"转发设备瓶颈效率 / 传输的设备数量",那么这个设备必须跑在满速率

* 剩下的设备则会平分剩余的带宽,除非仍然有"一个设备的输出效率"小于"转发设备瓶颈效率 / 传输的设备数量"的情况出现

* 也就是说,C的最大速率`2 Mb/s`小于平均速率`12 Mb/s / 3 = 4 Mb/s`,所以C必须跑满

* A和B的最大速率在`12 Mb/s`,大于平均速率`12 Mb/s / 3 = 4 Mb/s`,所以A和B必须平分剩下的`12 Mb/s - 2 Mb/s = 10 Mb/s`,所以A和B都是`5 Mb/s`

* 那么,会不会存在一种情况,有N个最大速率全部小于平均速率的设备,然后这些设备把所有的带宽全部吃干净导致最大速率大于平均速率的设备没法平分剩余的带宽了?

* 答案是一定不会存在这种情况,用数学方式解决这个问题会比较简单
* 我们假设小速率设备有N个,大速率设备有M个,总输出速率为`R`
* 那么在最坏的情况,所有小速率设备的瓶颈速率都等于`R / (N + M)`,那么所有小速率设备的输出总和也才`(N * R) / (N + M)`,大速率设备仍然有`(M * R) / (N + M)`的总带宽

* 也就是说,最坏的情况下,这个算法会退化成完全公平策略!

* 当然,实际上我们并不会直接使用这个算法,一般在实际中,我们会使用趋近于这个算法的其他算法

* 不过我们可以总结一下这个算法为我们带来了什么:
	1. 首先就是足够的灵活,一旦有新的流增加,那么就会重新平分,如果有流减少,那么其他流就会平分这个空缺的带宽
	2. 保证了带宽的始终繁忙,保证了带宽始终被吃满
	3. 这个算法是分布式的,不存在任何其它机器作为宏观调控
	4. 没有任何一个流的带宽增高会不让所有速度低于他的流的带宽降低(换句话说就是一个流的带宽增高一定会伴随着带宽低于他的流的带宽降低,当然这在这个算法中不被允许,因为它需要公平)

#### 4.3 `TCP`的拥塞控制

##### 4.3.1 转发设备与`max-min fair`

* 虽然我们说`max-min fair`是用于端的,但其实所有的跳也是`max-min fair`的
* 我们先来输出一个结论,还记得我们之前学过的`WFQ`(加权公平排队)吗?事实上,转发设备中的`WFQ`在理想情况基本上是一个接近`max-min fair`的算法

* 为什么?这里我们必须回顾一下`WFQ`
* `WFQ`为每个虚拟队列搞了一个叫做权重的东西,每个流能通过一个比例获得一个带宽大小,这使得每个流都能获得一个公平的带宽,这意味着他非常灵活,一旦有新的流,那么比例立刻改变,然后通过加权平分,一旦某个流没有包,那么比例也会改变,将这个无用带宽分给别的流

* 你会发现他给我们带来的特性和`max-min fair`其实非常相似,一样的非常灵活,一样的非常公平,一样的分布式,一样的保证了带宽始终被占满,更重要的,一样的"没有任何一个流的带宽增高会不让所有速度低于他的流的带宽降低"

* 甚至在最坏的点都是一样的,极端情况下会退化成完全公平策略

* 值得一提的是,你肯定觉得这个`WFQ`和`max-min fair`的关系比较奇怪,我们会在后面进行解释

##### 4.3.2 我们如何知道什么时候拥塞了?

* 从根本上控制拥塞,本质上需要通过控制发送方的输出速率来实现
* 但老实说端其实很难知道一条路径上有没有拥堵
* 所以我们需要一个算法或者说功能为我们描述什么地方拥堵了

###### 4.3.2.1 `ECN` (Explicit Congestion Notification)

* 这个算法其实很简单,发送方在发送完一个包之后,每个路由都有权利在这个包的某个位置写入某几个字节
* 那么这个包在走完"发送"这条路径之后,就会留下一串字节,这串字节描述了这条路径的拥堵情况,于是接收方回复ACK的时候,就会携带这串字节返回给发送方
* 于是发送方就能够知道中途哪个位置拥堵了

* PS:这个算法其实是用在`IP`协议上的

###### 4.3.2.2 `CWND` (Congestion Window, 拥塞窗口)

* 也可以叫做拥塞控制,拥塞避免等等

* 本质上这也不算是一个算法,他就是两个维护了一串字节的指针或者`index`这种,但是我们会在本小节讲一下为什么需要拥塞窗口

* 这个窗口能够告知拥塞情况的原因也很简单,下面我们来看看原理
* 首先,我们知道发送方并不会每次都发送一个包,他有可能会发送多个包
* 所以,势必会有一种情况,发送方发送了所有应该发送的包,他开始等待接收方回复的`ACK`
* 那么此时对于发送方而言,其实就已经浪费时间了

![[Pasted image 20251022190256.png]]

* 所以,有没有办法能够让发送方一直不停歇地发送?有的朋友有的
* 我们知道传输数据到网络也是需要时间的,比方说我把一个包放进网络花了整整`4ms`这种
* 一个包在网络中流动也是需要时间的,假设一个包在网络中需要跑`40ms`才可以到接收方,接收方回复的`ACK`跑到发送方也需要`40ms`
* 那么有意思地来了,如果发送方一次性发送`20`个包,那么他会在正好发送完最后一个包的时候正好接收到来自接收方的关于第一个包的`ACK`,此时发送方就可以接着发送下一个包了

![[Pasted image 20251022190855.png]]

* 于是我们发现一个有意思的现象,那就是如果我们不考虑拥塞问题,我们可以规划一个较大范围的包,并且按顺序发送,那么我们可能会找到一个平衡使得我能以最大效率发送所有的包,就像是刚刚的例子一样

* 但因为拥塞情况的存在,所以我们不能无脑把这个范围定死,网络的带宽是随时可能会变化的,所以我们需要一个东西维护这个范围,并且让他可以随时变大或者变小,如果网络带宽小就把范围变小一点,如果网络带宽大就把范围变大一点

* 这个东西就是拥塞窗口

* 和滑动窗口相对的,拥塞窗口其实是处在发送方,当发送方发送完一段数据之后,他不会把数据直接从内存中抹除,而是先放在拥塞窗口中

* 他用于控制发送方和接收方的数据传输中,允许在网络线路中跑的内容,换句话说就是描述网络中能够承载的数据量,如果阻塞了,接收方回复`ACK`说你有数据没到,那么意味着这个窗口太大了

##### 4.3.3 `AIMD` (additive-increase/multiplicative-decrease, 和性增长/乘性降低)

* 这是一个算法,这个算法会用在这里的缘由其实很简单,因为网络会阻塞,我们没法实现上一个小节说的那种理想的情况
* 换句话说,其实本质上网络完全不拥塞和全速传输其实是一件比较矛盾的事情
* 所以这个算法用于在尽可能保证网络通畅不拥塞的情况下还能够尽可能逼近上一个小节中说的例子

* `AIMD`规定:发送方每次成功传输并接受`ACK`之后,会把拥塞窗口增大`1`,如果某次的`ACK`显示没有正确送达,那么将拥塞窗口的大小直接砍半(也就是`* 1 / 2`)

![[Pasted image 20251022191829.png]]

* 所以实际看起来他是跳动的,并且是灵活的

* 而实际上,使用`AIMD`这个算法也是为了尽可能实现`max-min fair`
* 他也满足`max-min fair`要求的几个内容,灵活,尽可能吃满带宽,以及公平

* 这个算法和`CWND`被用在`TCP`上

##### 4.3.4 宏观来看

* 所以宏观来看,我们确实已经非常接近`max-min fair`了

* `AIMD`保证了端的`max-min fair`,而`WFQ`保证了跳的`max-min fair`
* 那么如果每个路径的每个机器都能保证`max-min fair`,那么在宏观上,整个网络就都是`max-min fair`的!

##### 4.3.5 总的来说

* 首先,如果要实现拥塞控制,这意味着我的从源头控制输出速率,否则依然可能会造成丢包,这意味着拥塞控制其实控制的是端而不是跳 

* 那么我现在知道的拥塞控制有两种方法: 
	1. 第一种: 发送方发送包之后,接收方回复一个`ACK`,那么如果中途某个地方发生拥堵,这一跳就在这个包中填入一串内容,表示这一跳堵了,然后接收方接受之后,把跳填入的这串内容拷贝到一个`ACK`包里头然后发回给发送方,此时发送方就会知道中途哪一跳堵了,但是这种方式其实比较麻烦,因为他需要每个跳进行配合,我们希望的是跳能够被动接受端的检测而不是跳主动输出检测信息,于是就有了第二种方式 
	2. 第二种: 我们知道,`TCP`协议中有一个叫做滑动窗口的东西,我们发现,一般情况下,发送方发送完一个窗口的包之后就会开始等待,知道`ACK`返回,有那么一种特殊情况,我们知道发送一个窗口(可能包含多个包)需要时间,每个包在物理线路和每一跳中的传输也需要时间,那么,如果"包在物理线路和每一跳中的传输需要的时间(包括往返)"正好等于"发送一个窗口(可能包含多个包)需要的时间",那么就会让发送方不间断地一直发送,因为中间没有等待间隔,每发送一个包都正好有一个`ACK`被发送方接收,于是,我们需要一个东西控制这一堆包,即拥塞窗口(`cwnd`) 

* 而拥塞窗口只是一个窗口,我们还需要一个算法来控制这个窗口,于是就有了`AIMD`(和性增长/乘性降低)算法用于控制拥塞窗口的行为,其实控制这个行为的方式也很简单,他只有两个法则: 
	1. 如果发送方接受接收方正确的`ACK`,那么发送方会把自己的拥塞窗口扩大`1` 
	2. 如果发送方接受接收方错误的`ACK`(也就是说接收方表示你有包丢失了),那么发送方就会把自己的拥塞窗口减半 

* 这是一个动态的窗口,意味着发送方的输出速率可能不是固定的,发送方以这种行为,控制"拥堵"与"尽可能发送更大的窗口"的平衡










