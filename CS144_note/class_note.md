### 1 简单了解网络

* 本小节,我们将简单了解一下,或者说见识一下网络究竟是什么,以及常见的思想

#### 1.1 网络通信的本质

* 在现代设计中,网络通信绝大多数都是以字节流进行通信的
* 网络通信本质上其实是多主机之间进行通信,每个主机拥有自己的独立IP地址(严格意义上不能这么形容,但是我们可以大概这么理解),通过这个独立的IP地址,每个接入网络的设备就可以通过这个IP访问其他设备

#### 1.2 通信方案举例

##### 1.2.1 `HTTP`

* 比方说网页页面的获取,就是使用`HTTP`协议进行的

* 假设我们需要获取一个网页,本质上就是向某个IP地址的主机发送一串字节,这个字节流全是以`ASCII`字符构成,所以这些内容完全是可读的

* 然后该主机会接收这串字节,并做检验,完全通过后就可以回传一串字节,表示允许获取内容,然后表示允许获取的字节后面将会紧接着网页页面文件的文本一并以字节流/二进制返回,写入到用户的浏览器或者说内存中,浏览器将这一大片文本(本质上是前端代码)渲染成实际的图形页面,这样用户就能访问网页了

##### 1.2.2 `BitTorrent`(`BT`协议)

* 这种通信方式也是一种常用的通信方式,迅雷本质上也是用这种方式,实现网络通信的
* 在`BitTorrent`协议中,本质上不存在严格意义上的"服务端",所有主机都作为客户端,更严格意义上说,所有主机都是客户端,也都是服务端
* 我们知道,从迅雷等等以`BitTorrent`协议为基础的软件中下载东西,都需要一个叫做磁力链接的东西,这个磁力链接会直接以`Hash`的方式直接和文件进行对应
* 然后我们会在互联网中寻找谁在线且有这个`Hash`,只要找到一个人有这个`Hash`,我们就会寻找该主机中,曾今还访问过哪些其他主机的`Hash`,这样,即便我们没有进行下载,我们也知道互联网中有谁还有这个文件(当然,前提是这些主机都在线)
* 接着就建立连接,开始在各个主机中下载文件
* 当然,这样有利也有弊,因为所有主机既是客户端又是服务端,那么意味着每台主机的上传量都不低
* 同时,并不是所有主机中,都完整存有这个文件,于是每个文件都会被切分成若干个`piece`,我们在与其他主机建立连接后,会交换主机拥有的`piece`信息
* 优先下载所有建立联系的主机中,最稀有的`piece`,尽可能保证该`piece`不会缺失
* 只要所有`piece`都存在,就一定能获取完整的文件,同时还能并行下载,提高下载速度

* 我们再说得更详细些
* 如果我们需要通过一个磁力链接/种子文件下载文件,这个链接/文件多数情况下是你通过`HTTP`下载网页或是下载文件得到的,而使用它,首先必须要经过一个有`tacker`的主机(一个主机可能会存放多个`tracker`),每个磁链链接或者说每个`Hash`会对应一个`tracker`,这个`tracker`不包含文件本身,所以说`tracker`其实不提供下载服务,但他能告诉用户,当前`tracker`中,有哪些用户在线
* 换句话说,这个磁力链接/种子文件告诉你的其实不是文件本身,也不是某个在线的用户地址,而是一个`tracker`的位置信息,通过`tracker`来找到其他用户
* 所以,宏观来看,这所有的用户共同构成了一个集群,而`tracker`扮演的角色仅仅只是记录用户在线情况,还有`Hash`对应哪部分文件,且帮助用户找资源,仅此而已
* 至于交换信息,则是集群中的用户该干的事情,他们使用双向的`byte`流进行数据交换,`tracker`本身不参与实际的数据交换

* 这也是为什么`BitTorrent`协议的核心思想是`P2P`(`peer to peer`)

* 值得注意的是,磁力链接其实仅记录`tracker`的位置,而种子文件则在此基础上,还会记录文件结构和`piece`情况等等
* 而用户第一次通过磁力链接或是种子文件与`tracker`建立联系时,也是通过`HTTP`协议进行沟通的,至于用户与用户之间沟通,则是用的`BitTorrent`的专有协议

* 所以,我们在使用诸如`qBittorrent`等工具的时候,可以通过一些渠道获取足够的`tracker`,以提升某个文件的下载速度和同时在线的用户量

##### 1.2.3 `Skype`独特的通信方式

* 在了解`skype`的通信机制之前,我们首先需要了解一个概念,即`NAT`
* `NAT`,本质上就是家里的路由器,路由器为你分配私有IP地址,且如果主机通过路由器接入互联网,那么外界的陌生主机无法主动获取私有主机的数据,因为会被`NAT`拦截
* 如果私有主机通过了`NAT`访问了外部设备,那么这个外部设备不再设为陌生设备,而是类似于进入`NAT`的白名单中,于是这个外部设备也能够获取私有主机的数据了,实现了既保证用户安全,又能实现数据交换的设想

* 但问题来了,这里我们要讨论一个问题,即"如果主机在`NAT`后,还能不能实现`P2P`?"
* 我们来看一个图
![[Pasted image 20250901171758.png]]

* 首先,`NAT`后的`client B`登录并上线`skype`,此时`client B`主动与`server`交流,于是`server`与`client B`允许交换资源
* 然后不在`NAT`后的`client A`也登录并上线`skype`,此时`client A`与`server`也可以交换资源
* 此时`client A`拨打电话给`client B`,因为`client B`在`NAT`后,所以`client A`不能直接给`client B`打电话,因为`NAT`认为`client A`是一个陌生设备
* 所以由已经不是陌生设备的`server`帮忙转发`call`给`client B`,此时`client B`会提示有人拨打电话给自己
* 如果`client B`接听了电话,此时`client B`会发送一个请求给`client A`,那么`client B`和`client A`的第一次有效沟通其实是由`client B`主动完成的
* 此时`client A`和`client B`就可以实现`P2P`式的数据交换了
* 所以你发现了吗,即便是`client B`在`NAT`后,也可以实现`P2P`式数据交换,根本解决思路来自于:由已经允许数据交换的`server`代理转发"其他设备希望数据交换的任务",从而让`NAT`后的设备主动访问这个其他设备
* 非常巧妙
* 我们称这种代理`server`为`Rendezvous Server`(会合服务器)

* 如果`client A`也在`NAT`后还可以实现`P2P`吗?
* 答案是不行,因为让`client B`发送请求给`client A`,它也收不到,会被拦截
* 所以在这种情况下,会退化成中继服务器转发操作,即`client`只与`server`交换数据,转发数据给其他`client`由`Relay Server`完成

#### 1.3 计网的四层结构以及"跳转"

* 在现代计算机网络的概念中,我们将整个网络分为四个层,当然,了解完这个小节之后,你仍然可能云里雾里,这是正常的,我们只是了解一下大纲而已

* 在此之前,我们首先需要了解一个概念
* 现代计算机网络中,绝大部分情况下,数据的传输绝对不是两点一线地传输的,它更像是一张网,数据在网上的节点不停跳转,直到到达目的地
* 就像是现代的物流网络一样,包裹的下一站不一定就是目的地,也可能是另一个中转站点,计算机中的网络也一样,下一跳不一定是目的地,但一定会接近目的地

![[Pasted image 20250901212352.png]]

* 具体分为以下四层

![[Pasted image 20250901211220.png]]

1. `Link`: 这一层也被称为链路层,这一层负责实际的传输任务,它不在乎究竟怎么传数据,仅负责传输功能本身
2. `Network`: 这一层也被称为网络层,这一层负责检测/指定传输目标,换句话说就是将`data`和目的地打包成一个`packet`,或者解包`packet`并分析目的地,换句话说,规定目的地的是`Network`,`Link`仅为`Network`提供发送服务,具体要发送到哪里取决于`Network`是怎样设定的
3. `Transport`: 也被称为传输层,这一层的设计初衷其实很简单,是为了弥补`Network`层的一些设计缺陷,计网功能的设计中,很多地方秉承着尽可能解耦的原则,换句话说,`Transport`层其实更像是`Network`层的插件(可以从这个角度看但不能严格这么理解),以实现更多复杂的功能,`Network`层其实不能保证传输一定不会失败,`Network`只能保证传输尽可能成功,如果拥塞非常严重,那么数据丢失也是板上钉钉的事情,所以需要`Transport`层做更多的功能,比方说检测到丢包就进行重传操作等等,这种重传操作的规范,我们称作`TCP`协议,比方说我们看视频的时候,为了保证每一个视频片段都能完整播放,就需要使用`TCP`协议保证`packet`能完整传输,当然也有不需要完整传输的情况,比方说视频电话,这种情况下,重传其实是没有任何意义的,因为视频电话讲究严格同步,不能延迟太高,所以不如直接让其丢失,反映在用户上则可能就是视频卡顿或者模糊等等,这种允许不保证`packet`完整传输的规范称为`UDP`协议
4. `Application`: 这一层也被称为应用层,用于规范数据如何交换,或者说作为数据交换的架构,比方说我们之前聊的`HTTP`协议和`Bittorrent`协议都在这一层,或者说这一层是用于规范数据交换策略的

* 值得一提的是,我们所说的路由器,也在这个传输网络中
* 路由器中只存在`Link`和`Network`这两层(这个地方其实不太准确,我们会进行补充),`Network`用于解包`packet`并计算下一跳的位置,而`Link`则负责传输,至于其他两层,路由器不需要也不在乎,因为路由器的本职工作是"路由",即找到下一跳位置并进行传输

![[Pasted image 20250901220412.png]]

* `Application`层负责宏观控制如何进行数据交换,然后向下,以指定的`Transport`协议进行数据传输,同样的,`Transport`也会向下指定`Network`进行对应的数据封装形成`packet`,并同样向下要求`Link`传输包到下一跳(事实上`Application`和`Transport`多半也是封装包的过程,只是封装的内容除了接收者,其他中继的硬件看见了也没有任何意义,如果中继硬件能够看到,反倒会使中继硬件维护/设计成本增加,也不够解耦,所以中继硬件被设计成非常傻瓜解耦的仅支持寻找地址+转发的模式)
* 所以说,对于数据的发送者而言,这四层其实就是一个层层打包的过程
* 而对于接收者而言,则就是层层解包的过程

* 在这里我们就有必要提一提"端到端"(end-to-end)和"跳到跳"(hop-to-hop)的概念了
* 端到端本质的服务对象其实是数据的发送者和接收者,即通信链路的两端,端到端思想本身不在乎中间经过了多少跳,而只在乎数据是否完整,数据符合什么应用层协议
* 跳到跳服务的对象则是所有作为跳的中继硬件,即通信链路属于中间的部分,该思想不在乎具体有没有丢失数据,也不在乎怎么处理数据,只负责定位+转发
* 所以说,本质上围绕端到端的是`Application`和`Transport`,而围绕跳到跳的则是`Network`和`Link`

* 我们视野拉开些看,目前我们所知道的协议

* `Application`: `HTTP`,`Bittorrent`等等
* `Transport`: `TCP`,`UDP`等等

* 我们知道,一个数据在`Network`被打包的时候会添加进目的地址(当然,其实还会添加发送地址),这个过程我们称为`IP`(Internet protocol)协议,`IP`协议不保证一定能不丢失数据,不保证顺序正确,也不保证数据不会重复,并且,整个`Network`就只有这一个协议,没有其他个性化的方案,因为仅使用这个方案就完全足够了,简单,统一,傻瓜,易用!

* 至于`Link`,也有很多其他的协议,比方说`4G`,`5G`,`WIFI`等等

* 所以宏观来看,整个自上而下的四层就像是一个漏斗一样,上下都可以走各式各样功能丰富的协议,但中间的`Network`一定只能走`IP`协议
* 这也是`IP`为什么这么重要的原因

#### 1.4 浅谈`IP`协议

* 在了解`IP`协议本身之前,我们先来谈谈`IP`协议的几个特点(虽然上一小节已经谈论过一部分了),以及这些特点为`IP`协议带来了什么

* 显著的是,`IP`协议是面向跳到跳的协议,`IP`协议只负责转发相关的内容,完全不负责数据中存储了什么,也不负责如何处理数据
* 并且,`IP`协议不可靠,`IP`不会保证一定能不丢失数据,不保证一定不会重复数据,他只能尽可能保证数据正确,除非阻塞严重,一旦拥塞严重,`IP`协议认为丢失该包也是正常操作,它不会做检查,也不会重发
* 同时也正因如此,我们常说路由器参照`IP`协议用于转发包,但实际上路由器也可能会因为设置错误而导致转发到不该转发的机器上(本质上,关于路由器如何知道该怎么转发这一点,路由器自身内部有一个转发表,用于判断应该往哪个方向转发,但这个表终归还是人类设计的,不可能不出错对吧),所以`IP`协议也不能保证转发一定成功

* 所以,如你所见,这个我们所称的"`IP`协议"似乎一点也不"协议",它一点也不复杂,甚至说有些懒惰,它啥也不检查,啥也不关心,只是自顾自地转发数据报,转发不了就丢弃
* 但正是因为足够简单,足够傻瓜,才能让其能变成全球通用的互联网协议,才能让其能遍布全球,轻而易举地变成"网络"
* 同时因为足够简单,所以对于网络中的中继硬件来说,其构造也会足够简单,也会更容易维护,更加容易进行升级,至于更多的功能,放到传输的两个端点去进行吧

* 当然,这里我们提到了数据报(datagram),我们需要对其做一些解释
* 我们在之前的小节中提到过,数据在发送之前,会经过四层打包,最开始在`application`,`datagram`仅由需要传输的数据构成,本质上就是一个字符串或者说二进制串,向`transport`打包后,字符串的头会被添加一串字符/数据,用于标示使用的什么`transport`协议,同样的,在`Network`层,也会添加一串字符/数据用于标示数据来源(`IPSA` "IP source address")和目的地(`IPDA` "IP destination address"),`Link`层也是如此,添加一串用于标示传输方式的字符/数据
* 我们称数据报自上而下四层打包,最后在链路层被打包为`frame`(帧)

* 同时,`IP`协议其实也不在乎`Link`层是怎样传输的,能传输就行,所以,CS144课程中提到,你甚至可以用信鸽作为传输介质hh

* 我们简单谈一谈`IP`协议的一些细节问题
* 我们知道,数据包在网络中传输,所以势必的,可能就会出现无限循环传输的情况,所以`IP`协议用一个字段描述还剩下多少次跳转机会,称为`TTL`(Time To Live),初始值为`64`/`128`/`...`,每次跳转就会`-1`,如果为`0`时还没有送达到,那么这个`data packet`(数据包)就会被丢弃
* 同时,`IP`协议也会尽可能保证`data packet`被正确路由,为此`IP`协议再次添加了一个字段用于简单校验
* `IP`协议现在有两种,一种是`32 bit`的`IPV4`,另一种是`128 bit`的`IPV6`,因为网络发展非常快,所以现在,`IPV4`地址已经快要用完了,目前更多人都在转移到`IPV6`
* 当然,`IP`协议也不是不可扩展功能的,它也留有了一定字段允许扩展其功能,只是几乎没有人会这么干就是了

#### 1.5 简单看看网络中的"包"

* 如你所见,在上一小节中我们提到了很多类似于"包"的专有名词,我觉得有必要了解一下这些名词的区别,否则看懂上一节其实会相对困难一点点

1. `message`: 报文,这是我们最原始的数据,是最初的还没有被网络部分做任何打包的数据,可能由字符流或者二进制流构成,对于目标主机的对应进程而言,它是完全可读的
2. `datagram`: 数据报,对于`Transport`和`Network`这两层而言,`datagram`是基本传输单位,当然我们只是叫他这个名字而已,实际运用还是很简单的,所以根据协议类型,我们可以在`Transport`中分为`UDP datagram`之类的(严格来说没有`TCP datagram`),然后向下被打包成`IP datagram`
3. `frame`: 帧,这是`Link`传输的基本单位,由`datagram`打包而成
4. `data packet`: 数据包,这其实是一个泛称,用来指所有在网络中传输的东西

#### 1.6 包是怎样传输的

* 我们知道,`data packet`会从某个主机发送给另一个主机,当然这个`data packet`可能多半是一个`frame`,因为`frame`是`Link`层的基本传输单位

* 当我们将其传输到一个路由中,路由会将其解包(本质上其实不算是解包,而是读某一段固定区间),然后路由会取出其中的`IPDA`,并查一个叫路由表的东西

* 这个表并不会记录完整的`IP`地址,而是记录一个相对模糊的方向,类似于这样

|类型|目标链路|
| :---: | :---: |
| default | Link0 |
| 类型1 | Link1 |
| 类型2 | Link2 |
| 类型3 | Link3 |
| 类型4 | Link4 |
| 类型5 | Link5 |

* 然后路由器会根据`IP`,找到最匹配的类型,然后发送给对应的下一跳或者对应的目标链路
* 但是,总会有完全不符合所有匹配类型的情况
* 此时,路由器会将其匹配到默认路由,也就是`default`,会将其发送给更大的网络以期望其能够正确匹配目标链路

* 我们就拿CS144课程的例子来说

* 一个`data packet`从学校机房中发出,他会经过机房的路由,路由中可能记录了学校内的部分其他路由,比方说餐厅的路由或者是图书馆的路由
* 如果我的目标就是学校内的其他设备,那我可以直接使用路由表中设定的类型,并下一跳到餐厅或者图书馆之类的路由,再由它们进行直接转达

* 但如果我的目标地址不是学校中的设备,且路由表中找不到任何能够匹配的类型,那么下一跳就会走默认路由,可能会发送给运营商的路由/数据中心的路由以期望在下一跳中能获取到更全面的路由表

#### 1.7 `TCP`协议在数据传输中的作用

* 在前面几个小节中,我们已经了解过了,`TCP`是一种可靠字节流的传输协议,底层的`IP`协议为其提供服务
* 你可能在学习或者一些科技向视频中有了解过,构建一个`TCP`传输"通道"之前,需要进行三次握手
* 就类似于这样：
	1. 客户端发送`SYN`(synchronize)标志位给服务器,表示我想和你建立连接
	2. 服务器发送`SYN`标志位和`ACK`(acknowledge)标志位回客户端,表示我也想和你建立连接,并且我已经准备好了
	3. 客户端发送`ACK`标志位给服务器,表示我也准备好了
* 至此,客户端和服务端就建立了可靠的`TCP`连接(当然,`TCP`的"可靠"不全部源自于三次握手,三次握手只是保障可靠的重要条件之一)

* 另一个问题,我们需要搞清楚"端口"(`port`)
* 我们已经知道,我们可以通过一个`IP`地址找到一个主机,但主机上可能跑着很多服务,我们怎么知道要访问哪个服务呢?
* 于是我们需要端口帮我们进行区分
* 同一个`IP`下,不同的`Transport`协议的不同端口可能对应着的不同的服务,这里我们仅拿`TCP`进行举例
* 比方说在`80`号端口,就是默认的`HTTP`服务的端口,又或者说我访问油管,其服务的默认端口可能是`443`这种

* 换句话说,我们需要获取到一个对应的服务,应该使用`IP`和`port`的组合,才能允许获取对应服务,至于具体是怎么获取到这个`IP`和`port`的,我们暂时不需要特别清楚,但可以提的是,这两个东西是通过解析域名得到的


#### 1.8 分组交换(Packet switching)

* 如你所见,如果我们直翻"Packet switching",那么应该叫包交换,但实际上这个词和中文语境下的"交换"没有啥关系,同时,"包"这个词在这里也有些出入
* 首先输出一个结论
	1. 在这个思想中,"包"是手段,"分组"是目的
	2. 在计算机网络的语境中,这里的"交换"其实指数据的转发

* 分组交换是现代计算机网络的设计思想
* 在更加早期的数据传输技术中,人们普遍是用电话线进行数据传输,换句话说就是打电话
* 电话线优势很明显,就是一旦建立连接,就几乎不存在数据中断,但缺点也很明显,这条电话线会被两个通信端点独占,其他任何人都没法共享这个电话线,那么,电话线这个资源就是不可分割的,即便你打电话的时候一句话都不说,电话线也会被你一直占用,这就导致资源的浪费,这种浪费在当今网络是非常致命的
* 试想一下,假设路由器的网络带宽也是一个不可分割资源,那么一旦你的室友在下载电影或者下载游戏,那么你的电脑就访问不到任何网络,只能等待你的室友断开网络连接
* 所以我们需要一种方式,能让信号的传输介质变得可共享
* 于是,分组交换思想就应运而生了
* 我们将数据切割成小块,然后打包,发送
* 于是,就会有一个现象,当你空闲的时候,路由就会停止向我转发数据包,如果此时有其他人需要路由转发数据包,那么路由就可以轻松帮助他转发
* 同时,如果两个人同时需要路由,那么路由器也会尽可能公平,他会尽可能保证公平地转发数据包,比方说当前`ms`可能向我转发数据包,那么下一`ms`,就会向共享路由的另一个人转发数据包,再下一次又是向我转发数据包
* 所以你发现了吗,路由此时在人类眼里看来,就像是一个可以分配的资源一样,或者说就像是蛋糕一样,可以被切分给所有共享者,这种将单一资源以概率或统计的方式在多个用户中共享的思想被称为"统计复用"(Statistic Multiplex)
* 我们换一个更加简单的场景,我们将路由器想象成`CPU`一样的资源,那么如果实现多线程,多线程会平分这个`CPU`资源,所以,核心思想其实一直都没有变,都是为了尽可能减少资源浪费,尽可能始终让设备一直高效运行,从而提高整体的运行效率
* 拆分成包的另一个优势是,我们在端点,不需要在乎组成一个文件的所有包,都是怎样在中途转发过来,换句话说,我们不需要在乎各个包在哪条路径上转发的,甚至不需要在乎包是否按顺序到达,只需要在端点解包并将打散的数据重排就行(重排是`Transport`层协议关心的事情)
* 并且,哪怕两端主机已经建立了TCP链接,实际数据包在中途的传输中,也不会按照既定线路,而可能会分发到多个路由,最后汇总到目标地址

* 来自维基百科:
![[Packet_Switching.gif]]

* 并且,`IP`协议就是严格按照该思想设计的
* 这使得每一跳的逻辑都很简单,路由也可以很简单,但却可以在底层这么简单的情况下构建成一个庞大,复杂,却又安全的网络

* 于是你会发现很有趣的事实,就是网络中可能会存在多个数据包并行地向你传输,就像是千万滴水汇聚的河流一样,我们称这种通信中的数据包集合为一种"流"(flow)


#### 1.9 分层(Layering)

* 那么,简单输出一个结论/事实,"分层思想"在现代程序设计亦或是计算机设计中,绝对有着不可或缺的作用,你能看到数不胜数的程序基于分层思想进行设计,我们简单打个比方

![[image-7.png]]

* 如你所见,这是`Linux`的系统层级
* 如果你深入了解过`Linux`,那么一定很熟悉这个东西
* 分层设计思想,对于开发者亦或是用户来说,都是极为重要的思想
* 我们聊聊CS144中的例子
* 假设我想邮寄一本书给朋友,那么势必会通过以下几个步骤:
	1. 将书打包并贴好发件地址和收件地址
	2. 将书投放进邮筒,书会在邮筒中等待邮递员
	3. 邮递员取到书,将书给到我附近的邮件中转站
	4. 中转站会通过各种方式发往朋友附近的邮件中转站
	5. 朋友附近的邮件中转站则会派邮递员向朋友住址的邮箱投递邮件
	6. 邮件会在邮箱中等待直到,朋友拿到邮件
	7. 朋友确认邮件无误后进行拆包
	8. 朋友获得这本书

* 于是你会发现一个很有意思的事情
* 我们在发邮件的过程中,所有组成部分只需要干好自己的活就行,我们无需关心底层究竟是怎样运作的

* 我们放在网络中,就是四层分层,放在`OS`中,就是图中展示的这六层

* 另一个有趣的事实是,一旦某个组件需要进行更新,那么其余所有的层其实都不需要变化,所以分层能让功能之间解耦
* 但同时也有缺点,你会发现如果有了分层,虽然对于用户而言,隐藏了绝大部分的底层信息,对用户而言降低了复杂性与学习成本,但实际上这样做会极大地损失灵活性,这里我们聊聊CS144课程的另一个例子

* 如果你使用过`Python`或者说`Java`之类的语言,你会发现很多接口都全部封装好了,所有的底层细节用户都不必了解,用户只需要知道怎么使用顶层接口就行了
* 但C语言则完全不一样,你甚至可以在`.c`文件中穿插汇编语言,因为比方说`Linux`的内核代码中,就会有部分代码是用汇编写的,因为C语言允许你更灵活地使用一些功能,这就使得C语言的灵活性非常高,理论上你可以用C语言手搓一个C++,亦或是Python,但相对的,很多东西都要手动造轮子,所有的底层细节都需要我去注意,这就导致开发效率低,学习成本直线上升
* 换句话说就是过渡的封装会降低复杂性,降低学习成本,但同时灵活性也会大大降低

* 我之前和一个很厉害的后端工程师聊过,他说做后端的最高境界,就是能管理好项目的所有后端服务以及做这些服务的人,他说服务和服务之间有着很复杂的依赖关系,这种将项目拆分成各个服务,并进行层层依赖,本质上也是分层思想的具体体现


#### 1.10 封装(Encapsulation)

* 在网络中,封装也是一种常见思想
* 这里我们可以说得简单一些,因为在学习语言的过程中,我们或多或少学习过该思想

* 我们知道,一个`massage`,或者说数据,会从`Application`层层封装到`Link`,就像是这样
![[Pasted image 20250905110009.png]]

* 因为有这样的封装,所以每到一个设备中,该设备就只需要访问自己该访问的部分,就像是路由器,它只需要访问在`Network`和`Link`封装的头和尾,其他关于`massage`或者是其他层的细节不需要知道,依旧是解耦的思想,简单傻瓜易维护,但是不灵活
![[Pasted image 20250905110022.png]]

* 这里我们可以了解一个技术,当然这个技术的名字我们肯定是知道的,但具体做了什么,我们曾经可能从来没有了解过,这里我们借用这个技术来感受一下封装的优势
* 假设我们想在外部网络访问公司内网的服务器,我们可以在公司放一个既接通了外部网络,又连接公司内网的中继服务器
* 我们发送一个这样的包给中继服务器
![[Pasted image 20250905111735.png]]

* 对于中继服务器而言,他不知道具体要转发什么内容,他只知道接收的这个`packet`的`massage`中,存放了一个完整的`packet`,他要将这个"内部"`packet`解析一下,然后转发到内部网络
* 这种技术叫做"虚拟专用网络隧道"(Virtual Private Network,也就是我们知道的`VPN`技术)

#### 1.11 `IPv4`地址

* 相信你一定在某些电子游戏中遇见过要用`IP`地址访问某个服务器的情况,当然,你肯定知道这个`IP`地址代表着某一台服务器,不同服务器的地址是不一样的,而本小节将会详细解读一下`IPv4`地址的构成

* `IPv4`地址是由`32`个`bit`构成的一串数字,我们看`IPv4`地址的时候要将其按`8bit`拆分成4各部分看,即`a.b.c.d`的形式
* 这意味着一个`IP`地址最大可以是`255.255.255.255`,也可以是`0.0.0.0`

* 比方说`192.168.0.100`,`25.66.10.1`,`172.45.0.111`,这些都是一个`IPv4`地址

* 另一个值得要注意的东西叫子网掩码,他和我们在用的`IP`有很大的联系
* 我们输入以下命令会返回一堆东西,我们可以慢慢看(为了服务器的安全,我还是得打一下码的)
```shell
oldking@iZwz9b2bj2gor4d8h3rlx0Z:~/CS144-2024-winter-backup$ ifconfig
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 1o.x.x.x  netmask 255.x.x.x  broadcast 1x.x.x.x
        inet6 x::x:x:x:x  prefixlen x  scopeid 0x20<link>
        ether x:x:x:x:x:x  txqueuelen 1000  (Ethernet)
        RX packets 35883058  bytes 6550064423 (6.5 GB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 34958182  bytes 8303867503 (8.3 GB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```

* 我这个阿里云服务器有两个地址,一个`IPv4`,一个`IPv6`
* 其中`1o.x.x.x`就是`IPv4`地址,`255.x.x.x`则是子网掩码

* 子网掩码这个东西怎么用?我来实例一下
* 假设我的子网掩码是`255.255.255.0`,假设我的设备的`IPv4`地址是`192.168.1.100`,我舍友的设备的`IPv4`地址是`192.168.1.201`
* 那么将我的设备`IPv4`地址按位与(`&`)上子网掩码得到`192.168.1.0`,我室友的`IPv4`地址做同样操作,也会得到`192.168.1.0`,那么证明我们两台设备的在同一个位置下,则表示我们两个设备可以不经过路由器,可以直接进行连接通信

* 事实上,路由器在做转发的时候,也是会参考子网掩码的,他会优先选择可直连的设备转发

* 关于`IP`分配问题
* 最初,`IPv4`地址的分配其实规定得很死,`IPv4`地址被分为三个类别,其中具体的值被划分成了`Network`部分和`Host`部分

* 该图截自CS144课程
![[Pasted image 20250908103039.png]]

* `Network`部分表示所处在多大的网段,或者说处于同一区域下的`Host`有多少
* `Host`部分则表示具体的主机
* 换句话说,就是`Network`位数少就意味着`Host`位数多,表示该网段下的设备很多
* 换句话说,子网掩码就是一个"边界",用于划分哪个部分是`Network`,哪个部分是`Host`

* 关于网段,我们可以这样理解
* 我们知道公网`IP`其实是非常有限的,所以我们做不到为所有人都分配一个公网`IP`,那么该怎么让人人都用上网络呢?
* 于是我们可以在公网下搞一个私有地址,比方说我的小区的某个路由的公网`IPv4`地址是`205.104.36.5`,其中`205.104.36`表示`Network`部分,`.5`表示`Host`部分
* 表示这个设备是`205.104.36.0`这个区间中的第`5`个设备
* 但实际我们为每栋用户分配的却不是这个公网`IP`,因为公网`IP`有限,所以我们为整个小区分配了一个私有地址,这个私有地址`192.168.0.0`(`Network`部分),只有小区自己内部可以使用
* 所有的用户与公网的交流,全部通过这个拥有公网`IP`的路由器代为转发

* 所以,在这个场景中,`205.104.36.0`是一个"公有网段",而`192.168.0.0`则是一个私有的网段

* 但你一定也发现了一个问题,如果小区的网段是`205.104.36.0`,但我的小区只有`5`个路由,这不就导致有两百多个`Host`被浪费掉了吗?答案是,是的,全部被浪费掉了!

* 所以,当人们发现`IPv4`开始不太够用的时候,提出了一个新的方案,叫做`CIDR`(无类别域间路由, Classless Inter-Domain Routing)

* 这个方案让`Network`的长度可以不受原来的三种类型约束,而是可以自定义其长度,我们回到小区的例子来看看他是怎样做的
* 原先,小区分配的是`205.104.36.0`,表示该网段下可以分配大约两百多个公网`IP`设备,但现在我们知道该小区只有`5`个公网用的路由,于是我可以改成分配成`205.104.36.160/27`,这意味着这个网段可以分配`2^(32-27) = 32`个公网`IPv4`地址,换句话说,这个`/27`表示前`27`位属于`Network`,后面的`5`位表示`Host`地址,同时`/27`也代表着子网掩码,那第`5`个路由的`IP`可以表示为`205.104.36.5/27`

* 那么最后,我们来规范一下,类似于`205.104.36.0`这种,他一般只是被称为一个`IPv4`地址,但语义不明确,而类似于`205.104.36.0/24`这种,称为`CIDR`网络前缀

#### 1.12 最长前缀匹配(Longest Prefix Match, `LPM`)

* 前段时间我们聊过路由转发`packet`需要查路由表,寻找最匹配的路径进行转发,这里我们就来补全这个空缺,来深入聊一聊路由是如何做最匹配路径的寻找的

* 我们先来看看路由表的具体构造如何

| dest | link |
| :---: | :---: |
| 0.0.0.0/0 (default) | 1 |
| 172.10.0.0/16 | 1 |
| 172.10.8.0/24 | 2 |
| 26.64.0.0/16 | 2 |
| 79.0.0.0/8 | 3 |
| 13.230.9.0/24 | 2 |
| 174.25.0.0/16 | 4 |

* 其中,所有的`0`其实都表示此处是一个通配符,拿到的目标`IP`地址和该表中的地址后,依照子网掩码位数,比较最前位就可以找到最匹配的路径,如果没有最匹配的,就会走默认路由

* 我们举个例子,假设现在路由器拿到了一个`172.10.8.2`的包并需要将其转发
* 其中:
	1. 第一个地址不取任何数字,因为他是默认路由,一定是和需要转发的地址匹配的,然后做好记录,表示这个路径匹配过了
	2. 第二个地址取前`16`位和需要转发地址的前`16`位进行比较,发现也符合,那也把这个路径记录下来
	3. 第三个地址取前`24`位和需要转发地址的前`24`位进行比较,发现也符合,那也把这个路径记录下来
	4. 剩下的如法炮制...

* 于是最后发现,所有记录的`3`个匹配项中,`172.10.8.0/24`这个地址存在`24`位与需转发地址匹配,那么就会走`link 2`进行转发

#### 1.13 地址解析协议(Address Resolution Protocol, `ARP`)

* 在了解`ARP`之前,我们首先还需要了解一些前置知识

* 首先,`IP`地址是一个`Network`层地址,但实际传输却是在`Link`层传输,而`Link`层其实无权访问`Network`层的任何内容,所以势必的,`Link`层也需要有自己的"地址",这个地址我们称为`MAC`地址
* 另一个问题,公网`IP`地址其实不是物理意义上存在的,而是"受分配的",是虚拟的一个地址(只有某些互联网服务才可以申请某个固定的公网`IP`,造成这种受分配情况的原因还是因为`IPv4`地址太过于稀缺了),而`MAC`地址却是一个物理意义上存在的地址,是网卡出厂的时候就烧录进网卡的,所以理论上这个地址才是全球唯一的网卡地址
* 所以实际上,我们会将`datagram`在`Link`层中打包成帧,然后实际在`Link`层中转发的都是帧

* 另一个有意思的点是,一个路由器可以有多个网卡,并且可以有多个`IP`地址
* 首先我们要知道,因为路由器本质是在做转发操作,而一个网卡只能关联他所在的网段,所以如果我要从一个网段发送内容到路由器关联的另一个网段,就必须要用两个网卡

* 那么,以上是前置知识,现在我们将会举一个来自CS144的例子

1. A: 一台主机,`IP`地址为`192.168.10.100`,`mac`地址(用于辨认哪个网卡,属于链路层地址)为`AA:AA:AA:AA:AA:AA`
2. B: 一台主机,`IP`地址为`172.100.10.100`,`mac`地址(用于辨认哪个网卡,属于链路层地址)为`BB:BB:BB:BB:BB:BB` 
3. C: 一个网关,拥有两张网卡
	1. 一张网卡连接着A,该网卡的`IP`地址为`192.168.10.101`,mac地址为`CC:CC:CC:CC:CC:CC`
	2. 另一张网卡连着B,该网卡的地址为`172.100.10.101`,mac地址为`DD:DD:DD:DD:DD:DD`
	
* 那么,如果A需要发包给B,首先会参考子网掩码(A的子网掩码是`255.255.255.0`),但显然这里B不会和A在同一个网段下,那么此时A开始封装`packet`,源IP地址是A自己的,源`mac`地址也是A自己的,但目标IP地址是B的`IP`地址,目标`mac`地址是网关的`CC:CC:CC:CC:CC:CC` 发送帧给网关之后,网关会解包,并封装自己的`mac`地址(`DD:DD:DD:DD:DD:DD`)作为源`mac`地址放进帧的链路层中,还会封装B的`mac`地址作为目标`mac`地址放进帧的链路层中

* 这里这个网关其实就是路由啦

* 那么此时有一个很重要的问题出现了,A怎么知道网关的`mac`地址?当然不知道!所以我们需要`ARP`协议帮助我们获取网关的`mac`地址
* 此时,A会在当前网段中广播它所有能广播到的设备,向这些设备提问:"谁是`192.168.10.101`?告诉我你的`mac`地址!",在广播的时候,他会顺便把自己的`mac`地址附带进去,方便接收到的设备回传,那么C收到这个广播之后就会发回(非广播形式,或者说"私聊")它的`mac`地址给A,此时A就可以正确封装`packet`了,然后发送到C手上,然后C也做同样的事情获取B的`mac`地址,然后发包给B

* 注意,这里是在广播所有能广播到的当前网段设备,这意味着?!
* 我们是不是可以欺骗这个A,让A以为我们是一个路由器,而实际上我们是另外一台主机?!
* 当然可以!
* A中将会维护一张缓存表,映射C的`IP`和`mac`地址,只要在还没有实现映射的时候,抢在网关应答之前应答A,并把自己的`mac`地址当作一个网关`mac`地址发回给A,那么他就会把这个伪装的网关真的当作一个路由发包
* 恭喜你学会了`ARP`欺骗

* 现在我们来聊一聊一个`ARP`包的组成
* 如你所见,这个包由以下几个部分组成(虽然这个图看起来很立体,不说实际传输的时候却是一个连续的字符串)
![[Pasted image 20250909120836.png]]

* 解释:
	1. `Hardware`: 表示链路层协议类型
	2. `Protocol`: 表示网络层协议类型
	3. `Hardware Length`: 表示链路层协议的长度
	4. `Protocol Length`: 表示网络层协议的类型
	5. `Opcode`: 设置代码,表示该包的属性,是请求(`1`),还是发回(`2`)
	6. `Src Hardware Address`: 发送方链路层地址 
	7. `Src Protocol Address`: 发送方网络层地址
	8. `Dst Hardware Address`: 接收方链路层地址
	9. `Dst Protocol Address`: 接收方网络层地址

* 回到例子
* A请求的时候应该是这样的:
	1. `Hardware`: `0x 00 01` (表示以太网协议)
	2. `Protocol`: `0x 08 00` (表示`IP`协议)
	3. `Hardware Length`: `0x 06` (表示链路层协议有`6 Bytes`)
	4. `Protocol Length`: `0x 04` (表示网络层协议有`4 Bytes`)
	5. `Opcode`: `0x 01` (表示请求)
	6. `Src Hardware Address`: `0x AA AA AA AA AA AA` (源链路层地址)
	7. `Src Protocol Address`: `0x C0 A8 0A 64` (源网络层地址)
	8. `Dst Hardware Address`: `0x 00 00 00 00 00 00` (目标链路层地址,因为这里是请求地址,所以地址还不知道,所以填空)
	9. `Dst Protocol Address`: `0x C0 A8 0A 65` (目标网络层地址)

* 实际发送的时候,还会封装成一个以太网帧进行发送,因为广播行为是封装在以太网帧中的,所以实际发送的时候是这样

* 我们还得简单看看以太网帧是怎样封装的
![[Pasted image 20250909124206.png]]

* 所以实际发包的时候是这样的:
	1. `Dst Mac Address`: `0x FF FF FF FF FF FF` (全`F`表示广播)
	2. `Src Mac Address`: `0x AA AA AA AA AA AA`
	3. `Ether Type`: `0x 08 06` (表示发的是`ARP`协议的包)
	4. `Payload`: `...`(`48 bytes`,这里面放的是`ARP`协议的包)
	5. `FCS`: 一个校验码,根据算法生成的,用于检错,我们现阶段不用太在乎里面装的什么 

* C发回以太网帧的时候应该是这样的:
	1. `Dst Mac Address`: `0x AA AA AA AA AA AA`
	2. `Src Mac Address`: `0x CC CC CC CC CC CC`
	3. `Ether Type`: `0x 08 06`
	4. `Payload`:
		1. `Hardware`: `0x 00 01` (表示以太网协议)
		2. `Protocol`: `0x 08 00` (表示`IP`协议)
		3. `Hardware Length`: `0x 06` (表示链路层协议有`6 Bytes`)
		4. `Protocol Length`: `0x 04` (表示网络层协议有`4 Bytes`)
		5. `Opcode`: `0x 02` (表示发回)
		6. `Src Hardware Address`: `0x CC CC CC CC CC CC` (源链路层地址)
		7. `Src Protocol Address`: `0x C0 A8 0A 65` (源网络层地址)
		8. `Dst Hardware Address`: `0x AA AA AA AA AA AA` (目标链路层地址,因为这里是请求地址,所以地址还不知道,所以填空)
		9. `Dst Protocol Address`: `0x C0 A8 0A 64` (目标网络层地址)
	5. `FCS`: 现阶段不在乎 


### 2 `Transport`层

* 在本小节中,我们将会了解`Transport`层中各个协议的作用以及结构

#### 2.1 `TCP`

##### 2.1.1 `TCP`协议的作用

* 在前面的章节中,我们提到过`TCP`协议为应用层服务,绝大多数`Application`层协议都需要`TCP`协议的服务,因为其能够在一定程度上保证数据一定送达,不会丢失数据,也不会顺序错乱

* 同时,网络的设计使得`TCP`是端到端的,那么意味着没人会在某一跳读你`TCP`相关的内容,`TCP`只关心发送方和目标主机的交流,不关心中间是如何跳的

* 同时正因为`TCP`协议是端到端的,所以它必须保证传输的数据一定是有序的,所以所有以`TCP`发送的,分散的,乱序的包,都会再经过一次目标主机的`TCP`协议,他负责将这些乱数据重组成`Application`层读得懂的内容

* 同时,本质上`TCP`不管在发送方和接收方来看,都是一个字节流,所以本质上在发送方,就是分割字节流再打包发送,而在接收方,本质就是解包后重组字节流,这也是为什么我们可以像读写文件一样读写一个`TCP Socket`,因为它和内存里的字节流没啥区别,只是多了几个校验,重传,重组等等几个步骤,而这些步骤都是`TCP`需要干的


##### 2.1.2 `TCP`协议的封装

* 和所有`Transport`协议一样,`TCP`协议需要封装来自`Application`的数据,然后形成一个`TCP Segment`,即`TCP`段
* 然后交由`Network`封装`IP Datagram`
* 最后交由`Link`封装对应协议的`Frame`

##### 2.1.3 建立连接与断开连接

* 建立连接的过程我们之前已经了解过了,即三次握手,这里我们回顾一下

* 如果A要和B建立连接:
	1. 首先A会发送一个`SYN`给B表示请求同步
	2. 然后B会发回`ACK`给A表示同意同步,并附带`SYN`给A表示请求同步
	3. 然后A会发回`ACK`给A表示同意同步

* 至此,两台主机已经建立了可靠的`TCP`连接了

* 那么如何断开连接呢?

* 如果A请求和B断开连接:
	1. 首先A会发送一个`FIN`给B表示`finish`,表示A要准备断开链接了
	2. 此时B如果还有数据没有传输完毕,就会可能会发回一部分数据,末尾会携带一个`ACK`,表示我同意断开连接,但是我的数据还没有传输完毕,要等待一会儿
	3. 当B如果完成传输了,那么就会发回一个`FIN`给A,表示我也完事儿了,可以断开连接了
	4. A会发回一个`ACK`给B表示同意断开连接

* 至此,这两台主机就断开连接了
* 这就是我们所说的"四次挥手"

* 那么好,如果B在进行第二次挥手的时候,恶意地不发回`ACK`,此时怎么办,难道A会无限地等待下去吗?
* 当然不会,`TCP`设计了超时机制,如果B不发回`ACK`,A就会持续地发送`FIN`,到达一定次数之后,如果B还是不做回应,那么A就会强制与B断开连接

##### 2.1.4 尽可能保证数据正确送达

* 注意,虽然`TCP`协议能在`IP`协议的基础上"确保"能够送达,但这种"确保"不是一定会送达,比方说难道网络断开连接了也能送达吗,显然不可能
* 所以`TCP`的"确保"送达更像是一种兜底机制,如果连`TCP`都没法送达了,那估计换其他的协议估计也不太行
* 所以换句话说,没人会愿意自己的数据不被送达,所以在`IP`协议这里就已经在尽最大可能让数据送达了,至于`TCP`更像是一种添加了重排的兜底机制,`IP`协议尽最大可能送达,但自己却不会做绝大多数的完整性检查等等,所以`TCP`帮助数据在两端做完整性检查,做重发,做重排,以保证传输过程中不会因为一些非人为错误导致数据混乱或者发送失败,但归根结底底层还是用的`IP`协议,所以连`TCP`其实也是没法保证"一定"能够送达的

* 现在我们来谈谈`TCP`是怎样做到尽可能保证数据正确送达的:
	1. "应答机制":当一个`packet`被接收之后,目标主机应该发回一个`ACK`来告诉发送方已经正确接收了,不需要重发
	2. "校验和"(checknum):它是一串数字,用于送达之后校验数据是否正确,确保不会因为某一跳导致数据缺失了一部分
	3. "序列号"(Sequence number):之前我们提到过,本质上送达的是字节流,所以本质上就是个数组,所以我们需要记录每个数据段在这个数组中最开始的下标,以方便我们送达之后恢复成字节流,同时,如果某个部分丢失,目标主机也能够知道它丢失的是哪个部分
	4. "流量控制"(Flow-control):如果发送方比接收方发包的速度快非常多,那么接收方的缓冲区可能会在一瞬间被塞满,这时候发送方如果接着发送就可能会导致数据没法写进缓冲区,此时就需要通过同步接收方的缓冲区,以保证不把缓冲区塞满的情况

##### 2.1.5 一个`TCP Header`的结构

* 一个`TCP Header`包含如图的内容
![[Pasted image 20250910164055.png]]

* 以下来详细做些解释:
	1. `Src Port`:发送方端口号,用于指代发送方的某个进程/服务
	2. `Dst Port`:接收方端口号,用于指代接收方的某个进程/服务
	3. `Sequence`:序列号,我们会在后面详细解释这个东西
	4. `Acknowledge Sequence`:确认号,我们一样会在后面详细解释这个东西
	5. `Head Length`:表示该`TCP Header`的大小
	6. `RSVD`:保留位,一般不使用
	7. `Flag`:
		1. `CWR`:用于`ECN`机制,暂时不用了解
		2. `ECE`:同样用于`ECN`机制,暂时不用了解
		3. `URG`:表示紧急提示,为`1`则会处理`Urgent Pointer`部分现在一般不建议使用
		4. `ACK`:表示确认
		5. `PSH`:建议接收方立即响应送达信息,比方说送达的是延迟敏感的数据,那么就几乎不会走缓冲区,而是立刻应答
		6. `RST`:`Reset`,立刻重置连接,一般用在不可逆的严重错误中
		7. `SYN`:表示请求,用于建立连接
		8. `FIN`:表示结束连接请求
	8. `Window Size`:窗口大小,这个就是用于告诉发送方剩余的缓冲区大小的,防止数据堆积
	9. `Checksum`:校验和
	10. `Urgent Pointer`:紧急指针,几乎不用
	11. `TCP Options`:这是一个可选项,可以自定义`TCP`的一些功能,不过几乎没人会自定义功能
	12. `TCP Data`:`TCP`数据

##### 2.1.6 `Sequence`和`Acknowledge Sequence`

* 本小节会比较复杂,个人觉得`TCP`协议中最复杂的也是这个了

* 首先我们得带入一个场景
* 假设现在有A和B两台主机,A已经和B建立了`TCP`连接,那么A向B发送了一个包
* 现在这个包在传输途中,遇到了拥塞或者其他什么的问题,总之就是包没法正确递达
* 按理来说,A发送了一个包,B会应答这个包已经到了,A应该会收到一个来自B的应答信息,但这里没有
* 于是A认为`TCP`连接已经断开,于是开始和B做重连(重连这个步骤其实是`Application`层做的,`TCP`本身不会做重连)
* 那么很顺利,重连很快完成了,A重新发送了一个包给B,B也成功拿到了这个包
* 但很不巧,原来那个因为拥塞而没有递达的包,现在突然不拥塞了,于是这个包传递给了B
* B如何判断这个包该不该接收?B只看四个东西:
	1. 源`IP`
	2. 源`port`
	3. 目的`IP`
	4. 目的`port`

* 之后我们聊到`TCP`的封装的时候会详细聊一下这个
* 那么很显然,这个本应该丢弃的包传递到了B手上,这四个东西都能对的上,那么B理应接受这个包,一旦这个包被接受了,那么就会变成一个未定义行为

* 所以现在,我们需要一个标识符用来区分一个包是旧包还是新包
* 所以我们现在可以搞一个规定,规定发送方必须发送一个类似于随机匹配码的东西
* 当A和B三次握手连接的过程中,双方都会随机生成匹配码,且双方必须确认各自的随机匹配码
* 每次发包的时候都必须携带这个匹配码才可以发包

* 这个匹配码就是一个`ISN`(初始序列号),初始状态下是随机分配的
* 那么好,此时以后就几乎不会再误收包了

* 那么`Sequence`和`Acknowledge Sequence`还解决了另一个问题,即包重排问题
* 那么,`ISN`是随机的,但只在他身上附加随机的属性未免有点太浪费了,于是我们想到了一个很好的解决办法
* 一个随机数本身具有随机属性,那么一个随机数加上一个固定的数,也具有随机性
* 所以,我们可以规定一个`ISN`,但同时当作我们传输可靠数据的虚拟的起点位置,每做完一次传输,其加上传输的可靠数据的大小

* 所以,`Sequence`最开始在三次握手阶段会初始化并交换`ISN`,这个`ISN`作为特殊的`Sequence`发送给对方

* 我们可以想象成这是一个虚拟的队列,这个队列中的每一个字节都是可靠的,且队列中的每一个包都附带了编号
* 但这个队列实际不存在,我们仅仅只是给包进行了编号而已

* 同时,因为每个有效的数据都需要可靠传输,那么三次握手的`SYN`本质上也是有效数据,需要尽可能保障不被丢失,所以每次发送一个`SYN`都会让`Sequence``+1`
* 那么为什么`ACK`包不需要让`Sequence``+1`?因为`ACK`只是一个应答信息,就像是我询问你,你给个`OK`一样,其实是不包含有效信息的,如果迟迟收不到应答信息,那么发送方会直接尝试重新链接,所以完全不需要在`ACK`包的`Sequence``+1`

* 所以实际传输中,`Sequence`和`Acknowledge Sequence`该怎么设置呢?我们实际看个例子:
	1. 三次握手阶段:
		1. A发送带有以下信息的包给B:
			1. `Sequence`:设置为属于A的随机的`ISN`,我们假设设为了`5000`,表示我的`ISN`从`5000`开始
			2. `Acknowledge Sequence`:为空
			3. `SYN`:`1`
			4. `ACK`:`0`
		2. B接收到之后发送带有一下信息的包给B:
			1. `Sequence`:设置为属于B的随机的`ISN`,我们假设设为了`2300`,表示我的`ISN`从`2300`开始
			2. `Acknowledge Sequence`:`5001`,表示应答,你是从`5001`发包给我,期待你的`5001`
			3. `SYN`:`1`
			4. `ACK`:`1`
		3. A收到来自B的包之后发送一个应答信息给B
			1. `Sequence`:`5001`,我这里从`5001`发送给你(或者说准备从`5001`发东西给你了)
			2. `Acknowledge Sequence`:`2301`,确认了,你是从`2301`发包给我,期待你的`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		4. 至此成功建立`TCP`连接
	2. 实际传输数据阶段:
		1. A发送一个`200 Bytes`的包给B:
			1. `Sequence`:`5001`,我这个包在我这里是从`5001`开始编号
			2. `Acknowledge Sequence`:`2301`,期待你的`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		2. B应答A:
			1. `Sequence`:`2301`,我这个包从`2301`开始(当然,回应的包本身不包含有效数据,所以不会`+1`)
			2. `Acknowledge Sequence`:`5201`,我收到了你从`5001`~`5200`的内容,期待你的`5201`
			3. `SYN`:`0`
			4. `ACK`:`1`
		3. 至此完成一次发包
	3. 四次挥手阶段
		1. A发送关闭请求给B:
			1. `Sequence`:`5201`,我这个包从`5201`开始
			2. `Acknowledge Sequence`:`2301`,期待你的`2301`
			3. `FIN`:`1`
			4. `ACK`:`1`
		2. B回应A:
			1. `Sequence`:`2301`,表示我这个包从`2301`开始(回应不占空间,我还可以从`2301`补充内容给你)
			2. `Acknowledge Sequence`:`5202`,收到你的`5201`~`5201`了,期待你的`5202`
			3. `FIN`:`0`
			4. `ACK`:`1`
		3. B没有东西要补充给A了,所以也发送请求给A:
			1. `Sequence`:`2301`,我这个包从`2301`开始
			2. `Acknowledge Sequence`:`5202`,期待你的`5202`
			3. `FIN`:`1`
			4. `ACK`:`1`
		4. A应答B
			1. `Sequence`:`5202`,我这个包从`5202`开始(应答信息没有有效数据不占空间)
			2. `Acknowledge Sequence`:`2302`,期待你的`2302`
			3. `FIN`:`0`
			4. `ACK`:`1`
		5. 至此连接关闭

* 所以,我们简单来说:
	1. `Sequence`:我这个包从我的哪里起始
	2. `Acknowledge Sequence`:期待你从哪里开始的包

* 至于`Sequence`的重排功能,我们可以理解为一个包到达之后,其实不会立刻被放进字节流中,而是需要先放进缓冲区中,`TCP`会检查顺序,我们举个例子,假设现在A和B已经建立连接了,A的`ISN`是`5000`从`5001`发包,B的`ISN`是`2300`,从`2301`开始发包:
	1. 第一次A给B发包:
		1. A发送`200 Bytes`的包给B:
			1. `Sequence`:`5001`
			2. `Acknowledge Sequence`:`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		2. 但这个包因为一些原因没有送达
	1. 第二次A给B发包:
		1. A发送`400 Bytes`的包给B:
			1. `Sequence`:`5201`
			2. `Acknowledge Sequence`:`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		2. B对`5201`做检查,发现`5001`~`5200`这一段缺失了,所以暂时先把`5201`放进缓冲区,不放进字节流
		3. B回应A(这个步骤可能会重复1~3次甚至更多,意思是反复询问):
			1. `Sequence`:`2301`
			2. `Acknowledge Sequence`:`5001`,意思是,布什戈门,你的`5001`咋没了?
			3. `SYN`:`0`
			4. `ACK`:`1`
	2. B收到了A第一次延迟的包:
		1. B会一次性回应A的两次发包:
			1. `Sequence`:`2301`
			2. `Acknowledge Sequence`:`5601`,我收到你的`5201`了,期待你的`5601`
			3. `SYN`:`0`
			4. `ACK`:`1`

* 所以你发现了吗,`Sequence`用于表示当前包的起始字节的编号,然后接收端会根据这个包的有效数据大小和起始字节编号计算出我接下来期待哪个字节


##### 2.1.7 `TCP`的封装再谈

* 我们知道,四层结构是层层封装的,在`Network`层只存在一个`IP`协议,这意味着这个`TCP`段一定会封装进一个`IP`数据报中

![[Pasted image 20250911180315.png]]

* 一般一个机器是否会获取一个`TCP/IP`的包,取决于这个包中的这四个东西,其中`Src Port`和`Dst Port`来自于`TCP Header`,而`Src IP`和`Dst IP`来自于`IP Header`,当然准确来说需要取决于五个东西,最后一个是`Protocol ID`,用于检查这个`IP`数据报中存放的是什么类型的`Transport`层协议


#### 2.2 `UDP`

* 前面我们有简单提到过,`UDP`是一个不可靠传输协议,在本章节我们会详细了解一下

* 不过输出一个结论,`UDP`有点像是一个极其精简版的`TCP`,阉割了`TCP`中90%的机制,仅用于区分应该传输到目标机器的那个应用程序,其他的功能一概没有

##### 2.2.1  一个`UDP Header`的结构

* 可以先看一下这个图
![[Pasted image 20250921172153.png]]

* 没错,`UDP`就是这么简单,除了用于区分应该传输到目标主机的进程,几乎其他功能,我们现在来详细看一下:
	1. `Src Port`: 源端口号,可以告诉目标进程如果要回复的话应该往哪个进程回复
	2. `Dst Port`: 目标端口号,用于区分应该传输到目标主机的哪个进程
	3. `Checksum`: 检验和,用于校验数据是否损坏,这个在`IPv4`是可选的,但在`IPv6`是必须有的
	4. `Length`: 表示`UDP Header`+`UDP Data`的长度
	
* 为什么`UDP`要有`Checksum`?
* 主要是因为数据错误比错误丢失更可怕,数据错误可能会造成一些不可预见的问题,因为你都不知道递达的数据究竟会是什么样的,与其这样,不如直接丢弃数据,所以`UDP`还是有`Checksum`,目的是保证递达的数据要么绝对正确并接收,要么不正确并丢弃

* 另外,为什么`IPv4`可以没有`Checksum`,而`IPv6`一定要有`Checksum`呢?
* 因为`IPv4`协议自身就会校验自己的`IP Header`,而`IPv6`完全不会校验自己的`IP Header`,需要依赖`Transport`层的协议校验`IPv6`协议的`Header`

##### 2.2.2 多路分解协议

* 所以你能看到,`UDP`几乎只有"分辨要传给哪个端口"的功能,以及极其轻量化的校验机制
* 所以这个协议被理解成在目标主机用于"多进程划分数据"的协议也是可以的

##### 2.2.3 总结

* 所以,对于`UDP`来说,有以下几个性质:
	1. 不保证可靠传输,或者说可靠性没有`TCP`那么强
	2. 没有重排机制,所以如果一定要重排的话,得在`Application`层自己搞协议重排
	3. 没有重传通知机制,同样的,重传也得在`Application`层自己搞协议重传
	4. 没有建立连接机制,没有确认机制

* 那么那些地方用到了`UDP`呢,比方说`DNS`解析就用到了`UDP`,主要是轻量,相应快速,没有成功就在`Application`搞重传机制


#### 2.3 `ICMP`

* 这是一个`Network`层协议,用于反馈错误,全称是"Internet Control Message Protocol","互联网控制消息协议"

* 比方说,我试图在一个内部网络访问外部网络,于是主机会发包给路由器,但路由器因为没连接到外部网络,转发表里任何一个目标地址都不匹配,那么这个包就只能丢失,于是路由器会通过`ICMP`协议通知用户到底发生了什么故障导致传输失败

##### 2.3.1 一个`ICMP`消息的一生

* 我们回到例子,当一个路由器发现一个`IP`协议的包没法转发时,他会把这个`IP`的`Header`取出,并且顺带把`IP Data`的前面`8 Bytes`也取出,作为一个`ICMP`协议的`Data`
* 同时`ICMP`会在自己的`Header`中塞入`Type`和`Code`这两个东西,其中`Type`用于表示发生了什么类型的错误,`Code`表示在`Type`这个大类型之下具体发生了什么问题
* 然后将这个`ICMP`包封装进`IP`然后发回给源主机

* 大概就是这张图表示的这样
![[Pasted image 20250921190323.png]]

* 如你所见,`ICMP`会截取`IP Data`的原因在于,它可以通过这种方式,告诉源主机应该把这个错误信息发给哪个进程

* 这里再截一张来自于维基百科的图,这里列举了一些常见的错误信息
![[QQ图片20250921190757.png]]

* 路由器通过将`ICMP`数据报封装进`IP`数据报中实现发回问题给源主机的效果


##### 2.3.2 `ICMP`的应用

###### 2.3.2.1 `ping`命令

* 我们经常用的`ping`命令就是利用了`ICMP`协议实现"尝试通话"这个操作的
* 我们可以仔细看看常见错误信息的这个图,其中类型`8`就是我们所关注的核心,这个类型表示请求一个目标主机用`ICMP`回复源主机
* 所以源主机会打包一个几乎是空的的`ICMP`数据报,其中`Type`是`8`,`Code`是`0`,并封装进`IP`数据报中,然后发送给目标主机
* 目标主机接收之后就会发回一个`Type`是`0`,`Code`是`0`的`ICMP`数据报给源主机表示相应回显

###### 2.3.2.2 `Traceroute`工具

* 这个工具可以用于检测当前主机到目标主机会经过多少跳
* 他的实现方式也很简单,她用了一个很巧妙地技巧
* 我们知道,`IP`协议中会存一个叫`TTL`(Time To Live)的字段,用于描述这个包还能跳多少次
* 如果一个包因为`TTL`减到`0`而导致被丢弃,那么路由器会发送`ICMP`协议的包(`Type=11`表示`ICMP`超时,`Code=0`表示`TTL`超时)回来
* 所以我们可以利用这个机制,发送携带固定数字`TTL`的包(`UDP`+`IP`协议)出去,并等待接收`ICMP`协议的包回来,就可以知道现在是第几跳
* 比方说第一次发送`TTL=1`的包出去,那么回复的肯定是第一跳,第二次发送`TTL=2`的包出去,第二次回复的肯定是第二跳,循环往复我们就能找出来我们到目标主机到底经过了多少跳
* 那我们怎么知道什么时候到了目标主机了呢,这时候我们会用另一个巧妙的办法
* 每次我们发出去的包,其中`UDP`指定的目标端口号都是一个实际一定不会存在的端口号,于是目标主机识别到这个端口号发现这是一个完全错误的端口号,于是会通过`ICMP`+`IP`协议(`Type=3`表示目的不可达,`Code=3`表示目标端口不可达)发回给源主机
* 源主机的`Traceroute`接收到目标主机的包之后,他也就知道本次检测已经完成了,就会自己退出

##### 2.3.3 附加

* 不过本质上`ICMP`其实并不是一个`Transport`层的协议,而是`IP`协议的子协议,但他会返回`Transport`层的错误回来,服务于`Transport`层,就有点像是这个协议是一个`Transport`层协议的感觉


#### 2.4 `End-to-End`(端到端原则)

* 这里我们重谈一下端到端原则

* 所以,为什么我们的每一跳都要设计得这么简单?为什么一定不能添加其他的功能?为什么不添加功能反倒能保证数据要么能够完整递达,要么被丢弃?

* 原先斯坦福大学的学生试图每一跳中添加安全检查,用来防止出现传输中的错误,但事实证明在每一跳添加安全检查是一个完全错误的选择,因为当时出了一个问题,虽然每一跳都会做安全检查,但是检查的都是传输时发生的问题,而在每一跳的机器的内存中出的问题这个没法在中途进行检测,但当时他们认为,在中途检测之后,两端就不需要进行检测,对于程序设计来讲会更加简单,所以实际上他们也确实这么做了,但结果就是,他们无法规避某一跳的内存中的`bug`所导致的数据出错,又因为摒弃了两端检查,所以就导致了递达的数据是错误的,而且还实际使用了错误的数据
* 所以实际上,每一个机器的每一个内存,每一个传输过程,都有可能导致数据出错,这个没法避免,所以,我们必须在两端进行检查,既然都在两端进行检查了,那么在中间任何一跳进行检查都没有任何意义了

#### 2.5 跳到跳错误检测

* 虽然我们一直强调端到端原则,不过实际上,在跳到跳我们也还是会用一些错误检测机制,之前我们聊过的`Checksum`就是这种检测机制
* 值得注意的是,虽然跳到跳有检测机制,但实际上我们依旧需要在端到端做错误检测,特别是在`Application`,必须手动做检测,否则可能会出现我们上一小节聊到过的情况,特别是安全敏感场景,比方说银行系统,甚至需要做非常多种的检测才能保证完全不出错

##### 2.5.1 `Checksum`校验和

* 校验和用了一种非常简单的机制用于错误检测
* 该机制将数据分为一个个的`16 Bits`的段,然后将每个段相加得到`Sum`,并将`Sum`取反就得到了`Checksum`
* 比方说,我要发送一个`0xABCD77668080`,我们将其分为`3`个`16 Bits`段并相加,即`0xABCD + 0x7766 + 0x8080 = 1A3B3`,因为`Checksum`最大只有`16 Bits`,所以实际上如果超出的话会重新从`0`开始计算,此时就会变成`A3B4`,然后将其取反得到`Checksum = 5C4B`
* 那么接收端如果要使用`Checksum`进行检测,其方式也非常简单,只需要把所有数据按`16 Bits`相加,并同时加上`Checksum`就行,如果得到的结果是`0xFFFF`,那么表示数据没出错(不一定)
* 那么,为什么相加之后,如果没错就一定会等于`0xFFFF`?
* 因为我们之前把所有段相加得到的数是`Sum`,而`Checksum`是这个数的取反,那么相加之后就一定是`0xFFFF`,相加数据相当于再次计算一遍`Sum`

* 但细心的你肯定发现了,这种校验方式简单,但不是特别保证安全
* 假设我通过银行程序转账给别的账户,如果我转出的金额是`0x8000`,但传输过程中最前面的字节和最后面的字节发生了交换,此时我的求和是没有发生任何改变的,`Sum`依旧是`1`,这就导致接收端会认为数据没出错,但实际上数据已经从三万多变成了一块钱了

* 这种校验方式能检测出奇数个错误,不保证能检测出偶数个错误,不过虽然嘴上说这个校验算法非常简单也非常菜,但是实际上即便是这样,也能够检测出99%的错误了

##### 2.5.2 `CRC`循环冗余校验

* 我们先了解一下这个算法的原理,稍后详细解释为什么这么做
* 首先,我们知道,一个被除数除以一个除数可以得到一个结果和一个余数,如果这个被除数被改变了,那么得到的余数也会不一样
* `CRC`的本质就是这个,发送方与接收方约定一个除数,发送方将数据除以这个除数,得到一个余数,将这个余数作为校验码一并发给接收方,然后接收方再次计算一边得到的数据,对比一下校验码就知道数据有没有丢失了

* 接下来我们来详细解释一下原理
* 这里可能会有一点点复杂
* 我们将要传的数据转换成二进制,会得到一串类似于这样的二进制串
* `b_k-1 b_k-2 ... b_0`,这里的`b_k-p`代表第`k-p`个二进制数字
* 我们将其带入一个多项式,这个多项式不需要被算出来,因为我们只需要计算其系数,不需要算实际的值
* 将以上这个式子转换成这样:`b_k-1*X^(k-1) + b_k-2*X^(k-2) + ... + b_0*X^0 = M(X)`
* 我们假设双方约定了这样一个除数(也是一个多项式):`X^5 + X^2 + 1 = G(X)`
* 那么我们需要将`M(X)`左移`6`位(这个地方可能看起来很奇怪,不过我们会在后面进行解释)
* 发送方将这个`M(X) % G(X)`得到一个余数多项式,令这个余数多项式为`R(X)`,`R(X)`的表示形式也和`M(X)`一样,所以它也可以转化成一个普通的二进制序列
* 那么发送方只需要把`M(X) + R(X)`转化成的二进制序列发送给接收方,接收方就可以自己除一下判断有没有问题了

* 我们举个例子(这里所有的式子都用二进制序列表示)
* 假设发送方要发送`1001 1101`,双方约定了`100101`作为除数,那么左移后取模得到余数为`010101`
* 因为除数是一个`6`位数字,所以余数最多可以有`6`位,所以我们把要发送的左移`6`位,这样除数可以跟在发送数据的后面
* 所以最终会发送`0010 0111 0101 0101`给发送方
* 发送方根据约定的除数,判断后`6`位是余数,因为`0010 0111 0100 0000`除以`100101`后会得到一个余数,那么`0010 0111 0100 0000 + 010101`后,再除以`100101`,就一定不会得到余数,此时一定会整除,那么如果没有整除成功,证明有数据丢失

* 那么,我们将理论的时候,用的是多项式相除,为什么实际可以是二进制相除呢?
* 很简单,你令多项式的`X=2`,不就是二进制了吗(这里其实这么理解是不完全对的,本质上其实是:`CRC`的运算不是普通整数除法，而是在 `GF(2)`上的多项式除法)

* 这里要着重提的是,这个`G(X)`的选择其实很有讲究,因为不同的`G(X)`能够判断的数据丢失类型是不同的,强大的`G(X)`很长很长,能够判断几乎99.9999999999%的错误
* 这里的这个`G(X)`我们就称为`CRC`
* 这里贴一下维基百科关于`CRC`的表
![[QQ截图20250922180409.png]]

##### 2.5.3 `MAC`(Message authentication code, 消息认证码)

* 简单来说,`MAC`是一个密钥检测机制
* `MAC`的思想源自于密码学,也和数学相关,我们不会在本小节深入算法细节,因为这确实很麻烦
* 核心思想是这样的:
* 假设现在有两台主机`A`与`B`,两者存在一个相同的密钥`K`,当`A`准备发送包给`B`的时候,他会通过`MAC`算法,通过数据唯一的包`M`和唯一的密钥`K`计算出一个唯一的随机编码`T1`,严格来说这个`T`不是随机的,它是由`M`和`K`生成的,当`B`接收到`M`之后,他会做相同的操作,通过`M`和`K`计算出随机编码`T2`,通过比对`T1`和`T2`,就可以判断这个包在传输中途有没有被篡改

* 但因为这个随机编码`T`是通过算法算出来的,我们也不可以保证某种特定情况下,在发出方和接收方的`M`不同的情况下,依旧能生成同样的`T`,所以`MAC`不保证能检测到任何一种数据错误



#### 2.6 `FSM`(finite-state machine, 有限状态机)

* 简单来说,`FSM`是一个图,这个图描述了很多状态,方便程序员将简单的图例转化成复杂的逻辑,换句话说,就是让逻辑更清晰更可控一点
* 我们简单的描述一下一个`FSM`包含了什么,首先先看一下这个图例

![[Pasted image 20250926193410.png]]

* 类似于这种图示,我们就可以称作是有限状态机
* 一个状态因为某个事件变成了另一个状态,同时会做出一些操作或者行为
* 当然,这个对象接收到的事件可能是一个未定义的事件,那么这个行为的转换也是一个未定义行为,但我们这里是"有限"状态机,所以对于这种未定义行为肯定要做出一些限制
* 当然,一个状态机描述的状态可能会非常复杂,状态量非常多,直接画图可能会显得很乱,所以很多时候会省略一些不太常见的状态,仅描述核心的,常见的状态,至于其他状态可能会备注一些补充说明什么的
* 当然,对于未定义行为,你也可以专门为其设计一个状态,这个状态直接由用户规范他的事件和行为,这也是可行的

* 老实说,在学习这个部分的时候我觉得使用"状态机"这种东西其实可以用于写另一个"玩意",你可能听说过这个"玩意",叫做"元胞自动机",这是由冯诺依曼提出的模型,感兴趣的话可以搜一下(当然,实际上冯诺依曼提出的元胞自动机其实并没有实现出来,因为状态太复杂了)

* 接着我们可以来看一下`TCP`的`FSM`

![[Pasted image 20250926192210.png]]

* 我们来详细解说一下`client`和`server`的状态:
	1. `client`处于`CLOSED`状态,表示其连接关闭,`server`处于`LISTEN`状态,表示其正在监听是否有`client`发送请求
	2. `client`现在发送`SYN`请求,也就是做"Step 1 of the 3-way-handshake"这个步骤,也就是进入事件`CONNECT`,行为是发送`SYN`,然后`client`进入`SYN SENT`状态
	3. `server`收到事件`SYN`,然后做出发送`SYN+ACK`的行为,并转换状态到`SYN RECEIVED`
	4. `client`收到事件`SYN+ACK`,做出发送`ACK`的行为,并将状态转换到`ESTABLISHED`,表示连接已确立
	5. `server`收到事件`ACK`,不做出任何行为,将状态转换到`ESTABLISHED`,表示连接已确立
	6. `client`进入事件`CLOSE`,于是做出发送`FIN`的行为,并转化到状态`FIN WAIT 1`
	7. `server`接收到事件`FIN`,于是做出发送`ACK`的行为,并转换到状态`CLOSE WAIT`
	8. `client`接收到事件`ACK`,不做出任何行为,转换到状态`FIN WAIT 2`
	9. `server`也进入事件`CLOSE`,于是做出发送`FIN`的行为,并转化到状态`LAST ACK`
	9. `client`接收到事件`FIN`,于是做出发送`ACK`的行为,并转换状态到`TIME WAIT`
	10. `server`接收到事件`ACK`,不做出任何行为,转换状态到`CLOSED`
	11. `client`因为超时而转换状态到`CLOSED`

* 至此,一个完整的`TCP`过程结束


#### 2.7 流量控制

* 老实说,其实我们之前已经谈过流量控制的一部分内容了,只是当时大家还不太了解谈的东西关乎于流量控制

* 流量控制有两种策略:
	1. `Stop & Wait`: 基于一问一答模式的流量控制,优势是简单,不容易出错,缺点是效率过低
	2. `Sliding Window`: 基于滑动窗口的流量控制,优势是效率可以动态变化,效率可以非常高,缺点是更加复杂更容易出错

* 需要流量控制的原因也很简单,因为接收方接收的带宽可能是有限的,如果发送方的带宽过大,就会导致接收方来不及接收这么多数据,于是就会导致网络传输了毫无意义一定会被丢弃的数据,造成了资源的损耗

* 接下来我们详细聊一聊

##### 2.7.1 `Stop & Wait`

* 这个策略非常简单
* 就像是对讲机的一问一答一样,当发送方的数据包传输到之后,接收方会表示收到,然后发送方会发送下一个包
* 这样,对于这两台机器来说,发送方和接收方之间建立的网络连接中,只存在一个包在传输,这样就一定不会有资源损耗了

* 我们说得更复杂些:
	1. 发送方发送了包1
	2. 接收方接收了包并回复`ACK`
	3. 发送方发送了包2但是因为网络问题没有送达
	4. 超时之后发送方会重发包2
	5. 接收方接收了包2并回复`ACK`
	6. 发送方发送了包3
	7. 接收方接收了包3并回复`ACK`
	8. 回复的`ACK`因为网络问题没有送达
	9. 发送方以为没有送达,所以超时之后重发包3
	10. 接收方接收了包3并回复`ACK`
	11. 发送方发送了包4 
	12. 接收方接收了包4并回复`ACK`
	13. 回复的`ACK`因为网络问题没有送达
	14. 发送方以为没有送达,所以超时之后重发包4
	15. 接收方接收了包4并回复`ACK`
	16. 发送方发送了包5
	17. 突然间,之前没有接收成功的`ACK`突然恢复正常了,突然就被发送方接收了,那么发送方无法判断包5是否被接收!

* 以上,我们详细了解了可以解决的三种问题,即:
	1. 正常发送正常回复
	2. 发送失败
	3. 回复失败

* 现在有一个无法解决的问题: 即回复失败之后突然恢复正常

* 解决方式很简单,因为我们没法区分回复的`ACK`是针对哪个包的,所以只需要做区分就好了
* 发送方每次发送携带一个专用的识别码
* 接收方每次回复的时候携带相同的识别码回去
* 所以我们回到例子:
	1. 发送方发送了包4 
	2. 接收方接收了包4并回复`ACK`
	3. 回复的`ACK`因为网络问题没有送达
	4. 发送方以为没有送达,所以超时之后重发包4
	5. 接收方接收了包4并回复`ACK`
	6. 发送方发送了包5
	7. 突然间,之前没有接收成功的`ACK`突然恢复正常了,突然就被发送方接收了,那么发送方对比识别码发现这个识别码是一个已经应答的包4的识别码,所以发送方选择忽略这次重复`ACK`

* 那么,有没有办法给这个策略提速呢?肯定是有的,不过我们得谈谈导致这个策略速度慢的本质
* 我们知道网络是有延迟的
* 在这个策略中,我们采用的其实是串行传输,所以两个包发送的间隔取决于回复速度
* 而回复速度其实取决于延迟,毕竟发包的速度很快,慢的是传输嘛
* 所以解决速度慢问题的最简单的方式就是降低延迟

##### 2.7.2 `Sliding Window`

* 这种控制方式就比较麻烦了,不过这可以联系上我们之前了解过的`Sequence`和`Acknowledge Sequence`字段

* 先来讲讲滑动窗口方面(滑动窗口是一个很常用的算法,这里我们不深究算法内容)
* 为什么需要滑动窗口?
* 因为,传输延迟是不可避免的!所以不管你再怎么优化,远距离传输中`Stop & Wait`的上限其实并不是非常高
* 所以有了滑动窗口,因为滑动窗口策略是并行传输的!
* 滑动窗口策略允许两个端之间的网络中存在多个包!
* 对于发送方来说,他存在一个窗口,这个窗口中会维护多个包,也就是我们在`Sequence`和`Acknowledge Sequence`小节中提到过的`ISN`,这个窗口的下标会基于`ISN`设计
* 发送方会按顺序一次性发送窗口中维护的多个包
* 接收方接收的包不一定会按顺序抵达
* 假设发送方窗口大小是`6`,因为`ISN`导致窗口的起始位置是`1000`,单个包的大小是`2`,接收方窗口大小也是`6`,窗口起始位置是`3000`:
	1. 发送方发送`1000~1001`,`1002~1003`,`1004~1005`
	2. 此时接收方已经接受到了`1000~1001`,回复`ACK`并表示期待`1002`,同时其窗口后移接受到的包的大小,此时窗口起始位置是`3002`
	3. `1002~1003`传输过程中被遗失了,但接收方依旧收到了`1004~1005`,此时接收方会`ACK``1002`表示期待你的`1002`(或者说你的`1002`为什么没到?!),此时窗口里虽然有值(`1004~1005`那个包),但是因为窗口前面有空着的`3002~3003`,所以窗口不移动
	4. 发送方超时后,检查最后一个收到的`ACK`发现对方还在等我的`1002`,于是发送方重发一边`1002~1003`
	5. 这次接收方正常接收了,于是接收方回复`ACK``1006`,表示我期待你的`1006`且前面的内容我都已经收到了,于是窗口后移到`3006`
	6. 接收方接收了`ACK`后发现维护的窗口的所有内容对方都已经接受到了,所以也后移自己的窗口到`1006`

* 我们称"窗口前部有连续的存在字节就移动窗口"的这种策略为"累积确认"

* 那么,换句话说,其实接收方发送的期待值,其实某种角度也代表着自己的窗口的起始位置
* 另外发送方和接收方的窗口大小其实并不固定,接收方会告诉发送方自己还有多少剩余空间,也就是我们在`TCP Header`中学习的`Window Size`字段的功能
* 所以这个窗口大小其实是可以动态调整的

* 那么理论上,发送方应该维护这几个变量:
	1. `Send Window Size`(`SWS`): 即发送的包的窗口大小
	2. `Last Acknowledgement Received`(`LAR`): 最后一个回应的位置,即接收方最后期待的位置
	3. `Last Segment Sent`(`LSS`): 最后一个发送的位置

* 所以理论上,最差的情况就是其他包都到了,只有第一个包没有到,所以一定有`LSS - LAR <= SWS`

* 同时,接收方应该维护这几个变量:
	1. `Revive Window Size`(`RWS`): 即接收方的窗口大小
	2. `Last Acceptable Segment`(`LAS`): 即最后一个期待包的位置
	3. `Last Segment Received`(`LSR`): 即最后一个接收的包的位置

* 所以在最差的情况下,一定也会有`LSR - LAS <= RWS`

#### 2.8 重传策略

* 重传策略一般分为两种:
	1. `Go-Back-N`("回退N",`GBN`)
	2. `Selective Repeat`("选择重传",`SR`)

* 前者是一个极其悲观的策略,窗口中有任何一个包丢失,该策略都会直接重传整个窗口的所有包
* 后者则是非常乐观的策略,仅重传丢失的某个固定的包

* 我们在使用滑动窗口做流量控制的时候,一般会采用第二种策略,但如果接收端窗口大小是`1`,那么将会退化为第一种策略
* 主要原因是,如果接收端窗口为`1`,那么他无法缓存处于丢失的包之后的包(`index`位置的"之后"),所以如果丢包了,那么之后传的任何包丢直接丢失了,因为不在接收端窗口内

* 两种策略各有优劣 
* `GBN`更适合网络通信不太好的情况,因为他的重传检测很快,如果网络总是丢很多包,那么这种策略的"命中概率"会很高,那么可以节约很多关于`ACK`回复的延迟等待的时间,不过宏观来看,这种策略还是非常保守 
* `SR`则适合网络通信良好不容易丢包的场景,可以节约网络资源,如果网络不太好还使用`SR`,那么每个包都得一个个重传,同时还得一个个等待`ACK`,每等待一个`ACK`,都会造成一次端到端通信的延迟,那么宏观的看,就会造成很大的延迟,浪费时间


### 3 分组交换(`Packet Switching`)

#### 3.1 网络的历史

* 在CS144课程中花了一些篇幅聊网络的历史,固然这段历史很重要,但归根结底并不是这篇笔记的核心,所以我们仅作了解

#### 3.2 我们为什么需要分组交换

* 虽然在之前我们有简单了解过分组交换的相关概念,但在本章节我们会更加深入地理解分组交换的实质

* 在深入分析"我们为什么需要分组交换"这个话题之前,我觉得还是有必要讲一讲CS144中提到的例子,这对我们后续理解分组交换的意义有很大的帮助

##### 3.2.1 电话线路交换

* 不清楚你是否知道有个职业叫做"接线员",现在这个职业已经被彻底取代了,如果你是00后,哪怕你听说过这个职业,也可能不太清楚这个职业具体是做什么的

* 在发明线路电话的时候,很明显,一条电话线会被两个处于端点的人拥有
* 但很显然,我们无法为所有人分配一条电话线,毕竟这很昂贵,如果每个人都有电话线的话,那么每添加一个联系人,就需要新增一整条电话线
* 所以,后期的做法是,每个人会拥有一条电话线,但不是完整的,在没有拨通电话的时候,这条电话线连接的是"转接服务中心"
* 如果我要打给某个人,我就得告诉"服务中心的接线员"我要打给谁,然后接线员会在物理上帮我接电话线到对方
* 然后在通话的过程中,我和对方会独占这条电话线

* 所以你会发现一个有趣的事情,接线这个操作,本质上不就是"路由"吗?

* 而对于现代电话通信中,"路由"的操作通常就不是由人类来进行了,同时是通过电路来路由目的地,同时,传输过程中也不仅仅是只经过一次"路由",而可能会经过多次路由

* 另外,虽然现代电话线路中,其线路物理上可以被多个人共享,但是本质上所有的线路依旧被两个端点独占,所以我们依旧按照传统方式看待现代电话线路

* 但势必的,如果一条线路会被短暂独占,那么就需要为所有的路由增加"状态",一般我们简单地把路由看作有三个状态:
	1. 拨号
	2. 通话
	3. 断开

* 虽然新增状态可以让拨号这个操作变得自动化,但是可维护性却大大下降了

##### 3.2.2 网络中的分组交换

* 网络中的分组交换其实本质上也是路由,看起来比"电话路由"要更加复杂,但实际情况是,网络的交换其实更加简单,这点你应该可以在之前的小节中窥见
* 不使用电话的交换方式的主要原因其实很简单:电话线路交换需要维护状态!
* 换句话说,电话线路交换中,每条线路会维护单一的状态,那么一旦这么做,会导致线路被独占
* 那么,网络独占线路有什么错吗?这点我们之前也提到过,你正在打游戏,已经匹配上了,结果就因为室友在下电影,所以哪怕匹配进游戏了,也没法直接开打
* 更深入的说,互联网的连接讲究一个突发性,需要有很高的时效性,那么独占的思路必然是有问题,所以必须采用共享线路的思路
* 另外,一旦线路有了状态,那么维护线路将会是一个很麻烦的事情,并且维护状态造成的性能开销也可能会让延迟增加
* 同时,这也造成电话线路的灵活性较差,比方说通话过程中某个线路突然断开了,那么通话就直接没了,如果采用分组交换的话,就可一定程度上使用别的线路(本质就是使用转发表的其他下一跳来规避问题线路)

* 当然,另外一个需要提到的点是,因为路由器发包是串行的,所以如果路由器同时收到两个包,他得先存一个包,然后发另一个包,等到另一个包发完了才会发这个存的包,所以路由器或者说传输中间的任何一跳都是一定会有缓存的

#### 3.3 延迟&丢包

* 因为网络是一个突发敏感的传输方式,所以计算延迟是一个非常重要的步骤
* 我们来看看计算网络延迟大概需要哪些内容

##### 3.3.1 三种延迟

* 首先是物理延迟,或者说信号在介质中传输的延迟
* 要知道,电信号一般的传输速度都接近光速,我们按照`2 * 10^8 m/s`计算 
* 按照CS144课程中的例子,如果传输介质长`1000km`,在不考虑其他因素的前提下,那么信息从发送方传输到接收方所需时间大概是`1000km / (2 * 10^8 m/s) = 5ms`,那么,延迟至少是`5ms`起步

* 另一个值得注意的是"分组延迟",这个延迟其实很有意思
* 我们知道数据被转化成`0`&`1`,然后变成高低电平,也就是电信号,这些信号是串行的,因为某个时刻,某个数据线中的某一段的电平不可能有高低两种状态
* 所以发送方把数据传递给信号线也是需要时间的,我们把发送方从开始传递第一个`bit`到结束传递最后一个`bit`的过程称为"分组延迟"
* 换句话说,你知道你的电脑的网卡也是有旗舰款,中端款和低端款吗?
* 款式越低,那么网卡传递信号出去的效率也会越慢,然后分组延迟也就会越高
* 一般分组延迟是这样计算的,如果我我们知道网卡设备将数据塞进传输设备的速度,这里同样用CS144的例子,假设速度是`100Mb/s`,那么将一个`64byte`的包放进介质中需要约`64byte / 100Mb/s = 5.12μs`
* 如果速度是`1kb/s`,将`1kbit`的包放进介质中则需要约`1.024s`

* 所以,就以上两种延迟,我们来画个图(原图依旧是来自CS144)
![[Pasted image 20251002223038.png]]

* 在这个图中,我们假设有两台主机,中间有一台路由,`A`需要经过路由发包给`B`

* 那么,发送方不会在一瞬间就发送完整个包,于是就会有一种情况,在某个时刻,链路上存在着一个不完整的包,因为包还没有完全发送完毕
* 同时也会存在一个时刻,`A`认为自己已经发完了包,路由认为`A`啥也没发给他,因为包还在路上
* 同时也会存在一个时刻,会有一部分不完整的包还在链路中,剩下的内容已经被路由拿到了
* 只有当路由中的包完整了,路由才会选择转发出去

* 那么,一个包被路由接收之后,一定会立马被转发出去吗?
* 当然不会,如果这个路由在某个瞬间接收了太多包了,那么你的包有可能需要在路由的缓存中排队一段时间,然后才被发送到下一跳
* 那么,此时咱们的图就有可能变成这样
![[Pasted image 20251002231247.png]]

* 当然,如果这个路由在一瞬间有超出路由缓存上限的包试图进入路由,那么路由有可能会直接丢弃包, 如果你的学校人比较多的话,一般在大型的且没有意义的活动上可能就会这样,明明连接着5G,却什么也访问不了像是断网了一样,这时候我们可以尝试着切换到4G,这样排队的人会相对较少,至少能上网了

* 所以说,如果你交换信息的目标地址离你的物理距离特别远,那么传输介质的长度会很长,同时中间需要经过的跳的数量也会有极大概率显著增加,那么遇到排队的概率也会显著增加,这就也是我们访问远端主机的时候延迟非常大的原因之一

* 所以,就我们**现在了解的内容**综合来看,一个包的延迟为"传输延迟"+"分组延迟"+"可能的排队延迟"

##### 3.3.2 接收端缓冲

* 使用网络有着很多不同种类的场景
* 有些场景对于延迟极其敏感,而对于延迟敏感的场景,我们又可以分为需要与其他主机同步的场景与不需要与主机同步的场景
* 比方说网络游戏就对延迟非常敏感,并且需要与他人同步状态,所以对于网络的要求非常苛刻
* 又比方说在流媒体网站观看视频,如果体现在用户上,这种场景一样对于延迟非常敏感,但因为不需要与其他用户同步,所以他可以通过缓存来极大地提升体验
* 另外也有完全不在乎延迟的场景,比方说文件下载或者是网页加载这种
* 本小节着重了解第二种场景

* 我们假设视频文件的发送方按照某个固定速率发送视频,比方说发送方以`1Mb/s`的速率发送视频过来,用户也以`1Mb/s`的速率播放视频
![[Pasted image 20251003161041.png]]

* 那么,接收方接收到数据之后不会立马使用,就比方说我们在看长视频的时候,视频也不会立马播放,他可能会缓冲大概半秒钟左右才会播放
* 此时就是该进程正在接收数据并缓存的过程
* 缓存到一定程度之后,才会开始播放,此时就不会造成用户的卡顿
* 某个时刻,用户可能才看到大概第`1`分钟,但程序在后台已经缓存到大概第`2`分钟了

* 如果网络延迟太高,或者丢包率太高,就有可能会造成以下情况
![[Pasted image 20251003162158.png]]

* 当缓存量已经不满足用户播放的需求量时,就会造成赤字,于是用户就会卡顿直到留有一定缓存才会播放

* 所以换句话说,我们可以尽可能保证平均到达速率和播放速度差不多,或者说平均到达速度大于播放速度,但我们没法保证某个短时间内的到达速率(或者也可以说某个瞬间的接收端斜率)一定大于等于播放速度,所以我们需要缓存来提升用户体验,避免因为网络波动造成的卡顿

##### 3.3.3 排队模型(`queue models`)

* 这个小节的内容其实很简单,甚至说你可以通过之前学过的内容直接推断出来,所以本小节实际上几乎仅作为结论的输出
* 简单来说就是在路由中存在一个缓存,该缓存会被当作一个队列来使用:
* 这个队列会有的属性,包括某时刻的输入总量(可能来自不同机器),某时刻的缓存量,某时刻的输出总量,输出速率,根据这几个属性画了一个横坐标是时间,纵坐标是数据量的折线图,包括该缓存的接收折线与输出折线,于是我们可以根据这两个折线分析该缓存的属性与状态 
![[Pasted image 20251003212224.png]]
* 为什么包越小,延迟会越小?那么原因其实很简单,因为包越小,就越可以接近并行传输,缓存可以在接收一个包的时候发送另一个包 
![[Pasted image 20251003211936.png]]
* 另外,通过一个更复杂的折线图,我们可以了解到,只要一个缓存在某一时间段内的平均接收速率小于输出速率,且缓存始终没有吃满,那么就不会丢包,但可能会缓存,如果一个缓存的在某一时间段内的峰值接收速率小于输出速率,那么甚至连缓存都没有,一般可以直接输出

![[Pasted image 20251003213809.png]]
![[Pasted image 20251003213816.png]]

* 那么我们假设在`v2`开始缓存之前,`v1`缓存的数据已经全部被输出掉了,那么假设`v2`的大小已经大于了能够缓存的上限了,那么超出的部分将会被直接丢弃,也就是丢包了

##### 3.3.4 "随机"与延迟与泊松分布

* 首先复述一个之前我们已经了解过的结论
* 对于一个路由/交换机来说,包的抵达是一个非常随机的事情,如果有非常多的包在同一时间抵达,那么延迟就会非常高,甚至于丢包,以下我们会通过一个例子来说明这个问题

* 假设在一个路由中,`5s`内,平均`1s`就会有一个包到达,这里假设所有的包的大小都相同,假设一个包从介质中抵达路由需要`0.2s`(实际肯定要短得多,这里只是许个例子),一个包被路由输出的时间为`0.4s`
* 那么最好的情况应该是每隔`1s`就正好有`1`个包到达,那么在这`1s`中,前`0.2s`将会是接收包的过程,紧接着的`0.4s`应该是发送包的过程,剩下的`0.4s`,路由器什么都不做,处于等待/监听状态
* 在这种情况中,不会有包需要排队
* 但是,如果`5s`内,这`5`个包全部在同`1s`内全部被路由接收,那么先进的包不需要排队,第二个包需要等待`0.2s`,第三个包需要等待`0.4s`,如此递推
* 虽然平均接收的包并不多,但是仍然造成了延迟

* 我们很难估量某个时间段内会有多少数据包抵达,因为包的抵达几乎是纯随机的,所以我们需要借助泊松分布来衡量

* 因为我的数学其实学得并不是很好,甚至说非常差,所以在本小节我不会详细推导泊松分布(但会简单推导一下),但我会讲解为什么我们需要泊松分布公式,为什么他可以用在这里

* 简单来说,泊松分布用于计算"某一段时间内可能会发生若干次数的某个随机事件的概率",换句话说,就是计算"在这个时间段内,发生多少次这个事件的概率大概是多少"
* 他是怎样做到的?
* 因为事件在这个时间内会发生多次,所以事件不是独立的
* 所以我们可以通过把时间分片,以实现某个时间片中要么只发生一次时间,要么不发生,这样事件就是独立的了,然后可以用二项分布求概率,于是我们可以得到一个公式,用于表示在“在`n`个独立的小片中,每个小片事件发生概率为`p`,那么总共发生`k`次的概率是多少”

![[Pasted image 20251004235053.png]]

* 但时间片具体要分多细,这个我们不知道,所以我们最后要求极限,就可以假设时间片无限细的情况下,某一段时间内某随机事件发生的概率了,于是可以得到以下公式用于表示"在趋近于无限个独立的小片中,每个小片事件发生概率为`p`(因为时间片太多了,所以`p`这个概率会无限趋近于`0`),那么总共发生`k`次的概率是多少"
![[Pasted image 20251004235134.png]]
* PS:n->∞,p->0,np=λ

* 难道网络中的所有的包都可以是泊松的吗?
* 不能,因为泊松描述的是"随机",然而从宏观来看,网络中包数量的多少并不是泊松的
* 我们打个比方
* 我们知道有几个著名的时间段,人们会在这个时间段通过网购买特别多的东西,比方说618或者双十一
* 这几个时期是固定的,那么此时购物平台需要收发的数据包的数量将会提升几十甚至上百倍,所有卖家,买家,运营商,银行,购物平台,支付平台的数据包收发都会有风险因此垮掉,所以他们会针对这个时间段,像是应对大BOSS一样需要在短时间内应对如此大的流量
* 难道他们还属于泊松吗,显然是不可能的,这种情况是人为的,一定不属于泊松

* 所以说,从微观来看,比方说在几分钟或者说几秒内,包的传输无限趋近于泊松,但是宏观来看,包的传输很难称得上泊松

#### 3.5 以太网交换机和路由器

##### 3.5.1 工作原理简述

* 简单来说,以太网交换机是服务于`Link`层的,他的目的是用于转发以太网帧
* 首先我们可以见一见交换机长什么样,如果你家开过餐馆装过监控系统或者你有见到过商场装监控的话,你肯定看见过这个长着很多个输入输出口东西

![[69079ede-7b3c-4f04-83e6-11265cb6a4fa.png]]

* 我们看这些接口,粗略地看,我们把每一个接口都看作是一个端口

* 那么他的工作原理很简单:
	1. 检查到达的帧的`Header`
	2. 如果在转发表中存在这个`Header`中的目的以太网地址,那就直接转发
	3. 如果不存在,那么就会向除了接收该帧的端口外的所有帧全部广播地发送一遍这个帧
	4. 那么,交换机会学习,他会自行扩充转发表,比方说如果交换机接收到了一个没见过的`SRC MAC`的帧,那么他会将这个`MAC`地址与输出端口绑定,并塞进一个转发表中,如果下次从别的端口进来一个帧,他的目的`MAC`是之前存的这个`MAC`地址,那么他就会往之前记录的端口发送,我们在后面几个小节会更加深入探讨这个问题

* 接着我们来聊聊路由器
* 路由器你肯定见过
* 说不定你现在看这篇笔记的电脑的主机旁边就放着一个路由器

![[asus-rt-ax3000-wifi-router-01.jpg]]

* 路由器的本职不是转发`Link`层的帧的,他的本职其实是转发`IP Datagram`,所以他其实是工作在`Network`层的

* 路由器的工作原理:
	1. 检查一下这个包是不是专门发送给自己这个路由器的,如果是就接收,如果不是,那就是对方发错了,直接丢弃
	2. 如果自己是一个针对`IPv4`的路由器,那么得检查一下`IP`版本,防止接收到`IPv6`的包
	3. 把`TTL--`,并且检查`checksum`
	4. 检查`TTL`是否为`0`,如果是`0`,那么直接丢弃
	5. 查找转发表,如果转发表中存在这个`IP`范围,那么直接转发到目标端口,如果不存在,则通过默认路由转发,当然,还会检查一下是不是多播(简单来说就是群发),如果是,那么就转发到多个端口
	6. 如果能在`ARP`表中找到下一跳的以太网地址,那么将会直接封装一个以太网帧并通过目标端口转发
	7. 如果找不到下一跳以太网地址,那么将会先通过`ARP`广播获取下一跳的以太网地址

* 我知道现在咱看到这堆东西还是一头雾水,不过没有关系,有一些问题,我们会在后面解决

##### 3.5.2 查表

* 对于交换机来说,他的转发表其实很简单

* 大概长这样:

|目标`MAC`地址|目标端口|
| :---: | :---: |
|`0xA8B72340E678`|`port 7`|
|`0xB3D22571053B`|`port 3`|
|`...`|`...`|

* 当然,这个表实际上是放在一个双向的哈希表中的,这样会方便查找

* 对于路由器来说,查表会相对来说复杂一点,路由器会有两张表:

* 路由器的转发表:

|目标`IP`范围|下一跳`IP`|目标端口|
| :---: | :---: | :--: |
|`127.43.57.99`|`56.99.32.16`|`port 3`|
|`123.66.44.X`|`22.45.21.126`|`port 2`|
|`76.9.X.X`|`56.99.32.16`|`port 6`|
|`...`|`...`|`...`|

* 当然,一个路由表可能不仅仅包含这些信息,具体其实要取决于路由的协议
* 通过匹配最长前缀算法,我们可以知道哪个下一跳是最优的

* 因为路由器服务于`IP`协议,所以实际上路由器会解包一个帧,然后获取一个一个包的`IP Header`,但是实际传输肯定是跑在`Link`层的,所以解包之后,肯定还要再次封装一个`Link`帧,问题是`Link`帧中,下一跳的`MAC`地址我们是不知道的,所以需要缓存另一张表,映射下一跳`IP`和`MAC`地址

* 路由器的`ARP`表:

|下一跳`IP`|`MAC`地址|
| :--: | :--: |
|`56.99.32.16`|`0x76E309AB2CA1`|
|`22.45.21.126`|`0x43ED7D88A1B8`|
|`56.99.32.16`|`0x663ADD9B3771`|
|`...`|`...`|

##### 3.5.3 一些问题

* 这么说,路由器和交换机其实很像啊?
* 并非,从地位上讲他们两个完全不一样!

* 不知道你有没有发现一个细节
* 交换机的转发表中,存储的都是固定的`MAC`地址,以及对应的端口,他不会存储下一个机器的`MAC`地址,`IP`地址,以及某个`IP`范围或者是`MAC`地址范围

* 因为交换机根本就不会解包,换句话说,交换机的工作范围其实非常小
* 换句话说,他只负责某一个很小的网段内部的通信工作,而不负责转发到除了他负责的网段之外的其他网段

* 换句话说,这也体现了路由器其实是服务于更加上层的`Network`层的,而交换机是服务于更加底层的`Link`层的

* 那么实际的情况是怎样的?我们举个例子来说说:
	1. 比方说你的电脑,现在发一个包给主机旁边的路由器
	2. 然后路由器会解包,检查,查表,然后再封装转发给另一个路由(一般是运营商的路由)
	3. 那么运营商的路由可能会做同样的操作,但却不是转发给另一个路由,而是转发给这个路由器旁边的交换机,交换机经过多层转发,将包最终给到另一个路由器,然后由这个路由器转发给互联网服务商
	4. 服务商也会做一样的事情,路由接收,但是在服务商的数据中心却是经过交换机传输包,最终传输给服务器

* 另一个问题,一个路由的转发表有多少项?他是怎样查表的?

* 一个路由器大概有十万多个项,所以如果用暴力查找的话,其实非常浪费时间
* 所以他会做这样的事情:初始化一个深度是`32`的二叉树,每一个分支中,向左是`0`,向右是`1`
* 比方说我要查`0b 1100 0000 1010 1000`(`192.168.0.0/16`,只用查`16`位,后面的掩码掉了)这个地址,只需要这样索引"右右左左 左左左左 右左右左 右左左左",然后查看这个节点存的是哪个端口,哪个`IP`地址

* 当然,以上肯定不是找实际包里的`IP`地址,我们举个更详细的例子
* 现在路由表有`3`个项:
	1. `0.0.0.0/0`(`0b 0`)
	2. `192.168.0.0/16`(`0b 1100 0000 1010 1000`)
	3. `192.168.10.0/24`(`0b 1100 0000 1010 1000 0000 1010`)

* 现在包里的`IP`是`192.168.13.108`
* 转换成二进制是`0b 1100 0000 1010 1000 0000 1101 0110 1100`
* 所以我们按照左右一直从根往下找,直到找到匹配的`192.168.0.0/16`,当然,找到这个项之后其实不会停下来,而是会先缓存起来,因为其实现在还没到叶子节点,剩下还有整整`16 bits`没找,于是接着找`0000 1101 0110 1100`
* 结果发现,直到找到叶子节点,这个缓存的项再也没有更新过了,因为其他的节点全部都是空的,所以此时我们就直接使用找到的节点的内容`port X & IP 0x AA.BB.CC.DD`

* 所以在最差的情况下,这个路由表也只会查找`32`次,不会更多了!常数次的查找,能将查找时间控制到纳秒级别,这就很快了!!

##### 3.5.4 通用转发设备架构

* 本小节,我们来将之前聊过的交换机工作原理转化为架构
* 这里标题是"通用转发设备架构",主要原因是,本质上所有的交换设备的原理都差不多,所以这里取标题"通用转发设备架构"

* 我们来简单看看架构图(本小节所有架构图的原图全部来自于CS144,我只是自己全部画了一遍以便加深理解)
![[Pasted image 20251008131254.png]]

1. `Lookup Address`:查看目标地址,确定去向,当然,这个步骤肯定会查找转发表,也就是`Forwarding Table`
2. `Update Header`: 更新包头部内容,如果是路由器就会做`TTL--`,修改`MAC`地址之类的内容,如果是二层交换机(仅做某网段内的包转发的交换机)则没有这个功能,因为其不修改包头,如果是三层交换机(有部分路由功能的交换机,介于路由器和二层交换机的中间产物),则需要有这个功能
3. `Queue Packet`: 等待队列,如果需要,则会先塞进缓存中

* 当然,以上只是一个简单的架构,如你所见,这个架构其实是单入单出的,如果要实现多入多出,就会变成这样
![[Pasted image 20251008135538.png]]

* 这个架构有个简单的称呼,即"输出队列交换机","output queue packet switch",简称`OQPS`
* 因为缓存队列存在输出端中而不是输入端
* 这是一种"理想"的交换机架构,但他的问题其实比较大
* 正因为他的缓存释放在输出端的,所以这会导致一个很严重的问题:即如果这个交换机如果退化为N入单出,那么输出端用于缓存队列的硬件需要非常非常高的速率才能满足这种退化,换句话说,假设所有输入端口全部要往同一个输出端口输出,那么这个端口的缓存需要在非常短的时间内承受所有输入端的写入操作,这对缓存的读写能力的考验是极大的,几乎没有缓存能够承受住这种读写
* 假设单个输入与输出端口的速率全部为`R`,输入端口数量为`N`那么在这个架构下,交换机的缓存至少需要有`(N + 1) * R`的读写速率,这是非常恐怖的速率
* 所以我们说这种架构是理想的,但几乎是不可实现的

* 如果我们在`OQPS`上做一下修改,试图解决这个缓存速率问题,就会得到另一个架构
* "输入队列交换机","output queue packet switch",简称`IQPS`

![[Pasted image 20251008141554.png]]
* 这个解决思路其实很简单:既然输出端口的缓存可能会接收很多个输入端口的包,那么只要把缓存挪到输入端口不就行了,这样每个缓存就只需要接收一个输入端口的包了,所需读写效率直接变成`2R`了,远低于`(N + 1) * R`

* 但这又引入了另一个问题
* 我们可以把输入端简化成一个个队列
![[Pasted image 20251008142939.png]]

* 因为输入端的队列仍然是一个单队列,这就意味着,可能会有一种情况,输出端A堵住了,某个输入端的缓存队列中的首个包也是往A走的包,那么这个包也会被堵住,假设这个包后面还排了一堆往其他口走的包,那么哪怕其他口空闲了,这些包也走不了,因为在队头往A走的包走不动
* 这种现象称为头端阻塞
* 放在这个图中,第二个队列因为绿色的阻塞,导致后面的橙色和蓝色全都走不动,即便蓝色和橙色的输出端口全部是空的

* 于是我们需要在这基础上再做一些改进

* 于是我们得到了"基于输出队列的`IQPS`",也可以称作`VOQS`
![[Pasted image 20251008143513.png]]
* 他的每个缓存中,都存在"输出端口数量"个队列,这就不会造成常规`IQPS`的头端阻塞问题了

* `OQPS`是一种理想的架构,几乎无法实现,理性情况下,`VOQS`可以非常接近`OQPS`,而`IQPS`则只有`OQPS`效率的`58%`左右


##### 3.5.5 队列设计

* 请注意,个人认为本小节其实在文字上其实很难表述,从这个小节巨量的图就可以看出来,所以十分推荐先看课程

* 记得我们之前类比过网络资源和`CPU`资源吗?
* 网络资源和`CPU`资源其实很像,本质上,用户串行获取`CPU`资源,只不过在用户视角看起来太快了,就像是并行获取资源一样
* 那么,本质上路由或者交换机以串行服务用户,或者说以串行获取用户的包,这很好理解
* 那么问题来了,网络难道没有像`CPU`一样有优先级概念吗??
* 有的朋友,有的,我们本小节就来深入谈谈这个问题

* 那么,不知道你有没有遇到过一个非常有意思的事情,你的五个室友,一起开黑,车队满了所以你打算看看库里季度促销买了但没有玩过的3A单机
* 挑了个不错的开始下载,刚点击下载,你的室友们的网络集体爆炸,延迟飙升

* 在这个例子中,有两种网络使用场景:
	1. 延迟敏感但是流量不大的网络游戏场景
	2. 延迟不敏感但流量很大的下载场景

* 我们由浅入深地看,所以这里的图例其实是一个非常简单的图例,后面我们会过渡到之前的学到的架构中
![[Pasted image 20251008224202.png]]

* 那么我们知道,这个缓存队列中包的去向其实并不一致,那么,现在宿舍中有`6`个主机,那么去向就是`6`个?
* 其实不是的,本质上,其实所有人共享路由器的同一个网络端口,所以本质上,这个多入多出退化成了多入单出,除非你用有线连接到路由器
* 一开始的`5`个人全部都是在打网游,流量其实并不高,路由器需要接受的字节数和包的数量其实并不是非常多,他只需要在某个瞬间切换传输包的设备,然后传给他就行了
* 所以目前来看,路由器开能顶得住,秉承着`FIFO`的设计思想,一个包先到的话,就会先发送给你需要收这个包的室友
* 换句话说就是轮流给`5`个室友发包,固定时间内一人来一个包
* 但是,某个时刻你点了开始下载了
* 于是发生了一件非常抽象的事情,因为开始下载了,所以你的机器肯定会试图直接吃满你的路由,这就导致了其他人获得的路由器的时间片的数量被稀释了,因为现在路由器里`90%`都是你的包
* 这就像是我在`OS`中一直往死里开线程一样,本质上一直开线程可以用于掠夺其他进程的`CPU`时间片

* 所以,如果路由器性能不够强劲的话,就直接导致其他人的包得排到猴年马月才能被接收

* 所以我们迫切需要一种技术可以像`CPU`一样有一个优先级
* 那么分优先级也很简单,只需要把一个队列拆成两个就行了,`Low`代表不紧急的任务,`High`代表紧急的任务
![[Pasted image 20251008232313.png]]

* 下载东西的时候,走`Low`队列,游戏的时候,走`High`队列
* 当然,两者的效率可能也不太一样,我们假设`Low`的效率是`W`,`High`的效率是`2W`,那么,综合来看,`Low`队列会占用`1/3`的资源,而`High`会占用`2/3`的资源
* 那么,如果引入权重的概念,那么`Low`的权重应该是`1`,而`High`的权重则是`2`

* 那么,如果我们添加多个不同权重的队列呢?
![[Pasted image 20251008233258.png]]

* 那么,我们现在就拥有了一个多优先级的队列
* 一个队列的输出速度应该是这样计算的: `queue Ni 的输出速度 = N / 所有队列的权重相加 * R`
* 调度器会按轮一个一个检查每个队列,就像是`CPU`轮着服务进程一样
* 在每轮中,权重大的会多传不少,权重小的会少传很多,简单来说就是权重越大传得越多

* 那么,这里的输出速度是按包的数量来算的还是按照字节数来算的?
* 实际情况是,按照字节数来计算,如果按照包来计算的话,某些情况下其实会很亏,比方说多个高优先级的小包的优势体现不出来

* 那么,如果要按照字节数计算,那么肯定会有一种情况,某一轮输出时,一个包没有读完!
* 针对没有读完的包,我们要把它缓存起来,以便后续还可以把剩余部分拼接上
* 至于这个缓存,我们称作魔法队列
![[Pasted image 20251008234645.png]]

* 不过暂时的,我们的重点不是魔法队列,你只需要知道我们可以通过魔法队列来处理不完整包的输出,回到这个图
![[Pasted image 20251008234848.png]]

* 同时,会出现一个问题,一个不完整的包,什么时候会变得完整?这是我们值得去思考的,也是路由器应该提前思考的?
* 为什么路由器需要提前预测一个包在第几轮被完整读取了?

* 其实很简单,因为包不存在尾部标志位这一说,所以路由器才这么关注一个包什么时候被完整读取了,因为只要包被完整读取到了魔法队列中,这个包就已经被许可发送了!!

* 那么具体怎么计算呢?
* 其实很简单,我们假设一个包的头在第`S`轮被读取,这个包长`L`,该队列的权重是`W`,那么,这个包一定在末尾轮数`K = S + L / W`轮被读取走,那么意味着,在`S + L / W`,这个包被完整的读取走了
* 那么这也意味着,下一个包的开头,也就是下一个包的`S`已经被确定了,就是上一个包的`K`,那么,只要获得下一个包的`L`,就能直接推算出下一个包会在第几轮被完整传输完毕
* 至此,我们只需要一个递归,就可以一直推断下去!知道预测出所有已经缓存的包!

* 你肯定有疑惑,为什么这里可以直接用`L / W`就可以算出经过了多少轮

* 其实本质上,他计算的不是经过了多少轮的时间,而是在计算一个虚拟时间,所以,我们可以把权重直接看作是速率,因为这个速度中,`bit/time`中的`time`我们根本不在乎!只需要路由自己知道就好

* 那么,你肯定会想,如果一个包的前面没有任何包,该怎么计算时间?其实很简单,包头的读取的虚拟时间归零不就完了!!

* 那么,具体是怎么从这一个个队列中取走数据的呢?
* 路由器中会存在一个调度器的东西,这个东西会优先取剩余时间的那个,换句话说,如果一个包优先级够高,或者一个包足够小,那么他都有可能会成为调度器的选择!

* 那么,这意味着,本质上,调度器读取数据,其实是一个非常没有规律的事情,因为他其实本质上不是按照轮来计算的
* 那么这该怎么解释`K = S + L / W`是按照轮被读取走???

* 上面说的轮其实只是方便初学者理解的而已,实际上的时间计算根本不按轮来算,路由器自身其实会维护一个时间轴,每个包的每个部分都会直接被映射进这个时间轴中,一个包被缓存之后需要立马计算时间并且映射进时间轴中

* 以上的内容其实是`WFQ`的内容,有兴趣的话可以去网络上深入了解一下`WFQ`或者加权公平排队("weighted fair queueing")

* 那么我们长篇大论了这么多,其实就是在论证和学习两件事情,即:路由和交换机确实是有优先级算法的,我们学习了这种优先级算法的实现机制

* 那么回到最初的问题,我占用了路由的带宽,室友的网络延迟受到了较大影响
* 那么,问题来了,既然路由器有优先级算法,为什么室友的网络依旧受影响了??
* 其实原因很简单,因为一个包的优先级具体是多少,完全是由互联网厂商决定的,互联网厂商肯定要保证对于当下用户的服务,那么如果所有的互联网厂商全部都因为"保护用户的体验"而直接无脑把优先级拉到最高,那么此时优先级就完全没有任何意义了,之前学的内容也没有意义了,这里会直接退化成了普通队列的`FIFO`
* 我们称这种现象为`QoS`崩溃("Quality of Service",即服务质量)


##### 3.5.6 延迟保证

* 那么,之前我们有学到过延迟的计算公式:"总延迟" = "传输延迟"+"分组延迟"+"可能的排队延迟"

* 在这里面,"传输延迟"我们基本没法控制,因为它是物理限制,这个目前几乎没法突破
* 不过值得一提的是,在固定线路中,"传输延迟"+"分组延迟"基本是可以确定的,或者说是一个固定值
* 那么唯一不确定的因素就来自于"可能的排队延迟"
* 当然,不同转发设备的排队延迟肯定不太一样,所以我们需要一个方式,能够计算所有类型的转发设备的排队延迟
* 那么最简单的方式,我们假设现在有两个时间,`Ta`和`Tl`,如果在`Ta`时间下,输入端累计接收的数据量等于在`Tl`时间下输出端累计发送的数据量,那么我们可以称`Tl - Ta`可以是这个转发设备的延迟

* 其实原理很简单,我们把转发设备当作是一个视频播放器就行
* 之前我们有学过视频播放器其实会缓存一部分数据,然后才会播放
* 那么转发设备其实也是这种思想
* 转发设备也有缓存,然后他也会消耗数据,那么就和视频播放器的原理一模一样了
* 那么,我们怎么计算一个包在视频播放器中缓存了多久(这个包在缓存中经过了多少延迟)?
* 不就是"这个包被播放的时刻"-"这个包被接收的时刻"

* 为什么我们描述这个延迟的时候说的是"可以"是这个转发设备的延迟?
* 因为输入端的速率其实是很不固定的,所以我们如果要计算最大延迟,其实需要一个理想的输入端速率
* 那么,一个转发设备在某段时间内最多能接受多少流量?
* 这里我们有一个公式`A(t) = B + Rn * t`
* 其中,`B`是某个优先级的缓存大小,`Rn`表示第`n`优先级的输出速率,那么`Rn * t`就是在某个时间内该队列的累计输出量
* 那么,也就是说某时刻,该队列的累计输入量不允许大于`A(t)`,否则就会丢包
* 那么此时我们就得到了一个理想输入端累积量的图

![[Pasted image 20251010121207.png]]

* 这个理想输入端累积量不会一直延伸,如果队列中所有的包都已经离开,且没有任何包缓存,那么此时计算理想输入端累积量没有任何意义,直到某个时候有包进入了队列,此时才会重置理想输入端累积量
* 所以实际上应该是这样子的

![[Pasted image 20251013100321.png]]

* 所以你可以看到,理想输入端积累量会在队列中缓存了内容的时候重置
* 路由中专门为此做了一个协议,即资源预留协议,"Resource Reservation Protocol",简称`RSVP`

* 至此,我们只需要计算实际输出量(也有可能是理想输出量,某些设备可以计算这个的)减去理想输入积累量,就可以得到该转发设备的理论最大延迟

* 计算路径上所有的转发设备的理论最大延迟并相加,然后再加上传输延迟与转发延迟,就可以得到理论最大延迟,超过这个延迟值过多的包,我们都可以算作丢包


### 4 拥塞控制

* 那么很好,我们已经学到拥塞控制了,学完这个小节,你就已经学习完一半的`CS144`课程了,那么,本章我们将会了解拥塞控制的一些详细内容

#### 4.1 我们需要一个怎样的"拥塞控制"?

* 相信你应该很清楚,为什么网络需要有拥塞控制了,简单来说,如果网络没有拥塞控制,那么如果遇到传输瓶颈,那么可能将会造成上游传来的数据包丢失,这样就会浪费上游的网络带宽

* 在讨论一个实际的例子之前,我们需要做一个声明(这也是`CS144`课程中做的事情)

![[Pasted image 20251020105242.png]]

* 我们大概可以把拥塞控制分别放在4个粒度下: 
	1. 第一个图中,我们的粒度非常细,也就是我们需要拥塞控制非常灵敏
	2. 第二个图则是把粒度稍微放得更粗一点,这点粒度人类依旧比较难感受到,但是对于计算机来说则刚刚好,正好稍微比人类灵敏一点
	3. 第三个图则表示粒度比较粗的情况,常见于某天的时间段中,访问量突然增大,比如说下班回家之后,会有更多用户打开短视频平台
	4. 第四个图的粒度则极粗,常见于特殊节日,例如网购节日,游戏特卖什么的

* 对于第一种情况,如果我们要求拥塞控制在这么细的粒度下工作,那么会吃掉太多的性能,得不偿失
* 对于第三种情况,我如果此时做拥塞控制,那么灵敏度其实太低了,用户很容易感知到
* 而对于第二种情况则非常好,用户感知不到,也不会有特别高的性能开销
* 至于第四种情况,这种粒度下,从宏观来看也是有拥塞控制的,只不过这种拥塞控制一般是人为调控的,比如紧急增加并行路由数量这种

* 所以,这里我们讨论的拥塞控制,一般是第二种情况

* 那么,最简单的拥塞控制应该长成啥样?

![[Pasted image 20251020155828.png]]

* 如你所见,这种拥塞控制其实特别简单
* 对于设备A,B以及交换设备P来说,因为P的输出上限在`12 Mb/s`,所以设备A和B只有保持在各自`6 Mb/s`的输出上限才行,对于A,B和P来说,这种形式似乎可行

* 但如果对于P和Q来说,这就很难做了
* 因为Q不仅需要接收来自P的数据,还需要接收来自C和D的数据,但Q的输出效率依旧是`12 Mb/s`,那么如果只有D,那么我们将平分来自P和来自D的速度,那么对于P来说,他的实际输出数据其实已经坍缩成`6 Mb/s`了,D是`6 Mb/s`,对于A,B来说则会进一步坍缩成`3 Mb/s`,而我们希望A,B,C都能平分带宽变成`4 Mb/s`

* 如果引入一个输出效率更低的C,那么实际将会更难做,因为这种形式根本没法平衡各个设备的速率

* 并且,在这个例子中,如果A发送的效率是`12 Mb/s`那么就会造成至少`2/3`的数据被丢失,其实就会造成上游带宽做了无用功了,这是我们不希望看到的
* 更抽象的是,延迟也会奇高,因为`2/3`的包被丢失了

* 所以,我们需要的是一个相对更加公平的拥塞控制


#### 4.2 `max-min fair` (最大最小公平算法)

* 这是一种相对更加公平的算法
* 首先我们得看个例子来说明这个算法做了什么

![[Pasted image 20251020165318.png]]

* 在这个例子中,A,D的输出速率都是`12 Mb/s`,C的输出速率是`2 Mb/s`,那么结果是,A和D实际得到了`5 Mb/s`,C却能以`2 Mb/s`跑满

* 在`max-min fair`算法中,规定: 计算顺序必须按照设备输出速率的最小的那个逐渐递增,如果"一个设备的输出效率"小于"转发设备瓶颈效率 / 传输的设备数量",那么这个设备必须跑在满速率

* 剩下的设备则会平分剩余的带宽,除非仍然有"一个设备的输出效率"小于"转发设备瓶颈效率 / 传输的设备数量"的情况出现

* 也就是说,C的最大速率`2 Mb/s`小于平均速率`12 Mb/s / 3 = 4 Mb/s`,所以C必须跑满

* A和B的最大速率在`12 Mb/s`,大于平均速率`12 Mb/s / 3 = 4 Mb/s`,所以A和B必须平分剩下的`12 Mb/s - 2 Mb/s = 10 Mb/s`,所以A和B都是`5 Mb/s`

* 那么,会不会存在一种情况,有N个最大速率全部小于平均速率的设备,然后这些设备把所有的带宽全部吃干净导致最大速率大于平均速率的设备没法平分剩余的带宽了?

* 答案是一定不会存在这种情况,用数学方式解决这个问题会比较简单
* 我们假设小速率设备有N个,大速率设备有M个,总输出速率为`R`
* 那么在最坏的情况,所有小速率设备的瓶颈速率都等于`R / (N + M)`,那么所有小速率设备的输出总和也才`(N * R) / (N + M)`,大速率设备仍然有`(M * R) / (N + M)`的总带宽

* 也就是说,最坏的情况下,这个算法会退化成完全公平策略!

* 当然,实际上我们并不会直接使用这个算法,一般在实际中,我们会使用趋近于这个算法的其他算法

* 不过我们可以总结一下这个算法为我们带来了什么:
	1. 首先就是足够的灵活,一旦有新的流增加,那么就会重新平分,如果有流减少,那么其他流就会平分这个空缺的带宽
	2. 保证了带宽的始终繁忙,保证了带宽始终被吃满
	3. 这个算法是分布式的,不存在任何其它机器作为宏观调控
	4. 没有任何一个流的带宽增高会不让所有速度低于他的流的带宽降低(换句话说就是一个流的带宽增高一定会伴随着带宽低于他的流的带宽降低,当然这在这个算法中不被允许,因为它需要公平)

#### 4.3 `TCP`的拥塞控制简述

* 本小节我们会简述一下关于`TCP`拥塞控制的原理,但是其具体细节我们会在之后详细说明

##### 4.3.1 转发设备与`max-min fair`

* 虽然我们说`max-min fair`是用于端的,但其实所有的跳也是`max-min fair`的
* 我们先来输出一个结论,还记得我们之前学过的`WFQ`(加权公平排队)吗?事实上,转发设备中的`WFQ`在理想情况基本上是一个接近`max-min fair`的算法

* 为什么?这里我们必须回顾一下`WFQ`
* `WFQ`为每个虚拟队列搞了一个叫做权重的东西,每个流能通过一个比例获得一个带宽大小,这使得每个流都能获得一个公平的带宽,这意味着他非常灵活,一旦有新的流,那么比例立刻改变,然后通过加权平分,一旦某个流没有包,那么比例也会改变,将这个无用带宽分给别的流

* 你会发现他给我们带来的特性和`max-min fair`其实非常相似,一样的非常灵活,一样的非常公平,一样的分布式,一样的保证了带宽始终被占满,更重要的,一样的"没有任何一个流的带宽增高会不让所有速度低于他的流的带宽降低"

* 甚至在最坏的点都是一样的,极端情况下会退化成完全公平策略

* 值得一提的是,你肯定觉得这个`WFQ`和`max-min fair`的关系比较奇怪,我们会在后面进行解释

##### 4.3.2 我们如何知道什么时候拥塞了?

* 从根本上控制拥塞,本质上需要通过控制发送方的输出速率来实现
* 但老实说端其实很难知道一条路径上有没有拥堵
* 所以我们需要一个算法或者说功能为我们描述什么地方拥堵了

###### 4.3.2.1 `ECN` (Explicit Congestion Notification)

* 这个算法其实很简单,发送方在发送完一个包之后,每个路由都有权利在这个包的某个位置写入某几个字节
* 那么这个包在走完"发送"这条路径之后,就会留下一串字节,这串字节描述了这条路径的拥堵情况,于是接收方回复ACK的时候,就会携带这串字节返回给发送方
* 于是发送方就能够知道中途哪个位置拥堵了

* PS:这个算法其实是用在`IP`协议上的

###### 4.3.2.2 `CWND` (Congestion Window, 拥塞窗口)

* 也可以叫做拥塞控制,拥塞避免等等

* 本质上这也不算是一个算法,他就是两个维护了一串字节的指针或者`index`这种,但是我们会在本小节讲一下为什么需要拥塞窗口

* 这个窗口能够告知拥塞情况的原因也很简单,下面我们来看看原理
* 首先,我们知道发送方并不会每次都发送一个包,他有可能会发送多个包
* 所以,势必会有一种情况,发送方发送了所有应该发送的包,他开始等待接收方回复的`ACK`
* 那么此时对于发送方而言,其实就已经浪费时间了

![[Pasted image 20251022190256.png]]

* 所以,有没有办法能够让发送方一直不停歇地发送?有的朋友有的
* 我们知道传输数据到网络也是需要时间的,比方说我把一个包放进网络花了整整`4ms`这种
* 一个包在网络中流动也是需要时间的,假设一个包在网络中需要跑`40ms`才可以到接收方,接收方回复的`ACK`跑到发送方也需要`40ms`
* 那么有意思地来了,如果发送方一次性发送`20`个包,那么他会在正好发送完最后一个包的时候正好接收到来自接收方的关于第一个包的`ACK`,此时发送方就可以接着发送下一个包了

![[Pasted image 20251022190855.png]]

* 于是我们发现一个有意思的现象,那就是如果我们不考虑拥塞问题,我们可以规划一个较大范围的包,并且按顺序发送,那么我们可能会找到一个平衡使得我能以最大效率发送所有的包,就像是刚刚的例子一样

* 但因为拥塞情况的存在,所以我们不能无脑把这个范围定死,网络的带宽是随时可能会变化的,所以我们需要一个东西维护这个范围,并且让他可以随时变大或者变小,如果网络带宽小就把范围变小一点,如果网络带宽大就把范围变大一点

* 这个东西就是拥塞窗口

* 和滑动窗口相对的,拥塞窗口其实是处在发送方,当发送方发送完一段数据之后,他不会把数据直接从内存中抹除,而是先放在拥塞窗口中

* 他用于控制发送方和接收方的数据传输中,允许在网络线路中跑的内容,换句话说就是描述网络中能够承载的数据量,如果阻塞了,接收方回复`ACK`说你有数据没到,那么意味着这个窗口太大了

##### 4.3.3 `AIMD` (additive-increase/multiplicative-decrease, 和性增长/乘性降低)

* 这是一个算法,这个算法会用在这里的缘由其实很简单,因为网络会阻塞,我们没法实现上一个小节说的那种理想的情况
* 换句话说,其实本质上网络完全不拥塞和全速传输其实是一件比较矛盾的事情
* 所以这个算法用于在尽可能保证网络通畅不拥塞的情况下还能够尽可能逼近上一个小节中说的例子

* `AIMD`规定:发送方每次成功传输并接受`ACK`之后,会把拥塞窗口增大`1 / Window Size`,如果某次的`ACK`显示没有正确送达,那么将拥塞窗口的大小直接砍半(也就是`* 1 / 2`)

![[Pasted image 20251022191829.png]]

* 所以实际看起来他是跳动的,并且是灵活的

* 而实际上,使用`AIMD`这个算法也是为了尽可能实现`max-min fair`
* 他也满足`max-min fair`要求的几个内容,灵活,尽可能吃满带宽,以及公平

* 这个算法和`CWND`被用在`TCP`上

##### 4.3.4 宏观来看

* 所以宏观来看,我们确实已经非常接近`max-min fair`了

* `AIMD`保证了端的`max-min fair`,而`WFQ`保证了跳的`max-min fair`
* 那么如果每个路径的每个机器都能保证`max-min fair`,那么在宏观上,整个网络就都是`max-min fair`的!

##### 4.3.5 总的来说

* 首先,如果要实现拥塞控制,这意味着我的从源头控制输出速率,否则依然可能会造成丢包,这意味着拥塞控制其实控制的是端而不是跳 

* 那么我现在知道的拥塞控制有两种方法: 
	1. 第一种: 发送方发送包之后,接收方回复一个`ACK`,那么如果中途某个地方发生拥堵,这一跳就在这个包中填入一串内容,表示这一跳堵了,然后接收方接受之后,把跳填入的这串内容拷贝到一个`ACK`包里头然后发回给发送方,此时发送方就会知道中途哪一跳堵了,但是这种方式其实比较麻烦,因为他需要每个跳进行配合,我们希望的是跳能够被动接受端的检测而不是跳主动输出检测信息,于是就有了第二种方式 
	2. 第二种: 我们知道,`TCP`协议中有一个叫做滑动窗口的东西,我们发现,一般情况下,发送方发送完一个窗口的包之后就会开始等待,知道`ACK`返回,有那么一种特殊情况,我们知道发送一个窗口(可能包含多个包)需要时间,每个包在物理线路和每一跳中的传输也需要时间,那么,如果"包在物理线路和每一跳中的传输需要的时间(包括往返)"正好等于"发送一个窗口(可能包含多个包)需要的时间",那么就会让发送方不间断地一直发送,因为中间没有等待间隔,每发送一个包都正好有一个`ACK`被发送方接收,于是,我们需要一个东西控制这一堆包,即拥塞窗口(`cwnd`) 

* 而拥塞窗口只是一个窗口,我们还需要一个算法来控制这个窗口,于是就有了`AIMD`(和性增长/乘性降低)算法用于控制拥塞窗口的行为,其实控制这个行为的方式也很简单,他只有两个法则: 
	1. 如果发送方接受接收方正确的`ACK`,那么发送方会把自己的拥塞窗口扩大`1 / Window Size` 
	2. 如果发送方接受接收方错误的`ACK`(也就是说接收方表示你有包丢失了),那么发送方就会把自己的拥塞窗口减半 

* 这是一个动态的窗口,意味着发送方的输出速率可能不是固定的,发送方以这种行为,控制"拥堵"与"尽可能发送更大的窗口"的平衡



##### 4.3.3 `AIMD` 为网络改变了什么

* 在明确进入这一小节之前,我希望我们能看一下`CS144`中给的这个动画,我觉得这个动画可做得太帮了,完全符合我对于优质动画的想象!(不过缺点是他要求你有`flash`,考虑到这个动画诞生的时间,我觉得咱也不能多说啥)
* http://guido.appenzeller.net/anims/

* 接着看看这个图(这个图的前提和那个网站`flash`动图一样,我们需要假设交换设备输出端的速率小于发送方的输出速率)

![[Pasted image 20251022225033.png]]

* 值得注意的是,这个图是最佳情况,当然还是会有非最佳情况的,我们会之后考虑
* 所以你能发现一个现象,交换设备的缓存负载会随着拥塞窗口的增大而增大
* 这很好理解,你能直接看这个动图理解为什么会发生这种情况,但是用文字描述的话嘛
* 简单来说就是线路中存在的包太多了,且线路中的包变得越来越多,导致缓存不得不存储这些包,要不然就会丢包
* 拥塞窗口越大,线路中的包越多,线路中的包越多交换设备缓存的负载就会越大
* 另一个值得注意的是,交换设备的缓存负载越大,那么一个包的`RTT`(往返时间),也就是说延迟会越大(这是最佳情况,因为你知道的,`RTT`是会存在一个下限的),因为交换设备的缓存队列的负载增大导致排队时间更长了

* 因为`RTT`和`Window Size`是成比例增大的,所以一般情况下,我们甚至可以把两者相除得到一个常数: `Window Size / RTT = R`
* 但这里有一种情况除外,最开始的时候,`Window Size`还很小,此时`RTT`完全和交换设备缓存负载无关,因为此时还没负载呢,交换设备连输出端都跑不满呢

* 所以一开始的时候,其实发送端仍然要等待`ACK`回复才可以接着发送,这中途发送端就只能等待,什么都不能做,直到`RTT`开始与交换设备缓冲区开始相关

* 那么,如果不是最佳情况,会发生什么?
![[Pasted image 20251023135038.png]]
* 那么这个图就是非最佳情况发生的事情
* 这个图实际上是缩小了一点交换设备缓冲区造成的结果
* 这个图告诉我们了什么?
* 如果缩小缓冲区,就会使得交换设备缓冲区有一段时间内没有任何东西缓存,同时输出端还在这段时间内跑不满,这点你可以看`RTT`那个图,因为缓冲区没东西,所以不需要排队,也就没有排队造成的延迟,所以你能看到有一段时间`RTT`是一条直线,因为此时`RTT`已经和交换设备缓冲区不相关了

* 为什么会造成这种现象?
* 主要是因为发送方会有窗口减半这个操作!
* 如果交换设备缓冲区太小,那么就太容易触发发送方的减半操作,但发送方的减半操作可不是一个小数目,这个减半操作触发太快,会导致发送方的输出速率减得比交换设备输出速率还要低,那么此时对于交换设备来说,输入的速率比输出的速率还小,那么自然是跑不满下行带宽,交换设备的缓冲区也自然不会有任何东西需要缓存

* 那么意思是,我们需要为交换设备的缓冲区设计一个合理的大小,那么到底多大是合理的?

* 一个结论是`Buffer Size = RTT * Out Link rate`,也就是说缓冲区大小应该等于往返延迟乘以交换设备输出速率
* 为什么是这个大小?

* 那么我们可以观察一下,`RTT * Out Link rate`这个值似乎大于等于处于交换设备下行线路的所有包的数量,也就是说交换设备最高可以让下行线路中有`RTT * Out Link rate`这么多包

* 那么如果我让交换设备缓冲区也能承受这么多包,那么交换设备缓冲区和交换设备下行线路一共能够承受`2 * RTT * Out Link rate`的包,那么当丢包发生时,输出端速率减半,也只会使得缓冲区的包直接归零而不会影响到下行线路的负载


#### 4.4 多流工作

* 在多流工作中,你将会看到一个计算机模型推导成数学模型的过程,推导成数学模型不是为了计算些什么,而只是为了在数学层面论证多流工作中的一些规律,老实说你仍然可以不借助数学模型推断出这些规律,但是CS144使用了数学模型,虽然对我这个数学渣不太友好(头脑风暴了好一会儿hhh),但是从结果来看,确实还是比较深刻的

* 本小节我们会了解一个新的概念,"吞吐量",只不过我觉得"吞吐量"这个翻译不太清晰,所以我把它定义为"吞吐速率",他其实就是广义上学术中的"吞吐量"

* 首先我们还是得先看看图,左边的是单流模式下的拥塞窗口大小和`RTT`的状态,右边是多流模式下仅拥塞窗口大小的状态

![[Pasted image 20251027103556.png]]

* 为什么右边没有`RTT`?
* 在多流模式下,一个交换设备中会同时存在很多个流,当交换设备中存在的流足够多时,当前流带宽的变化对于交换设备缓存占用量的影响微乎其微,就像是你每天往长江倒一桶水,某天你故意没倒,那对于长江的水量其实也没多少影响
* 那么我们可以认为多流模式下的`RTT`几乎是恒定的,换句话说变化过小,不值得我们考量`RTT`的变化
* 所以在微观看,多流模式下,每个固定的`RTT`后,窗口大小`+1`,单流模式下因为窗口大小和`RTT`强相关,所以`RTT`会变长
* 所以体现在宏观上,单流模式下就是以曲线增长,而多流模式下几乎就是纯粹的直线

* 我们把多流模式的图单独取出来再次精简一下

![[Pasted image 20251027110123.png]]

* 那么问题来了,`A`的面积是多少?
* 很简单,无非就是一个梯形的大小,直接算出来得到`3 / 8 * W^2`
* 现在你一定有一个问题,明明横轴是时间,为什么他的值(也就是把梯形旋转`90`度之后的高)却可以是`1 / 2 * W`?
* 我们假设`W`只是一个未知量,而不是一个单位,那么纵轴的完整表达应该是`倍率 * W`,单位是`bits/Bytes`,也就是和我们现在的表达方式一样
* 因为微观上看他是锯齿状的,所以窗口大小每有一次增长,就需要多花一次`RTT`,那么此时窗口有`1 / 2 * W`次增长,那么就需要花`1 / 2 * W`次`RTT`,所以,梯形的高就可以是`1 / 2 * W`,单位是`RTT Time`

* 所以我们计算出来的`A`的面积是`3 / 8 * W^2`,单位是`bits * RTT Time`或者是`Bytes * RTT Time`
* 那么,计算`A`的面积有什么意义??
* 它代表在`1 / 2 * W`的`RTT Time`内,发送方发出的窗口的积分
* 所以,我们可以计算出平均窗口大小是`(3 / 8 * W^2) / (1 / 2 * W) = 3 / 4 * W`,单位是`bits`或者`Bytes`

* 因为窗口大小除以`RTT`时间会等于吞吐速率(我们要始终切记,`RTT`是往返时间,也就是说,一个包在确认发出和确认接收之间一定会有`RTT`这一段时间,我们之前分析过,只要窗口足够大,那么我们可以看作发送方是连续不断发送的,所以吞吐速率也就是吞吐量可以这么算,换句话说我们可以通过窗口大小除以发送窗口大小花的时间计算发送效率),如果`RTT`时间的单位是`s`,那么我们可以通过平均窗口大小计算出平均吞吐速率(也就是平均吞吐量),单位是`bits/s`或者`bytes/s`

* 所以平均吞吐速率`T = (3 / 4) * (W / RTT)`

* 另一个我们需要计算的是丢包率`p`,丢包率表示多少个包会丢一次,那么这里每`A`个包就会有一次丢包,所以丢包率`p = 1 / A = 8 / (3 * W^2)`,所以换算一下,就得到`W = sqrt(8 / (3 * p))`

* 我们把`W`带入到`T = (3 / 4) * (W / RTT)`就会得到一个平均吞吐速率和丢包率,`RTT`之间的关系
* 即`T = sqrt(3 / 2) * (1 / (RTT * sqrt(p)))`
* 于是你发现一个很有意思的事情,如果延迟越大,那么吞吐速率其实越低,换句话说就是堵了,堵了当然带宽低(当然也有可能是两端太远了,两端太远会导致包的确认时间很长,意味着单位时间能循环的次数变少,速率也就降低了),另一个问题就是如果丢包率很高,同样带宽也很低,因为一丢包窗口减半,所以带宽同样上不去

* 这些结论其实只需要你对网络有一点了解就能推断出来,但这里我认为用数学模型也不错


#### 4.5 `TCP Tahoe`

##### 4.5.1 历史问题

* 这里我们需要了解一点点历史问题

* 在1986年及之前已经就有`TCP`,协议了,但是那时候的`TCP`协议还是相对来说非常原始,或者说,"简陋"(?)
* 因为那时候的`TCP`有着一个非常严重的问题

* 我们知道,`TCP`在发送端会维护一个`cwnd`表示已经发出但还没有确认的数据
* 那时候的`TCP`原始到什么情况呢,大概就是那种非常死板的直接开始发送整个窗口大小的那种情况
* 那时候的`TCP`不会试探网络究竟能承载多少数据,他只会在三次握手并获得了接收端的窗口大小后,无脑发送他觉得自己能发送的最大量的数据
* 但那时候的网络基建没那么发达各个线路的通信效率也没有那么高,所以你会发现发送端和接收端的最大带宽会比通信线路的最大带宽高出来好几倍甚至好几十倍!
* 所以这会演变成一个非常离谱的问题:丢包率高得吓人,每次发一堆包出去,结果几乎每次接收端都发送回3次`ACK`回来说你某个包没到,并且最恶心的事情,丢包率一高,那么总时间中处于等待超时的时间的占比就会很高
* 所以就会出现爆发式的发一堆包,然后等待超时,然后重传并且又爆发式的发一堆包,然后又等待超时的情况

![[Pasted image 20251028232028.png]]

* 在这个图中,你也许会发现另一个问题,因为爆发式发一堆包的这种情况存在,所以你会发现这个"原始"的`TCP`哪怕在重传之后的发包也依然是爆发式发包,这就意味着哪怕只有一个包丢了,也会导致之后的所有包全部需要重传一边,因为发送方普遍认为某一个包丢了的最坏情况是后面的所有包全丢了

* 以上问题,最终演变成了一场灾难,1986年斯坦福大学的NSFNet就因为这个问题几乎瘫痪

* 所以,我们得解决以下问题:
	1. 什么时候发包?
	2. 发多少包,如何发包?
	3. 如何接收`ACK`

* 在这之后,`TCP Tahoe`面世了

##### 4.5.2 `CWND`

* 在真正学习`TCP Tahoe`的算法之前,我们需要了解一个之前可能不太熟悉的东西,当然,就一个术语而已,`MSS`(Maximum Segment Size, "最大分段大小")
* `MSS`表示当前发送端和接收端约定的能够发送的包最大能有多大
* 比方说一个包最大`130 Bytes`,也就是`MSS`为`130 Bytes`,发送方的窗口能放`10`个包,那么发送方窗口大小就是`1300 Bytes`

* 那么,`TCP Tahoe`只有两种状态,"慢启动"与"拥塞避免"

![[Pasted image 20251029001640.png]]

* 在慢启动状态下,每`RTT`窗口大小都会翻一倍,比方说当前`RTT`窗口大小是`2`,那么下一个`RTT`窗口大小是`4`,换句话说其实是每次发送方接收到`ACK`时,`CWND`会扩大一个`MSS`,因为当前`CWND`的大小为`2 * MSS`,所以会有两次`ACK`,所以`CWND`会在一次`RTT`中接收两次`ACK`,所以`CWND`会在一次`RTT`之内翻一倍,`CWND`几乎呈现指数级增长

![[Pasted image 20251029002201.png]]

* 而在拥塞避免的状态下,每`RTT`窗口大小都会只会增加一个`MSS`,那么意味着每`ACK`只会增加`MSS^2 / CWND`的大小,所以拥塞避免下,实际`CWND`几乎是线性增长的

* 当然,`TCP Tahoe`对于`CWND`肯定没有那么简单
* 我们可以看看状态机

![[Pasted image 20251029102425.png]]

* 毕竟我们不能让`CWND`无限指数级增长,所以状态机中还引入了一个叫做`ssthresh`(慢启动阈值)的东西
* 当慢启动导致`CWND`的大小超过了这个阈值,就会转到拥塞避免状态下
* 换句话说其实就是在一定程度下快速探测(慢启动)网络承载的上限,当接近上限的时候采用缓慢探测策略(拥塞避免)一点点累加

* 当丢包或者超时发生时,`CWND`会重新回到`1`,因为网络可能已经发生了波动,我们需要重新探测网络承载上限,但相对的,我们可以不采用原先的`ssthresh`,而是采用`CWND / 2`当作`ssthresh`
* 因为`TCP Tahoe`的保守估计是,无论网络如何变化,保守都有`CWND / 2`我可以作为快速探测
* 同时`ssthresh`的灵活性也保证了`CWND`会随着网络负载变化而灵活变化
* 所以其实总的来看,`CWND`应该会这样变化

![[Pasted image 20251031162515.png]]

* 当然你也能发现,如果在慢启动下也丢包,那他依旧会让`ssthresh = CWND / 2`且重置`CWND`

##### 4.5.3 超时估计

* 超时估计修正也是`TCP Tahoe`对于旧`TCP`的主要变革之一,首先我们得先知道老`TCP`的超时估计是在干嘛

* 首先要解决一个疑问,为什么需要超时估计?
* 超时估计主要用于估计超时时间,换句话说就是我搞一个计时器,用于判断一个包会在多久之后属于超时

* 旧`TCP`是这样做的:
	1. 我们设`RTT`均值为`r`
	2. 设一个权重为`p`(`p > 0` & `p < 1`)
	3. 设实际测量值为`m`
	4. 那么`new_r = p * old_r + (1 - p) * m`,即一个包的`RTT`我们估计为`new_r`,`p`一般会取`0.9`
	5. 如果一个包在`B * new_r`之内还没有被确认接收,那么我们判断这个包出现丢包了,一般`B`这个常数取`2`

* 乍一看似乎挺好的一个算法对吧,这个算法会根据当前实际情况更新`r`,确实挺灵活的,测量值高,那他就会增加`r`,测量值低就会降低`r`
* 但他有一个致命的缺陷,这点我们需要举一个实际的例子

* 假设一个包的`RTT`目前在`80ms`,并且我的`old_r`为`100ms`,那么`new_r`就会是`0.9 * 100 + (1 - 0.9) * 80 = 98ms`,目前来看其实还挺好的对吧
* 那么如果一个包的`RTT`目前在`400ms`,并且我的`old_r`为`100ms`,那么第一轮实际算下来会是多少?才`130ms`?!
* 如果测量值依旧保持`400ms`,第二轮算下来是`157ms`?!
* 所以,使用第一轮估计的包,估计得太小了,乘上`B`之后为`260ms`,但实际值是`400ms`,那么这个包依旧被认为丢包了
* 使用第二轮估计的包,乘`B`之后为`314ms`,依旧被认为丢包
* 换句话说这个算法目前来看太激进了

* 我们再看另一个极端例子
* 假设一个包的`RTT`目前在`100ms`,并且我的`old_r`为`100ms`,那么第一轮`new_r = 100ms`
* 这个值对于实际只有`100ms`的包来说,实际我们按照`2 * r = 200ms`判断这个包有没有丢,这其实太保守了

* 所以,这个算法最大的问题是,他变化得太慢了!特别是对于突然的大幅的网络波动!因为他的变化其实是相对固定的,或者说他的变化没有学习能力,他不会因为网络剧烈波动而修正变化幅度,或者说变化幅度修正得不够大,我们需要一个网络波动小时,变化幅度修正小,网络波动大时变化幅度就修正得大的算法

* 换句话说,我们需要一个网络波动小就激进,网络波动大就保守的算法

* 那么我们看看`TCP Tahoe`做了什么:
	1. 设`RTT`估计值`r`,测量值`m`
	2. 设误差为`e = m - r`
	3. 设权重为`g`,像旧算法一样更新`new_r = r + g * e`(虽然算法不太一样,但目的是一样的),`g`一般取`1/8`
	4. 设另一个权重为`h`,`RTT`方差为`v`
	5. 重新计算`new_v = (1 - h) * old_v + h * |e| = old_v + h * (|e| - old_v)`,`h`一般取`1/4`
	6. 超时阈值`Timeout = r + 4 * v`

* 这里我们举三个例子
```Text
old_r = 100ms, m = 400ms
e = 300ms
old_r = 100 + 37.5 = 137.5ms
old_v = 200ms
new_v = 200 + 0.25 * 100 = 225ms
Timeout = 137.5 + (4 * 225) = 1037.5ms

old_r = 100ms, m = 120ms
e = 20ms
new_r = 100ms + 2.5 = 102.5ms
old_v = 60ms
new_v = 60 + 0.25 * (-40) = 50ms
Timeout = 102.5 + 4 * 50 = 302.5ms

old_r = 100ms, m = 120ms
e = 20ms
new_r = 100ms + 2.5 = 102.5ms
old_v = 10ms
new_v = 10 + 0.25 * 10 = 12.5ms
Timeout = 102.5 + 4 * 12.5 = 152.5ms
```

(以下关于数学的内容如果有误请务必提出来谢谢)
* 我们知道,如果一个差值用一个均值减去一个实际值表示,宏观看这些差值,我们可以得到方差,那么这个方差可以用于表示当前这个分布稳不稳定
* 那么`v`其实就是一个"均值",只不过这个均值是差值的均值,或者说用于评判当前波动稳不稳定的值
* 当前`v`,也就是`new_v`的计算方式是上一轮不稳定程度`v`,也就是`old_v`与本轮误差`|e|`的加权平均
* 换句话说我通过上一轮的不稳定程度与现在的误差综合评判出当前稳不稳定
* 更换句话说,这里的`v`其实是过去误差`|e|`的平滑平均,简单来说,我综合考量了上一次的不稳定程度和现在的误差,所以他会显得更为平滑一些,因为我们不能直接采用当前误差或者上一次的`v`,这样太死板了,用一句很梗的话说:"这个世界就是一个巨大的折中",我折中考虑了两边的情况,所以会很平滑

* 所以你可以看到一个有意思的现象,如果`old_v`更小,那么我认为上一次计算其实就已经很稳定了,那么这一次计算就可以不需要那么保守,如果上一次的`v`也就是`old_v`非常大,那么我们认为这一次也不一定会非常稳定,所以`new_v`会很大,就需要保守一些,最终`Timeout`就很大

* 这个图可以非常好的反应这个结论(来自于CS144)
![[Pasted image 20251031114827.png]]

##### 4.5.4 自时钟

* `TCP Tahoe`引入了一个非常简单但厉害的设计控制发包的速度,即自时钟(self clock),我们可以简化为这么一个图

![[Pasted image 20251031161042.png]]

* 在这图中,发送方与接收方的带宽往往会大得多,但传输链路的带宽就这么大,所以高频率发包最终也会因为传输链路带宽问题最终速度变慢,到接收方的时候,此时速度就远比接收方的最大带宽要低了

* 那么这意味着接收方回复`ACK`的速度其实和接收包的速度保持一致,或者说对于接收方而言,接收包和发送`ACK`,这两情况中,每个包的间隔基本差不多

* 那么回到发送方的时候,他们的间隔也会差不多,因为已经被链路降低过一边带宽了,并且一个`ACK`实际上非常小,所以回复的时候,带宽就很难降低了,所以发送方会以非连续的方式收到`ACK`,这时发送方会参照这个回复`ACK`的间隔发包,这样就基本掌握了当下发送方在网络中能够获得的最大带宽,然后调整发送速度

##### 4.5.5 快速重传

* 这是一个补充内容
* `TCP Tahoe`存在一个快速重传机制,当发送方收到了连续三个`ACK`的时候,`TCP Tahoe`首先会进行快速重传,也就是把丢的包先重传一边,然后才会修正`CWND = 1`进行慢启动

#### 4.6 `TCP Reno`

* 其实,本质上`TCP Reno`对于`TCP Tahoe`的改进其实比较少,总体上还是基于`TCP Tahoe`的这套原则,不过`TCP Tahoe`其实对于现代来说只是提供了理论基础,实际应用方面,后人做了非常多的改进,就比方说`TCP Reno`

* `TCP Reno`和我们下一个小节会聊到的`TCP NewReno`都是比较贴近现代`TCP`的新东西,虽然我个人认为`TCP Tahoe`也很贴近就是了

* `TCP Reno`做的一个比较重要的内容,就是"快速恢复"与"快速重传",我们直接看图,看看`TCP Reno`做了什么新操作

![[Pasted image 20251031162821.png]]

* 我们知道(当然,前面几个小节对于这里可能没有提得非常清楚),有两种情况会导致`CWND`减少,一种是"三次重复`ACK`",也就是丢包,另一种是`Timeout`

* 那么我们可以看到`TCP Tahoe`对于这两者其实都是没有任何优化的,他认为这两种情况都是比较严重的情况,所以直接让`CWND`归零了
* 而`TCP Reno`其实不认为三次重复`ACK`是一种严重的情况,他认为此时网络还没有非常拥塞,毕竟`ACK`还可以传回来,所以他乐观的认为这次丢包可能只是偶然的网络波动造成的,所以他不会把`CWND`直接归零,而是在快速重传完毕(和`Tahoe`一样)之后修正`CWND = CWND / 2`,也就是砍半,也就是说直接不探测网络承载

* 但如果是超时,他的判断方式和`TCP Tahoe`一样,他认为超时是网络拥塞极度严重导致的,所以他会将`CWND`归零,然后重新探测

* 然而快速重传中的一个机制对于`TCP Reno`则会拖慢发送效率
* 我们首先来看一下`TCP Reno`到底有什么问题
* `TCP Reno`实际上应该是这样的(仅丢一个包的情况),所以这里我们在引入快速重传之后需要修正一下这个图
![[Pasted image 20251031172536.png]]

* 你发现了吗,在每次重传之后,发送方都需要等待一段时间,我们知道,发送方能在其他地方发送得这么快的原因就是因为他维护了`CWND`,但是在重传的时候,我们仅需要等待一个包,也就是这个丢的包,而不是等待一整个窗口

* 一旦需要等待一个单独的包,那么就意味着需要等待一整个`RTT`时间,在这一段`RTT`中,发送方什么也做不了,只能进行等待,所以这会降低效率,下一小节我们聊到的`TCP NewReno`就会着重解决这个问题,同时还会解决另一个更加严重的问题

#### 4.7 `TCP NewReno`

* 而`TCP NewReno`则是对于`TCP Reno`的一个新的改进,他让"快速重传"(注意不是快速恢复)变得更快了,而关于`Timeout`则还是和`TCP Reno`&`TCP Tahoe`一样

* 但我们在`TCP Reno`考虑一下这个场景,`TCP Reno`的`CWND = 8`时
> 1. 发送方发送`1 2 3 4 5 6 7 8`
> 2. 结果`2 3 4`丢失
> 3. 那么接收方会触发`dupACK`(多次重复`ACK`)
> 4. 发送方收到了连续三次`ACK = 2`之后直接触发快速重传
> 5. 发送方触发快速恢复
> 6. 发送方回到拥塞避免
> 7. 结果发送方发现又收到了来自接收方的`dupACK`,`ACK = 3`
> 8. 于是快速恢复打了水漂,再次触发快速重传,然后又回到拥塞避免,于此往复

* 结果你会发现,他似乎一直在兜圈子,处理效率非常慢,每次重传一个包都要等一个`RTT`时间

* 我们再来看另外一种更加极端的场景,同样是`TCP Reno`的`CWND = 8`时
> 1. 发送`1 2 3 4 5 6 7 8`
> 2. 结果`2 3 4 5 6 7 8`丢失,也就是`2`后面的全部都丢了 
> 3. 所以一开始会向上一个场景一样触发快速重传,重传完`2`之后回到拥塞避免
> 4. 但重传完`2`之后发生了一个很离谱的问题,接收方认为发送方就只发了`1 2`,但发送方认为自己`1 ~ 8`全都发了
> 5. 所以然后重传完`2`之后,接收方不会触发`dupACK`,而是仅发送一次`ACK = 3`
> 6. 因为只回复了一次`ACK = 3`,于是发送方以为`3`已经被接收了
> 7. 这就误会深了,发送方认为`3`被接收了,等待另一个`ACK`,接收方觉得`3`一直没发一直在等待`3`
> 8. 然后两者就一点东西都不发给对方,全部都在等待,最后直到发送方认为已经`Timeout`了(触发`RTO`,即"Retransmission Timeout","重传超时时间"),于是重置`CWND`...

* 在这个场景中,因为连续丢包问题,导致发送方和接收方全部都在等待对方,最后不得不以超时收场,如果出现丢包还要等超时收场,那么效率就会可想而知的低

![[Pasted image 20251101224630.png]]

* 老实说,我觉得得先从图看起
* 在这个例子中,`CWND`初始大小为`12`,那么一开始的窗口范围是`1~12`

* 你会发现一个非常有趣的事情,丢包之后,`CWND`会砍半,但同时,窗口在丢包之后依旧会向右移动,比方说图中的标记,你能看到在快速重传`pkg3`的时候`CWND`甚至已经向右移动了`3`位
* 这是因为在`TCP NewReno`中,几乎所有的`ACK`都会导致`CWND`移动,哪怕是重复的`ACK`,这是为了保证在丢包之后依旧可以发包过去,保证等待重传之后的一个`RTT`内不会浪费时间,继续压榨发送方
* `TCP NewReno`认为既然接收方能发`ACK`回来,那么链路还没有彻底堵死,那我就接着发东西,只不过发得没有以前那么多了
* 所以在把之前丢的包全部传回去之前,发送方会一直保持这个`CWND`大小发包,此时不论返回的`ACK`是多少,发送方都认为窗口最左侧的包已经到了,然后右移窗口,无脑往后发包
* 也就是说,一个包丢失并不会影响`CWND`的继续扩大与移动,而是进行快速重传并标记最左侧丢失的包,直到`CWND`内与其左侧所有丢失的包全部被补上才会退出快速重传
* 所以我似乎可以这么形容`TCP NewReno`: 不管发送方收到什么`ACK`,反正只要是`ACK`,就一定会让`CWND`右移一位,如果右移后窗口里有了一个还没发送的包,那么就发送这个包
* 所以实际上,`TCP NewReno`允许同时存在两种状态


#### 4.8 为什么我们需要`AIMD`?

![[Pasted image 20251103101710.png]]

* 1988年,`Chiu Jain Plot`最初由David D. Clark和Van Jacobson提出,也就是上面这个图
* 这个图的横坐标和纵坐标表示两个不同流的速率,表示用一个物理路径中跑者的两个流
* 然而,这里存在一个根本矛盾,用户的需求是尽可能公平,也就是让`A = B`,而网络服务商的需求是尽可能不浪费带宽,也就是让带宽跑满,让`A + B = C`

* 所以只有一个点是最佳的点,能符合两者的要求,也就是这个交汇点,这个黄色的点
* 所以问题落在了怎么尽可能接近这个点

* 这是`AIMD`做的事情
* 如果`A + B > C`,也就是橙色的这个部分,那么一旦某个交换设备缓冲区满了,就会丢包,于是`AIMD`会做乘性相减,那么原来占用高的流会减得更多,占用少的流减得更少,最后就使得最终会非常接近交汇点,然后在交汇点附近沿着`A = B`这条线震荡


### 休息一下吧

* 自此,你已经学习完了将近一半的内容了,或许你可以找个时间去公园溜达几圈,或者和好朋友出去吃个饭什么的

### 5 一些应用与`NATs`

#### 5.1 `NAT`

* 关于`NAT`,你或许在之前的某一些章节中就已经了解了一部分`NAT`的知识了,不过我觉得我们得重新复习一下

##### 5.1.1 使用`NAT`的初衷及其基本原理

* `NAT`被提出的理由其实很简单,主要是因为人们发现`IPv4`协议的地址量越来越少了,最后可能会出现无地址可用的情况,所以我们需要一个`NAT`,让更少的人拥有公网`IP`地址,换句话说,现在一个普通人申请一个公网`IPv4`地址其实非常困难,就是因为`IPv4`地址太稀缺了,很多用不上公网`IP`的人,其实占着更为稀缺的公网`IP`是一件不好的事情,所以现在这些人绝大部分都会使用`NAT`技术,安全,省心,同时还不占用公网`IP`,换句话说就是找个师傅装`WIFI`

* 那么`NAT`的原理很简单
* 每个`NAT`后面可以维护多个本地`IP`地址,然后当这些用户需要访问外部网络的时候,`NAT`就会帮他们转发

* 我们举个例子
* 比方说`NAT`后面有3个设备,这是他们的本地`IP`地址:
	1. 设备1:`192.168.10.100`
	2. 设备2:`192.168.10.101`
	3. 设备3:`192.168.10.102`

* `NAT`自己也会有一个地址,这个是公网`IP`地址,比方说我们假设`NAT`的公网`IP`地址为:`162.7.69.180`
* 当设备1想要访问一个公网`IP`:`177.61.2.108`的时候,他会发包`SRC:192.168.10.100 DST:177.61.2.108`给`NAT`,`NAT`会修改这个包的`IP`为自己的地址,那么此时这个包应该是这样的`SRC:162.7.69.180 DST:177.61.2.108`,然后发送到网络
* 当用户主动发出第一个包之后(当然,这个包也许是`SYN`什么的),`NAT`就会记录这个映射关系,我们假设设备1在端口`6969`访问外部设备,那么这里就可能建立了这样的映射关系:`192.168.10.100:6969`<-->`162.7.69.180:1314`
* 这个外部的公网`IP`会因为这个映射关系,短暂的进入`NAT`的"白名单"(具体是怎么进入"白名单"的,需要详细了解`NAT`的种类,不同的`NAT`种类机制可能都不太一样)
* 此时外部`IP``177.61.2.108`如果访问该设备,就只需要给`NAT`的`162.7.69.180:1314`发包就行了
* 换句话说,这个`177.61.2.108`其实以为与自己交流的`162.7.69.180`就是用户的地址,但实际上不是用户地址,只是个`NAT`而已
* `177.61.2.108`发包给`NAT`之后,`NAT`也会修改`IP Header`的内容,根据映射关系把`SRC:177.61.2.108 DST:162.7.69.180`修改成`SRC:177.61.2.108 DST:192.168.10.100`然后转发给设备1

* 如果你想了解更多关于`NAT`技术的内容,你也可以访问这个`RFC`:https://www.rfc-editor.org/rfc/rfc1631.html

##### 5.1.2 常见的`NAT`种类

* 常见的`NAT`有四种:
	1. 全椎`NAT`: 几乎完全无限制
	2. 受限锥`NAT`: 通过`IP`限制外部设备的访问
	3. 端口受限锥`NAT`: 通过`IP`+`Port`限制外部设备访问
	4. 对称`NAT`: 特殊类型,我们会在后面详细聊到

###### 5.1.2.1 全椎`NAT`(Full Cone NAT)

* 这是最开放也是最没有限制的`NAT`类型

* 只要本地设备访问外部设备一次,那么几乎任何外部设备都可以随意访问这个本地设备
* 全椎`NAT`不会映射外部设备的`IP`,而是映射`NAT`自己的`IP`+`Port`

* 我们打个比方,现在有以下两个本地设备:
	1. 设备1: `192.168.10.101`
	2. 设备2: `192.168.10.102`

* `NAT`的公网`IP`是`176.10.9.88`
* 现在设备1在端口`6969`访问了一个外部设备`133.5.192.10`,于是`NAT`做了映射:`192.168.10.101:6969`<-->`176.10.9.88:1001`,那么此时任何外部设备都可以向`176.10.9.88:1001`发送包以访问本地`192.168.10.101:6969`

* 当然,这种映射也不是永久的,仍然是临时的,一旦映射的设备没有任何流量,那么视为这个设备已经断开连接,就会将相关的映射移除

* 那么简单来说,全椎`NAT`就是把本地`IP`地址映射成了同一公网`IP`+不同端口的形式
* 当然,这个例子其实就是我们之前讲解原理的时候举的例子,几乎一模一样,所以全椎`NAT`也几乎是最简单的`NAT`,其他`NAT`其实本质都是在全椎`NAT`上做文章

![[Pasted image 20251104224556.png]]

###### 5.1.2.2 受限椎`NAT`(Restricted Cone NAT)

* 受限椎`NAT`很简单,只是在全椎`NAT`基础上,多加了一个`IP`映射而已,换句话说就是现在需要验证外部设备的`IP`了

* 依旧是之前的例子,现在有以下两个本地设备:
	1. 设备1: `192.168.10.101`
	2. 设备2: `192.168.10.102`

* `NAT`的公网`IP`是`176.10.9.88`
* 现在设备1在端口`6969`访问了一个外部设备`133.5.192.10`,于是`NAT`做了映射:`192.168.10.101:6969`<-->`176.10.9.88:1001` & `133.5.192.10`,那么此时只有`IP`为`133.5.192.10`的外部设备允许向`176.10.9.88:1001`发送包以访问本地`192.168.10.101:6969`,其他设备全部会因为`IP`没法通过导致返回一个`ICMP`

* 如果本地设备有一段时间没有与外部设备交换数据了,那么这条映射关系可能会被删除

* 相较于全椎`NAT`来说,受限椎`NAT`已经非常安全了,毕竟只有一个受限`IP`能够访问到本地设备了,那么意味着能访问到本地设备的`IP`的数量将从几乎无限下降到`1`

![[Pasted image 20251104224607.png]]

###### 5.1.2.3 端口受限椎`NAT`(Port Restricted Cone NAT)

* 在受限椎`NAT`上,端口受限椎`NAT`引入了外部设备的`Port`作为映射关系的一部分
* 依旧是之前聊过的例子,现在有以下两个本地设备:
	1. 设备1: `192.168.10.101`
	2. 设备2: `192.168.10.102`

* `NAT`的公网`IP`是`176.10.9.88`
* 现在设备1在端口`6969`访问了一个外部设备`133.5.192.10:9191`,于是`NAT`做了映射:`192.168.10.101:6969`<-->`176.10.9.88:1001` & `133.5.192.10:9191`,那么此时只有`IP`为`133.5.192.10`且端口为`9191`的外部设备允许向`176.10.9.88:1001`发送包以访问本地`192.168.10.101:6969`,其他设备全部会因为`IP`或者`Port`没法通过导致返回一个`ICMP`

![[Pasted image 20251104224617.png]]

###### 5.1.2.4 对称`NAT`(Symmetric NAT)

* 这是一个非常特殊的`NAT`,在聊对称`NAT`,之前,我们首先得先聊聊受限椎和端口受限椎`NAT`的另一个机制

* 就拿端口受限椎`NAT`来说,现在有以下两个本地设备:
	1. 设备1: `192.168.10.101`
	2. 设备2: `192.168.10.102`

* `NAT`的公网`IP`是`176.10.9.88`
* 现在设备1在端口`6969`访问了一个外部设备`133.5.192.10:9191`,于是`NAT`做了映射:`192.168.10.101:6969`<-->`176.10.9.88:1001` & `133.5.192.10:9191`

* 如果设备1在端口`6969`访问了另一个外部设备`133.5.192.11:5151`,那么`NAT`新增映射:`192.168.10.101:6969`<-->`176.10.9.88:1001` & `133.5.192.11:5151`

* 也就是说,无论访问的外部设备怎么变化,新增的映射关系在能够复用原来的映射关系的时候就会直接复用,换句话说,只要本地设备的`IP`和端口没变化,那么映射的`NAT`的`IP`和端口就允许不变化

* 如果设备1在端口`6970`访问了另一个外部设备`133.5.192.12:1000`,那么`NAT`会做映射:`192.168.10.101:6970`<-->`176.10.9.88:1002` & `133.5.192.12:1000`

* 如果本地设备的端口变化了,那么映射中`NAT`的端口也会变化

![[Pasted image 20251104224655.png]]

* 但对称`NAT`则相反,如果我们再次使用这个例子带入到对称`NAT`中

* 现在设备1在端口`6969`访问了一个外部设备`133.5.192.10:9191`,于是`NAT`做了映射:`192.168.10.101:6969`<-->`176.10.9.88:1001` & `133.5.192.10:9191`

* 如果设备1在端口`6969`访问了另一个外部设备`133.5.192.11:5151`,那么`NAT`新增映射:`192.168.10.101:6969`<-->`176.10.9.88:1003` & `133.5.192.11:5151`

* 也就是说,对称`NAT`不考虑本地设备的端口,他一定不会复用原来的映射关系,一定会建立新的映射关系

![[Pasted image 20251104224632.png]]

* 或者对于这两者,我们换一个更为简单的图

![[Pasted image 20251104225357.png]]

* 这意味着,对于端口受限椎`NAT`来说,打洞其实还是一件相对容易的事情
* 当然,你可能不太清楚什么是打洞

* 众所周知,如果一个设备在`NAT`后面,那么它其实很难原生或者说很难主动P2P
* 所以人们搞出了打洞技术,简单来说,现在存在两个`client`,而且全都在`NAT`后,那么实现P2P就需要一个中继服务器完成,如果只有一个`client`在`NAT`后,可以参考Skype的做法

* 假设两个`client`一个是`A`一个是`B`,然后有一个中继服务器`S`
* 那么`A`会首先和`S`沟通,当然这是`A`主动发出的
* 然后`A`的`NAT`会记录`A`的映射关系,且`S`会从发来的包中读到`A`的`NAT`的`IP`和`Port`
* 对`B`也是这样做

*  此时服务器`S`就可以和`A`和`B`进行交流了,于是`S`为`A`发送`B`的`IP`和`Port`,为`A`发送`B`的`IP`和`Port`
* 然后服务器让`A`主动地试图和`B`交换数据,当然,这肯定不会成功,因为`B`的`NAT`没有`A`的映射,虽然`A`失败了,但是`A`的`NAT`获得了一个`B`的映射
* 此时让`B`主动访问`A`,`B`的`NAT`也会拥有`A`的映射,然后因为`A`的`NAT`有了`B`的映射,所以`B`能够成功访问`A`,于是就打洞成功了,实现了P2P

* 换句话说,打洞的本质就是让两个`Peer`的`NAT`能够拥有对方的`IP`和`Port`

* 但是!这对于对称`NAT`几乎不可能行得通
* 因为打洞的一个重要机制就是需要让`client`知道对方`NAT`的`IP`和`Port`
* 但对称`NAT`的端口是一定会变化的,换句话说`client`访问`server`用的端口和`client`访问另一个`client`用的端口不一样,这导致`server`即便是给两个`client`分享了对方的`NAT`的`IP`和`Port`,也会因为实际P2P使用的`IP`和`Port`不一样导致发送的包被`NAT`丢弃

![[hole-punching.png]]

* 图片来自:https://bford.info/pub/net/p2pnat/

* 顺带一提,如果你使用过`Radmin Lan`这样的工具和远端的朋友玩过离线版塔科夫+`fika联机mod`或者潜渊症之类的游戏的话,那么应该会比较熟悉

* 这个工具其实就是用打洞实现P2P的


##### 5.1.3 `NAT`回环

* 有一种场景,如果我们引入`NAT`,可能会造成传输效率低下的问题

![[Pasted image 20251107113234.png]]

* 这里我们在内网搭建两台服务器,然后全部连接到一个交换机,并处于一个`NAT`后
* 那么假设这两台服务器要交换数据,会怎么做?

* 有两种可能性:
	1. 某个内部设备试图通过公网IP访问另一个内部设备,那么`NAT`会把包发到公网,然后经过公网的包再跑回来回到`NAT`,最后被传给目的内网地址
	2. 某个内部设备试图通过内网地址访问内网设备,那么`NAT`知道这是一个内网地址,他经过交换机发送包给那个内网设备

* 这里我们只谈第一种情况
* 你会发现,这里跑了一遍公网,这其实是完全没必要的步骤
* 当然,关于这点我们暂且不谈

* 换句话说,这个内网设备试图以访问公网`IP`的形式访问同一个内网服务器

* 我们知道,一个`NAT`会修改包中`DST IP/Port`的地址为目的主机的内网`IP/Port`,这里我们举个例子:
	1. 发送方是`B`,内网`IP`为`192.168.10.101`
	2. 接收方是`A`,内网`IP`为`192.168.10.100`
	3. 交换机称为`S`
	4. `NAT`称为`N`,公网`IP`为`166.76.120.70`,映射:`192.168.10.100:1000`<-->`166.76.120.70:6000`
* 那么`B`在端口`4000`发送一个包给`166.76.120.70:6000`:
	1. 发包的时候,这个包的结构是:
		1. `SRC`: `192.168.10.101:4000`
		2. `DST`: `166.76.120.70:6000`
	2. 这个包被`NAT`接收之后,`NAT`会修改包的目的地址,同时为设备`B`在`NAT`添加一个映射关系:
		1. `SRC`: `192.168.10.101:4000`
		2. `DST`: `192.168.10.100:1000`
	3. `A`接收这个包之后,可能会回复一个包:
		1. `SRC`: `192.168.10.100:1000`
		2. `DST`: `192.168.10.101:4000`

* 那么,问题来了,`A`回复的这个包还会走`NAT`吗??答案是不会!
* 因为交换机会直接转发包给`B`,直接不走`NAT`了
* 但是,`B`认为他之前在和`166.76.120.70:6000`交换数据,现在突然来了一个`192.168.10.100:1000`,这会被他直接识别为位置数据包,那么就直接丢弃
* 所以,会产生一个现象:`B`可以发包给`A`,且能被`A`正常接收,但是`A`没法回复`B`

* 所以解决这个问题也很简单
* 要么我们需要让`NAT`实现一个功能,识别发送方和接收方是否都是当前内网的设备,如果两者都是内网设备,那么不再向公网转发,而是转而向内网交换机转发,同时还需要修改这个包的`SRC`和`DST`
* 回到例子,`B`在端口`4000`发送一个包给`166.76.120.70:6000`:
	1. 发包的时候,这个包的结构是:
		1. `SRC`: `192.168.10.101:4000`
		2. `DST`: `166.76.120.70:6000`
	2. 这个包被`NAT`接收之后,`NAT`会修改包的目的地址和源地址,同时为设备`B`在`NAT`添加一个映射关系`192.168.10.101:4000`<-->`166.76.120.70:6001`:
		1. `SRC`: `166.76.120.70:6001`
		2. `DST`: `192.168.10.100:1000`
	3. `A`接收这个包之后,可能会回复一个包:
		1. `SRC`: `192.168.10.100:1000`
		2. `DST`: `166.76.120.70:6001`
	4. 同样经过`NAT`,同样修改`SRC`和`DST`:
		1. `SRC`: `166.76.120.70:6000`
		2. `DST`: `192.168.10.101:4000`
	5. 回复包被`B`接收

* 所以,你会发现,这两个设备似乎通过各自的公网`IP/Port`(当然是`NAT`虚拟出来的)和对方交流,双方都认为对方真的是一个公网设备

##### 5.1.4 `NAT`产生的哲学问题

* CS144中提到了一个哲学问题,在引入`NAT`之后,端到端思想还有效吗? 
* 我的大致理解是,大致上,依旧是有效的,`NAT`只是精细了端的步骤,或者让端变得复杂了,但宏观上仍旧是端到端 
* 另一个问题是,`NAT`的引入让定义新的互联网标准变得困难
* 因为一旦引入一个新的互联网标准,那么NAT就应该重新设计以兼容新的标准 这似乎导致了现代所有的新协议都是基于UDP的原因

* 我们知道,现在已经推出了`IPv6`地址了,你可以在运营商购买相对应的服务,但是问题来了,既然`NAT`技术是用于缓解`IPv4`协议不够的问题,那么为什么`IPv6`推出之后为什么`NAT`没有被立刻取代?

* 如果坚持强的端到端原则,那么`NAT`就不应该存在,所有的安全防护都应该严格在端进行,我们且不论`NAT`本身会不会有安全检查,但事实是,`NAT`的安全性确实有一个点非常好使,即匿名上网
* 毕竟`NAT`根本不会给你分配真实的`IP`地址,所以只要你的的网络环境通过了层层`NAT`,那么其实很难找到你的具体`IP`,或者说距离直接找到你这个人还留有一定空间,以至于你的具体`IP`信息不会被当作商品销售,当然只要你想,你也可以选择类似于`NAT66`之类的东西让`NAT`兼容你的`IPv6`地址
* 所以我个人来说还是不选择站队,毕竟两者都有可取之处,同时,某种程度上讲,`NAT`在服务用户方面确实比`IPv6`要简单易维护
* 老实说,我觉得这点有点像是`Linux`和`Windows`的关系,就像是在聊为什么`Linux`明明更加安全效率更高,但为什么大家都选择`Windows`?

##### 5.1.5 `TCP`和`UDP`对`NAT`的要求

* 就一句话,千万不要使用对称`NAT`!!!因为打洞真的很重要!换句话说实现P2P非常重要!


#### 5.2 `HTTP`协议

* `HTTP`即"超文本传输协议","HyperText Transfer Protocol"

* 字面意思,这是一个用于传输"超文本"("HYperText")的协议
* 那么什么是超文本?

##### 5.2.1 `HTML`

* `HTML`即"超文本标记语言","HyperText Markup Language"

* 老实说,如果你接触过`Markdown`,你大致可以理解为`HTML`就是一个功能非常强大的`Markdown`,该语言使用`HyperText`进行书写

* 浏览器通过`HTTP`协议获取一个`HTML`文件,并且将这个文件渲染出来,所以浏览器关于渲染方面的工作方式其实和`Markdown`阅读器很像,都是将获取到的文本文件渲染
* 所以本质上,浏览器就是一个带有网络访问功能的渲染器

* 所以,你可以在任意一个网页右键然后查看源码,你就可以看到这个网页具体是怎么写的

* 比方说我在`www.bilibili.com`看到的源码大概是这样的

```html
<!DOCTYPE html>
<html class="bili_dark" lang="zh-CN">
<head>
<meta charset="UTF-8" />
<title>哔哩哔哩 (゜-゜)つロ 干杯~-bilibili</title>
<meta
name="description"
content="哔哩哔哩（bilibili.com)是国内知名的视频弹幕网站，这里有及时的动漫新番，活跃的ACG氛围，有创意的Up主。大家可以在这里找到许多欢乐。"
/>
<meta
name="keywords"
content="bilibili,哔哩哔哩,哔哩哔哩动画,哔哩哔哩弹幕网,弹幕视频,B站,弹幕,字幕,AMV,MAD,MTV,ANIME,动漫,动漫音乐,游戏,游戏解说,二次元,游戏视频,ACG,galgame,动画,番组,新番,初音,洛天依,vocaloid,日本动漫,国产动漫,手机游戏,网络游戏,电子竞技,ACG燃曲,ACG神曲,追新番,新番动漫,新番吐槽,巡音,镜音双子,千本樱,初音MIKU,舞蹈MMD,MIKUMIKUDANCE,洛天依原创曲,洛天依翻唱曲,洛天依投食歌,洛天依MMD,vocaloid家族,OST,BGM,动漫歌曲,日本动漫音乐,宫崎骏动漫音乐,动漫音乐推荐,燃系mad,治愈系mad,MAD MOVIE,MAD高燃"
/>
//...
```

* 我们往下看看,你能看到这里`HTML`加载了很多图片以及`css`等资源,毕竟类似于图片这种资源,我们没法直接像`Word`一样插入到一个纯粹文本的内容中去,所以这里你可以看到都是网页路径,就和我们在`Markdown`中插入图片类似

##### 5.2.2 `HTTP/1.0`
* `HTML/1.0`不是`HTML`广泛使用的一个版本,所以实际上我们这个小节是为了给下一个小节做铺垫,因为我们必须得聊聊`HTTP/1.0`的缺陷

* 首先需要明确的是,为`HTTP`协议提供服务的传输层协议是`TCP`

* `HTTP/1.0`使用`TCP`协议时设计了一个非常致命的问题,这个问题在当时还不直观,但是现在其实缺点很明显
* 就是效率太低

* `HTTP`协议是这样做的
* 对于每一个需要加载的资源来说,比方说图片,`css`这类资源,每次加载都算做一次单独的`TCP`连接
* 这就造成了`TCP`需要握手的次数过多了,每次握手都会带来一次`RTT/2`的延迟,那么只要这类资源一多就会导致延迟非常高

* 你能看到`www.bilibili.com`加载了这么一堆资源(以下这段代码也不全是这类资源)

```html
<link rel="dns-prefetch" href="[//s1.hdslb.com](https://s1.hdslb.com/)" />
<link rel="apple-touch-icon" href="[https://i0.hdslb.com/bfs/static/jinkela/long/images/512.png](https://i0.hdslb.com/bfs/static/jinkela/long/images/512.png)" />
<link rel="shortcut icon" href="[https://i0.hdslb.com/bfs/static/jinkela/long/images/favicon.ico](https://i0.hdslb.com/bfs/static/jinkela/long/images/favicon.ico)" />
<link rel="canonical" href="[https://www.bilibili.com/](https://www.bilibili.com/)" />
<link rel="alternate" media="only screen and (max-width: 640px)" href="[https://m.bilibili.com](https://m.bilibili.com/)" />
<link rel="stylesheet" href="[//s1.hdslb.com/bfs/static/jinkela/long/fonts/harmonyos.css](https://s1.hdslb.com/bfs/static/jinkela/long/fonts/harmonyos.css)" media="print" onload="this.media='all'" />
<link rel="stylesheet" href="[//s1.hdslb.com/bfs/svg-next/font/2024-11-04/laputahome-2moi75x0k8k.css](https://s1.hdslb.com/bfs/svg-next/font/2024-11-04/laputahome-2moi75x0k8k.css)" />
<script>window._BiliGreyResult={"method":"gray","grayVersion":"170604"}</script><script data-inject-polyfill src="[https://www.bilibili.com/gentleman/polyfill.js?features=es2015%2Ces2016%2Ces2017%2Ces2018%2Ces2019%2Ces2020%2Ces2021%2Ces2022%2CglobalThis&flags=gated](https://www.bilibili.com/gentleman/polyfill.js?features=es2015%2Ces2016%2Ces2017%2Ces2018%2Ces2019%2Ces2020%2Ces2021%2Ces2022%2CglobalThis&flags=gated)"></script>
<script type="text/javascript" src="[//s1.hdslb.com/bfs/seed/jinkela/short/bmg/register/fallback.js](https://s1.hdslb.com/bfs/seed/jinkela/short/bmg/register/fallback.js)"></script>

<link rel="stylesheet" href="[//s1.hdslb.com/bfs/seed/jinkela/short/bili-theme/map.css](https://s1.hdslb.com/bfs/seed/jinkela/short/bili-theme/map.css)"/>
<link rel="stylesheet" href="[//s1.hdslb.com/bfs/seed/jinkela/short/bili-theme/light_u.css](https://s1.hdslb.com/bfs/seed/jinkela/short/bili-theme/light_u.css)"/>
<link id="__css-map__" rel="stylesheet" href="[//s1.hdslb.com/bfs/seed/jinkela/short/bili-theme/dark.css](https://s1.hdslb.com/bfs/seed/jinkela/short/bili-theme/dark.css)"/>
```

* 那么一次连接过程可能是这样的:
	1. 用户和服务器三次握手.并在最后一次`ACK`的时候,用户会携带请求内容给服务器,比方说用户请求了两个资源,一个称作是`1`,另一个称作是`2`
	2. 服务器回复`1`给用户,用户获得了两个关于资源`1`的包即`1a`和`1b`
	3. 然后用户解析这个资源`1`发现这个资源`1`使用了其他资源,比方说一个图片`3`(那么这个资源`1`就可能是一个`HTML`文本)
	4. 然后重新建立连接申请资源`3`
	5. 在建立连接申请`3`的过程中,`2`也到了两个包,一个是`2a`一个是`2b`
	6. 同样的,用户发现`2`里使用了资源`4`,于是也开始建立连接申请`4`,于是你会发现此时有两个连接在同时建立
	7. 然后`3`会先到,然后才是`4`

![[Pasted image 20251112115733.png]]

* 所以你会发现,这里其实多了两次完全没必要的三次握手的过程,有至少大约`3/2 * RTT`的时间都浪费在了`TCP`连接上
* 另一个造成的问题是,因为每次获取资源的都需要单独的一次`TCP`连接,所以实际上`TCP`拥塞窗口增长不了多少就没了,这就导致了拥塞窗口似乎变成了一个毫无意义的东西,所以如果一个网页的资源非常非常多的时候,我们如果能使用拥塞窗口给后续的资源加载提提速那就再好不过了,那么延迟还会更低

* 我们来看看一个`HTTP/1.0`的请求字段是怎样写的,一个请求字段包含以下几个东西

|名称|解释|
| :---: | :---: |
|请求行(`Request Line`)|你要对资源执行的操作,`URL`,`HTTP`版本,只能有一行|
|请求头(`Request Header`)|附加的信息,比如说"状态",浏览器类型等等,可以有很多行|
|请求体(`Request Body`)|这是可选的,一般用于配合请求行的特定操作传输文本量大的内容,比方说配合`POST`上传账号密码信息|

* 那么一个`HTTP/1.0`的请求字段可能是这样的

|行号|字段|解释|
| :---: | :---: | :---: |
|`1`|`GET /index.html HTTP/1.0`|请求一个`/index.html`页面,使用`HTTP/1.0`的版本|
|`2`|`User-Agent: Mosaic/2.0`|表示一个客户端,这是一个早期的浏览器|
|`3`|`Accept-Charset: utf-8`|表示能够接受的字符集|
|`4`|`Accept: text/html, image/gif, image/png, image/jpeg`|需要接受的回应内容的类型|
|`5`|`Connection: close`|连接类型为关闭,也就是资源数据传输完毕之后立刻关闭连接|
|`6`|`空行`|表示请求体为空|

##### 5.2.3 `HTTP/1.1`

* `HTTP/1.1`修正了这个问题

* `HTTP/1.1`在请求字段的`header`的关于`Connection`的字段引入了一个叫做`keep-alive`的字段,当然对应的,`HTTP/1.1`对于其请求字段有了一些新的规范,比方说必须使用`Host`这个字段什么的,具体可以查一下`wiki`

* 一旦某个请求携带了这个字段,那么服务器和客户端都会认为这次连接需要保持比较长的时间,就不会有任何人主动断开连接,除非对方主动请求断开连接或者使用字段`close`

* 自此,`HTTP/1.1`就实现了长时间的资源传输,极大的提高了用户体验,至少能减少一次`3/2 * RTT`造成的延迟,需要传输的资源越多,提升就越大,因为窗口现在可以增长了

#### 5.3 `BitTorrent`

* 简单来说就是`BT`下载
* 迅雷总用过对吧,迅雷就是用这技术

* `BT`技术的核心是去中心化,即不存在常规的服务器和客户端的区别
* 比方说我们使用`HTTP`协议下载文件,那么就一定需要一个单独的服务器向用户传输文件,一定程度上,如果用户太多了,那么用户分到的服务器带宽就会很低
* 而`BT`的用户,每个人都是服务端,每个人也同时是客户端

* `BT`协议将一个大文件切割成很多个片段,一个用户可能不会拥有一个完整的文件,但有可能会拥有一个完整的片段

* 一个`BT`种子文件包含以下几个内容:
	1. 文件名
	2. 哈希值: 用`SHA-1`哈希算校验文件完整性
	3. `Tracker`: 一个用于知道哪个用户有这个文件的服务器地址

* 如果你用过一些下载番剧的种子资源网站,使用很多人用的`qBitTorrent` + `ssh`订阅的这种方式追番/补番,或许你会知道`Tracker`
* 一般情况下,某个番剧可能非常冷门或者非常古早,那么我们就需要新增很多`Tracker`提高下载速度(我们后面会理解为啥新增`Tracker`可以提高下载速度)

* `BT`的思想是,我从每个其他用户的设备中获得文件片段,然后最后在我自己的设备组合成一个完整的文件,当然,同时我也得为别人上传我已经有的片段,主打一个"获取得先共享"

* 那么我要下载肯定就得知道哪些用户会有这些文件片段对吧,那么`Tracker`服务器就是干这个事情的,客户端会向`Tracker`服务器发送请求,然后`Tracker`会回复现在有谁有这个文件片段,以及他的`IP`和端口号

* 那么,如果说这个种子文件里的`Tracker`回复的内容里直接就是空,那么表示这个`Tracker`说我不知道谁有这个文件片段
* 那此时就完蛋了,直接就没法下载了,因为没人有这个文件

* 所以我们需要增加`Tracker`数量,尽可能知道更多的用户,就能提高我的下载速度,当然,下载也是分多段并行下载的,所以能分的片段越多,能交流上的其他用户越多,那么下载速度就会越高,知道顶到你的输入带宽上限

* 除非,哪怕你加了几百甚至几千个几万个`Tracker`也没法下载,那么我们称为这个种子"死种"了,这种几乎就没救了,当然现在还有人开发出了用迅雷救死种的邪道操作,这个大家可以自己去查一查

* 当然,因为`BT`依旧使用了`Tracker`这种服务器,其实还不算是完全去中心化,那么现在也有完全去中心化的技术,即`DHT`("分布式散列表","distributed hash table")
* 他的中心思想也很简单,我现在仅知道一部分有限的用户,那么我会通过这些用户知道的其他用户像是类似于二分查找一样查找到离资源更近的用户,直到找到有对应资源的用户
* 当然虽然中心思想比较简单,但算法还是很麻烦的,这不讨论

* 那么实际上`BT`不仅仅用了`TCP`用于实际下载,还使用了`HTTP`/`UDP`在与`Tracker`交换数据上,`DHT`也是用的`UDP`

* 另外,`BT`有一种叫做"最稀有优先"的策略,这个策略很简单,就是优先下载最稀有的片段,防止因为片段过于稀有出现下载瓶颈或者死种的情况,这是一种提高鲁棒性的操作

* 如果一个种子的最初的分享者一开始提供的文件就无法通过哈希校验,那么就会陷入进度无限卡住的情况,后期一些`BT`下载工具还引入了这样一个校验机制,即如果一个节点始终无法有效下载,那就在超时之后将他纳入类似于黑名单的地方去

* 当然,现在其实`BT`整体环境不太好,目前看下来存在两种情况:
	1. 迅雷吸血问题: 迅雷始终获取其他客户端的资源到自己的客户端的用户里,但是不允许自己的客户端给其他客户端分享资源,自己的客户端只允许给别的也使用自己的客户端的人分享资源,这就导致迅雷用户一直在吸那些无偿上传的用户的血
	2. 运营商问题: 运营商看到你使用了大量的上传带宽,认为你是`PCDN`(一种使用家庭低廉/免费的上传带宽当作企业服务器大量上传的商业行为),然后限制你的上传带宽,运营商的本意是好的,打击`PCDN`对于运营商而言确实不是坏事,但是这特别容易误伤`BT`用户,毕竟`BT`用户不赚钱,还得白贴电费进去

* 另一个问题是,一些流媒体把用户的设备偷偷搞成类似于`PCDN`的设备,偷偷给别的用户上传资源以节省自己公司的服务器成本,然后这类不懂技术不懂`BT`的普通用户也遭殃,更是沟槽的,和迅雷坐一桌去

#### 5.4 `DNS`("域名系统", "Domain Name System")

* 一般来说,我们在`HTTP`协议中只要提供`IP`+端口号就可以访问对应的网页,但是这对大众其实极其不友好,你懂的,绝大部分广泛方便的技术最终都很可能会下放到消费用户这边
* 那么用户肯定不可能直接手写`IP`+端口还有什么`HTTP`请求之类的访问一个网页,那么我们需要一种更为简单的方式,即通过域名访问一个网页

* 如果你在浏览器输入这个`http://171.66.3.9`,然后你会发现你直接进入了斯坦福大学的网页的根地址了
* 而如果你输入`http://www.scs.stanford.edu/`,那么结果也是一样的
* 那么对于这一堆`IP`来说,那么域名显然是更加方便

##### 5.4.1 网址拆解

* 对于斯坦福这个例子,我们来拆解看一下,假设我们访问`http://www.scs.stanford.edu/labs/sc.html`(虽然现在这个文件已经访问不到了)

|内容|解释|
| :---: | :---: |
|`http`|表示该网页使用`HTTP`协议,默认的端口号是`80`|
|`www.scs.stanford.edu`|表示域名,将会转换成你要访问的`IP`地址|
|`/labs/sc.html`|表示一个文件地址,表示我要访问这个`html`文件|

* 但问题在于,浏览器怎么知道一串文字域名会对应哪个`IP`??

##### 5.4.2 域名解析原理

* 对于早期互联网而言,网络中的主机非常少,所以我们不需要一个非常庞大的系统解析域名得到`IP`,只需要修改一个文件,该文件使用类似于键值对存储一个域名对应的`IP`地址

* 那么浏览器访问该域名的时候自动调用这个文件,然后找到键值对就行了
* 关于文件位置:
	1. `Windows`: `C:\windows\system32\drivers\etc\`
	2. `Linux`: `/etc/`

* 这里我用`Arch Linux`演示
![[Pasted image 20251114163101.png]]

* 不过你可以看到这里我的这个文件中什么都没有,只有一个本地`IP`
* 这个`localhost`不是完全没用,如果你使用过`sunshine`这种串流服务端,你就知道你可以通过`https://localhost:[特定域名]`访问服务端的后台,这其实是相当于把前端页面写在`Web`端
* 另外,如果你之前没办法用`git`上传代码到`github`的话,你或许尝试过直接在`hosts.txt`里直接填入`github`的多个`IP`,这样能规避`DNS`解析(后续会解释)
* 但是,使用`hosts.txt`肯定是治标不治本的,毕竟这个文件需要你自己手动输入,当然你也可以拷贝别人的`hosts.txt`,甚至说后期可以通过某些服务更新这个`hosts.txt`,比方说通过`ARPAnet`的信息管理机构`NIC`("网络信息中心",来自斯坦福研究所,职责就是维护`hosts.txt`),但是之后的一些年内,互联网用户急剧增加,`NIC`最终很难扛住服务器压力,以及域名重名的问题,所以我们需要一个更加优雅的系统或者算法,来应对网络设备越来越多的情况
* 于是传奇的`DNS`问世了

* 如果你实际翻了一下`HOSTS.TXT`就知道这玩意如果东西很多的话是有多难维护
* 基本上,`HOSTS.TXT`就几乎可以等于一个`vector<pair<name, IP>>`,那么查找效率其实也比较低
* `DNS`做了一件事情,他把所有的域名全部归类,把域名都归属于顶级域下,诸如以下

|类别|解释|举例|更多|
| :---: | :---: | :---: | :---: |
|`.com`|商业|`www.bilibili.com`|哔哩哔哩网页端|
|`.net`|网络|`www.csdn.net`|`CSDN`论坛网页端|
|`.org`|非营利组织|`wiki.archlinuxcn.org`|`Arch Linux`在中国的主页|
|`.edu`|教育机构|`www.scs.stanford.edu`|斯坦福大学|
|`.gov`|政府机构|`www.whitehouse.gov`|白宫主页|
|`.int`|国际组织|`www.icao.int`|国际民航组织|
|`.cn`|中国(有很多以国家缩写为本国独有的顶级域)|`www.limestart.cn`|青柠起始页,我很喜欢的浏览器启动页|
|`.xyz`|一个通用域名|`abc.xyz`|属于Alphabet(google的母公司)的域名|
|...|...|...|...|

* 如果我想要访问一个域名,比方说`www.scs.stanford.edu`,那么设备首先会访问一个叫做`DNS`解析器的东西,这个东西可以在很多地方,比方说运营商,或者是学校,甚至是家用`NAT`

* 解析器会帮你联系某几个固定的根服务器,这些根服务器维护着几乎所有顶级域的服务器地址:
	1. 那么`DNS`解析器会向根服务器询问你知道到`www.scs.stanford.edu`的`IP`地址吗?根服务器说不知道,但你要访问一个`.edu`网站的话可以去`edu`的服务器问问,然后根服务器甩给`DNS`解析器一个地址
	2. 然后`DNS`解析器向`edu`询问,同样的,`edu`服务器也不知道,但他知道`stanford.edu`的地址,于是甩给你一个他的地址
	3. 然后`DNS`解析器向`stanford.edu`询问,同样的,他也甩给你一个`scs.stanford.edu`的地址
	4. 然后`DNS`解析器向`scs.stanford.edu`询问,`scs.stanford.edu`回答我知道地址,他是我的一个子域名,然后返回一个地址给`DNS`解析器
	5. 最后`DNS`解析器回答用户设备:"我搞到了那个域名的`IP`",然后返回一个`IP`

* 值得一提的是,`DNS`一般用的是`UDP`,且长度有限制
* 另外,`DNS`解析器并不会每次都向根服务器询问,因为人很多,太浪费网络资源了,所以对于常用的域名,`DNS`解析器一般会选择缓存一段时间

* 那么我觉得我们需要详细了解一下"一次`DNS`解析"的全部过程
* 那么这里我们拿`www.stanford.edu`举例,这里需要使用`dig`这个工具

```text
[oldking@kingarchlinux ~]$ dig www.bilibili.com

; <<>> DiG 9.20.13 <<>> www.bilibili.com
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 64998
;; flags: qr rd ra; QUERY: 1, ANSWER: 10, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 1232
;; QUESTION SECTION:
;www.bilibili.com.              IN      A

;; ANSWER SECTION:
www.bilibili.com.       23      IN      CNAME   a.w.bilicdn1.com.
a.w.bilicdn1.com.       14      IN      A       111.19.247.150
a.w.bilicdn1.com.       14      IN      A       111.19.247.151
a.w.bilicdn1.com.       14      IN      A       111.19.247.152
a.w.bilicdn1.com.       14      IN      A       112.45.122.107
a.w.bilicdn1.com.       14      IN      A       112.45.122.108
a.w.bilicdn1.com.       14      IN      A       112.45.122.109
a.w.bilicdn1.com.       14      IN      A       221.178.63.10
a.w.bilicdn1.com.       14      IN      A       221.178.63.11
a.w.bilicdn1.com.       14      IN      A       221.178.63.12

;; Query time: 55 msec
;; SERVER: 192.168.121.35#53(192.168.121.35) (UDP)
;; WHEN: Tue Nov 18 13:14:17 CST 2025
;; MSG SIZE  rcvd: 219
```

* 我们详细看这一部分:
```text
;; QUESTION SECTION:
;www.bilibili.com.              IN      A

;; ANSWER SECTION:
www.bilibili.com.       23      IN      CNAME   a.w.bilicdn1.com.
a.w.bilicdn1.com.       14      IN      A       111.19.247.150
a.w.bilicdn1.com.       14      IN      A       111.19.247.151
a.w.bilicdn1.com.       14      IN      A       111.19.247.152
a.w.bilicdn1.com.       14      IN      A       112.45.122.107
a.w.bilicdn1.com.       14      IN      A       112.45.122.108
a.w.bilicdn1.com.       14      IN      A       112.45.122.109
a.w.bilicdn1.com.       14      IN      A       221.178.63.10
a.w.bilicdn1.com.       14      IN      A       221.178.63.11
a.w.bilicdn1.com.       14      IN      A       221.178.63.12
```

* 详细说明:

|字段|解释|
| :--: | :--: |
|`QUESTION SECTION`|询问字段|
|`ANSWER SECTION`|结果字段|
|`www.bilibili.com.`|询问的域名地址|
|`IN`|表示该信息的类型属于互联网标准|
|`A`|`IPv4`地址|
|`CNAME`|结果是一个别名|
|`23`/`14`|`TTL`|
|`a.w.bilicdn1.com.`|别名,同时也是一个`CDN`服务器|
|`111.19.247.150`|`CDN`服务器的地址|
|`AAAA`|虽然这里没有显示这个字段,但这表示的是`IPv6`地址|

* 那么这段的意思其实就是`DNS`解析器在询问`www.bilibili.com`的`IPv4`地址是什么
```text
;; QUESTION SECTION:
;www.bilibili.com.              IN      A
```

* 那么这一段表示回复,表示`www.bilibili.com`其实会跳转到别名为`a.w.bilicdn1.com`的`CDN`服务器,现在能检索到的服务器有下面这一堆,而且全都是`IPv4`地址,并且`TTL`很短
```text
;; ANSWER SECTION:
www.bilibili.com.       23      IN      CNAME   a.w.bilicdn1.com.
a.w.bilicdn1.com.       14      IN      A       111.19.247.150
a.w.bilicdn1.com.       14      IN      A       111.19.247.151
a.w.bilicdn1.com.       14      IN      A       111.19.247.152
a.w.bilicdn1.com.       14      IN      A       112.45.122.107
a.w.bilicdn1.com.       14      IN      A       112.45.122.108
a.w.bilicdn1.com.       14      IN      A       112.45.122.109
a.w.bilicdn1.com.       14      IN      A       221.178.63.10
a.w.bilicdn1.com.       14      IN      A       221.178.63.11
a.w.bilicdn1.com.       14      IN      A       221.178.63.12
```

* 那我们可以试图复现一下`DNS`解析器做的事情,这里我们假设`DNS`解析器没有缓存地址`www.bilibili.com`,那么`DNS`解析器做的事情近似如下
```shell
[oldking@kingarchlinux ~]$ dig +trace www.bilibili.com. NS @a.root-servers.net.
;; communications error to 198.41.0.4#53: timed out

; <<>> DiG 9.20.13 <<>> +trace www.bilibili.com. NS @a.root-servers.net.
;; global options: +cmd
.                       518400  IN      NS      l.root-servers.net.
.                       518400  IN      NS      j.root-servers.net.
.                       518400  IN      NS      f.root-servers.net.
.                       518400  IN      NS      h.root-servers.net.
.                       518400  IN      NS      d.root-servers.net.
.                       518400  IN      NS      b.root-servers.net.
.                       518400  IN      NS      k.root-servers.net.
.                       518400  IN      NS      i.root-servers.net.
.                       518400  IN      NS      m.root-servers.net.
.                       518400  IN      NS      e.root-servers.net.
.                       518400  IN      NS      g.root-servers.net.
.                       518400  IN      NS      c.root-servers.net.
.                       518400  IN      NS      a.root-servers.net.
.                       518400  IN      RRSIG   NS 8 0 518400 20251201050000 20251118040000 61809 . QTAU7lTykJteXtfb6Rx+w+d75i/6kmEBZYkKTevktqZbb+V4gRGnWnpm Q4WYXKIlmNV6ho/m7xI1BQMJ5DKN0JAoSowB4Nfeid3uU+taecXR+Eq1 86FCo4C8dp3u5PB2OV7PuvBLzHODUpfO1iWjdyX5vn1WJYpSWMMnRAhn EPWzS4NMq5rCHMa89wUjicNSpICVTpuOti6o9Dk3ur1rOnTRxeKS2bPA Li9e0Vskw5leSBp9myYlEliwoa1ZinwSPj+J/5ORACb/RIOvByWIUlK4 lp9YRVOgmx8yLh+ue5j+/aLcsL0zvmq3vggcO8zpW2BEys7pwk3FNfFJ VfgmeQ==
;; Received 1097 bytes from 198.41.0.4#53(a.root-servers.net.) in 331 ms

;; UDP setup with 2001:500:1::53#53(2001:500:1::53) for www.bilibili.com. failed: network unreachable.
;; no servers could be reached
;; UDP setup with 2001:500:1::53#53(2001:500:1::53) for www.bilibili.com. failed: network unreachable.
com.                    172800  IN      NS      a.gtld-servers.net.
com.                    172800  IN      NS      g.gtld-servers.net.
com.                    172800  IN      NS      i.gtld-servers.net.
com.                    172800  IN      NS      b.gtld-servers.net.
com.                    172800  IN      NS      m.gtld-servers.net.
com.                    172800  IN      NS      d.gtld-servers.net.
com.                    172800  IN      NS      k.gtld-servers.net.
com.                    172800  IN      NS      e.gtld-servers.net.
com.                    172800  IN      NS      l.gtld-servers.net.
com.                    172800  IN      NS      f.gtld-servers.net.
com.                    172800  IN      NS      h.gtld-servers.net.
com.                    172800  IN      NS      j.gtld-servers.net.
com.                    172800  IN      NS      c.gtld-servers.net.
com.                    86400   IN      DS      19718 13 2 8ACBB0CD28F41250A80A491389424D341522D946B0DA0C0291F2D3D7 71D7805A
com.                    86400   IN      RRSIG   DS 8 1 86400 20251201050000 20251118040000 61809 . pQ61ohYDdud0drWAQI30BEDkHL75rTXTXN7tylHUGO4Qo1uyRCUJaepb v8nqUQDaqyAyf6frulLmrggJRf5KRNzZ/NRxtPJmU9MW3amxTLSe0TrB 0YtXD5IR/2TJTfaIpoh/6ztMfdd+qI7OtdOQ/CpBu55/nB/wTKxhink+ PxBu8hnpAZAxGjuZLmP3/R4Y7kB7wqbuGBO1YjvyCxT/U81VEBhsd97z wuhxIfM+D+5X6DfJ8mZ70qh83hg6XDUncWKudDzPa2XjTSkln2OKAQDz x9gNyycmCPbw3vMUytCe2CJ5TmgxnGsByzKFAOS/oKCgyfJAK7MjIRtX WGltkw==
;; Received 1207 bytes from 192.36.148.17#53(i.root-servers.net) in 94 ms

;; communications error to 192.26.92.30#53: timed out
bilibili.com.           172800  IN      NS      ns3.dnsv5.com.
bilibili.com.           172800  IN      NS      ns4.dnsv5.com.
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 900 IN NSEC3 1 1 0 - CK0Q3UDG8CEKKAE7RUKPGCT1DVSSH8LL NS SOA RRSIG DNSKEY NSEC3PARAM
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 900 IN RRSIG NSEC3 13 2 900 20251123002647 20251115231647 46539 com. GyeUYKPBDuHLVwfiBNB5J6WXh5bSS9m6dyvw5kmzP2ZYg0uoG1KwubxD Lm+3o1ZRcfegSC/r/MEyxyXxSRwzew==
34N8HDRIDRS931JVPDDJA5QLVPMOGVUB.com. 900 IN NSEC3 1 1 0 - 34N8VR2QIA8E6FQT7AUGCM6FARONEELO NS DS RRSIG
34N8HDRIDRS931JVPDDJA5QLVPMOGVUB.com. 900 IN RRSIG NSEC3 13 2 900 20251125012702 20251118001702 46539 com. qhGi1ORVCcjW9qsStFFPcwCFp6nooEGHlZKZn2ul4PuWh2l9VYmBWdu1 d0VZMjnwIkXxytsP8zcNeLBAbsiyCQ==
;; Received 788 bytes from 192.52.178.30#53(k.gtld-servers.net) in 120 ms

www.bilibili.com.       300     IN      CNAME   a.w.bilicdn1.com.
;; Received 75 bytes from 220.196.136.52#53(ns3.dnsv5.com) in 80 ms
```

* `dig +trace www.bilibili.com. NS @a.root-servers.net.`的大致意思其实是"以`a.root-servers.net.`为起点做迭代查询,且查询的内容是下一次查询的权威服务器"
* 那么结果很明显:
	1. 第一次查询到的权威服务器是根服务器的权威服务器,也就是`X.root-servers.net.`
	2. 第二次查询到的权威服务器是`com.`这个顶级域名的权威服务器,也就是`X.gtld-servers.net.`,是通过询问根服务器得到的结果
	3. 第三次查询到的权威服务器是`bilibili.com`这个域名的权威服务器,也就是`nsX.dnsv5.com.`,是通过询问`com.`这个顶级域名的权威服务器得到的结果
	4. 第四次询问`www.bilibili.com.`查询到的服务器是`a.w.bilicdn1.com.`,因为`nsX.dnsv5.com.`这个权威服务器直接记录了`www.bilibili.com.`的别名是`a.w.bilicdn1.com.`,所以可以直接查询到,但是,注意了!这里`nsX.dnsv5.com.`这个权威服务器不会返回`a.w.bilicdn1.com.`的地址,所以我们还需要再次查询一次`a.w.bilicdn1.com.`才可以真正访问到地址

* 我们可以做第二次解析,解析一下`a.w.bilicdn1.com.`
```shell
[oldking@kingarchlinux ~]$ dig +trace a.w.bilicdn1.com.

; <<>> DiG 9.20.13 <<>> +trace a.w.bilicdn1.com.
;; global options: +cmd
.                       1684    IN      NS      f.root-servers.net.
.                       1684    IN      NS      g.root-servers.net.
.                       1684    IN      NS      h.root-servers.net.
.                       1684    IN      NS      i.root-servers.net.
.                       1684    IN      NS      j.root-servers.net.
.                       1684    IN      NS      k.root-servers.net.
.                       1684    IN      NS      l.root-servers.net.
.                       1684    IN      NS      m.root-servers.net.
.                       1684    IN      NS      a.root-servers.net.
.                       1684    IN      NS      b.root-servers.net.
.                       1684    IN      NS      c.root-servers.net.
.                       1684    IN      NS      d.root-servers.net.
.                       1684    IN      NS      e.root-servers.net.
;; Received 431 bytes from 218.202.152.130#53(218.202.152.130) in 9 ms

com.                    172800  IN      NS      e.gtld-servers.net.
com.                    172800  IN      NS      a.gtld-servers.net.
com.                    172800  IN      NS      g.gtld-servers.net.
com.                    172800  IN      NS      i.gtld-servers.net.
com.                    172800  IN      NS      k.gtld-servers.net.
com.                    172800  IN      NS      d.gtld-servers.net.
com.                    172800  IN      NS      l.gtld-servers.net.
com.                    172800  IN      NS      b.gtld-servers.net.
com.                    172800  IN      NS      f.gtld-servers.net.
com.                    172800  IN      NS      m.gtld-servers.net.
com.                    172800  IN      NS      h.gtld-servers.net.
com.                    172800  IN      NS      j.gtld-servers.net.
com.                    172800  IN      NS      c.gtld-servers.net.
com.                    86400   IN      DS      19718 13 2 8ACBB0CD28F41250A80A491389424D341522D946B0DA0C0291F2D3D7 71D7805A
com.                    86400   IN      RRSIG   DS 8 1 86400 20251201050000 20251118040000 61809 . pQ61ohYDdud0drWAQI30BEDkHL75rTXTXN7tylHUGO4Qo1uyRCUJaepb v8nqUQDaqyAyf6frulLmrggJRf5KRNzZ/NRxtPJmU9MW3amxTLSe0TrB 0YtXD5IR/2TJTfaIpoh/6ztMfdd+qI7OtdOQ/CpBu55/nB/wTKxhink+ PxBu8hnpAZAxGjuZLmP3/R4Y7kB7wqbuGBO1YjvyCxT/U81VEBhsd97z wuhxIfM+D+5X6DfJ8mZ70qh83hg6XDUncWKudDzPa2XjTSkln2OKAQDz x9gNyycmCPbw3vMUytCe2CJ5TmgxnGsByzKFAOS/oKCgyfJAK7MjIRtX WGltkw==
;; Received 1179 bytes from 193.0.14.129#53(k.root-servers.net) in 464 ms

bilicdn1.com.           172800  IN      NS      ns3.dnsv5.com.
bilicdn1.com.           172800  IN      NS      ns4.dnsv5.com.
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 900 IN NSEC3 1 1 0 - CK0Q3UDG8CEKKAE7RUKPGCT1DVSSH8LL NS SOA RRSIG DNSKEY NSEC3PARAM
CK0POJMG874LJREF7EFN8430QVIT8BSM.com. 900 IN RRSIG NSEC3 13 2 900 20251123002647 20251115231647 46539 com. GyeUYKPBDuHLVwfiBNB5J6WXh5bSS9m6dyvw5kmzP2ZYg0uoG1KwubxD Lm+3o1ZRcfegSC/r/MEyxyXxSRwzew==
78IDM0IHS4CDNOV640I6R1U47SK3C09Q.com. 900 IN NSEC3 1 1 0 - 78IDQK3QMV76V38C9KSJGFKOBD79LTIK NS DS RRSIG
78IDM0IHS4CDNOV640I6R1U47SK3C09Q.com. 900 IN RRSIG NSEC3 13 2 900 20251124025811 20251117014811 46539 com. EpMk8tvLxiMh+Z88JFW55ACg1vLADRbvWKFh6sJ1LzJ4T2uAUKLEBQtJ louC+KyJKm+5/uHnYZ2hTHZ3A3rUAw==
;; Received 788 bytes from 192.35.51.30#53(f.gtld-servers.net) in 250 ms

a.w.bilicdn1.com.       90      IN      A       111.19.247.151
a.w.bilicdn1.com.       90      IN      A       111.19.247.152
a.w.bilicdn1.com.       90      IN      A       112.45.122.107
a.w.bilicdn1.com.       90      IN      A       112.45.122.108
a.w.bilicdn1.com.       90      IN      A       112.45.122.109
a.w.bilicdn1.com.       90      IN      A       221.178.63.10
a.w.bilicdn1.com.       90      IN      A       221.178.63.11
a.w.bilicdn1.com.       90      IN      A       221.178.63.12
a.w.bilicdn1.com.       90      IN      A       111.19.247.150
;; Received 189 bytes from 112.80.181.106#53(ns4.dnsv5.com) in 73 ms
```


