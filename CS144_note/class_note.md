### 1 简单了解网络

* 本小节,我们将简单了解一下,或者说见识一下网络究竟是什么,以及常见的思想

#### 1.1 网络通信的本质

* 在现代设计中,网络通信绝大多数都是以字节流进行通信的
* 网络通信本质上其实是多主机之间进行通信,每个主机拥有自己的独立IP地址(严格意义上不能这么形容,但是我们可以大概这么理解),通过这个独立的IP地址,每个接入网络的设备就可以通过这个IP访问其他设备

#### 1.2 通信方案举例

##### 1.2.1 `HTTP`

* 比方说网页页面的获取,就是使用`HTTP`协议进行的

* 假设我们需要获取一个网页,本质上就是向某个IP地址的主机发送一串字节,这个字节流全是以`ASCII`字符构成,所以这些内容完全是可读的

* 然后该主机会接收这串字节,并做检验,完全通过后就可以回传一串字节,表示允许获取内容,然后表示允许获取的字节后面将会紧接着网页页面文件的文本一并以字节流/二进制返回,写入到用户的浏览器或者说内存中,浏览器将这一大片文本(本质上是前端代码)渲染成实际的图形页面,这样用户就能访问网页了

##### 1.2.2 `BitTorrent`(`BT`协议)

* 这种通信方式也是一种常用的通信方式,迅雷本质上也是用这种方式,实现网络通信的
* 在`BitTorrent`协议中,本质上不存在严格意义上的"服务端",所有主机都作为客户端,更严格意义上说,所有主机都是客户端,也都是服务端
* 我们知道,从迅雷等等以`BitTorrent`协议为基础的软件中下载东西,都需要一个叫做磁力链接的东西,这个磁力链接会直接以`Hash`的方式直接和文件进行对应
* 然后我们会在互联网中寻找谁在线且有这个`Hash`,只要找到一个人有这个`Hash`,我们就会寻找该主机中,曾今还访问过哪些其他主机的`Hash`,这样,即便我们没有进行下载,我们也知道互联网中有谁还有这个文件(当然,前提是这些主机都在线)
* 接着就建立连接,开始在各个主机中下载文件
* 当然,这样有利也有弊,因为所有主机既是客户端又是服务端,那么意味着每台主机的上传量都不低
* 同时,并不是所有主机中,都完整存有这个文件,于是每个文件都会被切分成若干个`piece`,我们在与其他主机建立连接后,会交换主机拥有的`piece`信息
* 优先下载所有建立联系的主机中,最稀有的`piece`,尽可能保证该`piece`不会缺失
* 只要所有`piece`都存在,就一定能获取完整的文件,同时还能并行下载,提高下载速度

* 我们再说得更详细些
* 如果我们需要通过一个磁力链接/种子文件下载文件,这个链接/文件多数情况下是你通过`HTTP`下载网页或是下载文件得到的,而使用它,首先必须要经过一个有`tacker`的主机(一个主机可能会存放多个`tracker`),每个磁链链接或者说每个`Hash`会对应一个`tracker`,这个`tracker`不包含文件本身,所以说`tracker`其实不提供下载服务,但他能告诉用户,当前`tracker`中,有哪些用户在线
* 换句话说,这个磁力链接/种子文件告诉你的其实不是文件本身,也不是某个在线的用户地址,而是一个`tracker`的位置信息,通过`tracker`来找到其他用户
* 所以,宏观来看,这所有的用户共同构成了一个集群,而`tracker`扮演的角色仅仅只是记录用户在线情况,还有`Hash`对应哪部分文件,且帮助用户找资源,仅此而已
* 至于交换信息,则是集群中的用户该干的事情,他们使用双向的`byte`流进行数据交换,`tracker`本身不参与实际的数据交换

* 这也是为什么`BitTorrent`协议的核心思想是`P2P`(`peer to peer`)

* 值得注意的是,磁力链接其实仅记录`tracker`的位置,而种子文件则在此基础上,还会记录文件结构和`piece`情况等等
* 而用户第一次通过磁力链接或是种子文件与`tracker`建立联系时,也是通过`HTTP`协议进行沟通的,至于用户与用户之间沟通,则是用的`BitTorrent`的专有协议

* 所以,我们在使用诸如`qBittorrent`等工具的时候,可以通过一些渠道获取足够的`tracker`,以提升某个文件的下载速度和同时在线的用户量

##### 1.2.3 `Skype`独特的通信方式

* 在了解`skype`的通信机制之前,我们首先需要了解一个概念,即`NAT`
* `NAT`,本质上就是家里的路由器,路由器为你分配私有IP地址,且如果主机通过路由器接入互联网,那么外界的陌生主机无法主动获取私有主机的数据,因为会被`NAT`拦截
* 如果私有主机通过了`NAT`访问了外部设备,那么这个外部设备不再设为陌生设备,而是类似于进入`NAT`的白名单中,于是这个外部设备也能够获取私有主机的数据了,实现了既保证用户安全,又能实现数据交换的设想

* 但问题来了,这里我们要讨论一个问题,即"如果主机在`NAT`后,还能不能实现`P2P`?"
* 我们来看一个图
![[Pasted image 20250901171758.png]]

* 首先,`NAT`后的`client B`登录并上线`skype`,此时`client B`主动与`server`交流,于是`server`与`client B`允许交换资源
* 然后不在`NAT`后的`client A`也登录并上线`skype`,此时`client A`与`server`也可以交换资源
* 此时`client A`拨打电话给`client B`,因为`client B`在`NAT`后,所以`client A`不能直接给`client B`打电话,因为`NAT`认为`client A`是一个陌生设备
* 所以由已经不是陌生设备的`server`帮忙转发`call`给`client B`,此时`client B`会提示有人拨打电话给自己
* 如果`client B`接听了电话,此时`client B`会发送一个请求给`client A`,那么`client B`和`client A`的第一次有效沟通其实是由`client B`主动完成的
* 此时`client A`和`client B`就可以实现`P2P`式的数据交换了
* 所以你发现了吗,即便是`client B`在`NAT`后,也可以实现`P2P`式数据交换,根本解决思路来自于:由已经允许数据交换的`server`代理转发"其他设备希望数据交换的任务",从而让`NAT`后的设备主动访问这个其他设备
* 非常巧妙
* 我们称这种代理`server`为`Rendezvous Server`(会合服务器)

* 如果`client A`也在`NAT`后还可以实现`P2P`吗?
* 答案是不行,因为让`client B`发送请求给`client A`,它也收不到,会被拦截
* 所以在这种情况下,会退化成中继服务器转发操作,即`client`只与`server`交换数据,转发数据给其他`client`由`Relay Server`完成

#### 1.3 计网的四层结构以及"跳转"

* 在现代计算机网络的概念中,我们将整个网络分为四个层,当然,了解完这个小节之后,你仍然可能云里雾里,这是正常的,我们只是了解一下大纲而已

* 在此之前,我们首先需要了解一个概念
* 现代计算机网络中,绝大部分情况下,数据的传输绝对不是两点一线地传输的,它更像是一张网,数据在网上的节点不停跳转,直到到达目的地
* 就像是现代的物流网络一样,包裹的下一站不一定就是目的地,也可能是另一个中转站点,计算机中的网络也一样,下一跳不一定是目的地,但一定会接近目的地

![[Pasted image 20250901212352.png]]

* 具体分为以下四层

![[Pasted image 20250901211220.png]]

1. `Link`: 这一层也被称为链路层,这一层负责实际的传输任务,它不在乎究竟怎么传数据,仅负责传输功能本身
2. `Network`: 这一层也被称为网络层,这一层负责检测/指定传输目标,换句话说就是将`data`和目的地打包成一个`packet`,或者解包`packet`并分析目的地,换句话说,规定目的地的是`Network`,`Link`仅为`Network`提供发送服务,具体要发送到哪里取决于`Network`是怎样设定的
3. `Transport`: 也被称为传输层,这一层的设计初衷其实很简单,是为了弥补`Network`层的一些设计缺陷,计网功能的设计中,很多地方秉承着尽可能解耦的原则,换句话说,`Transport`层其实更像是`Network`层的插件(可以从这个角度看但不能严格这么理解),以实现更多复杂的功能,`Network`层其实不能保证传输一定不会失败,`Network`只能保证传输尽可能成功,如果拥塞非常严重,那么数据丢失也是板上钉钉的事情,所以需要`Transport`层做更多的功能,比方说检测到丢包就进行重传操作等等,这种重传操作的规范,我们称作`TCP`协议,比方说我们看视频的时候,为了保证每一个视频片段都能完整播放,就需要使用`TCP`协议保证`packet`能完整传输,当然也有不需要完整传输的情况,比方说视频电话,这种情况下,重传其实是没有任何意义的,因为视频电话讲究严格同步,不能延迟太高,所以不如直接让其丢失,反映在用户上则可能就是视频卡顿或者模糊等等,这种允许不保证`packet`完整传输的规范称为`UDP`协议
4. `Application`: 这一层也被称为应用层,用于规范数据如何交换,或者说作为数据交换的架构,比方说我们之前聊的`HTTP`协议和`Bittorrent`协议都在这一层,或者说这一层是用于规范数据交换策略的

* 值得一提的是,我们所说的路由器,也在这个传输网络中
* 路由器中只存在`Link`和`Network`这两层(这个地方其实不太准确,我们会进行补充),`Network`用于解包`packet`并计算下一跳的位置,而`Link`则负责传输,至于其他两层,路由器不需要也不在乎,因为路由器的本职工作是"路由",即找到下一跳位置并进行传输

![[Pasted image 20250901220412.png]]

* `Application`层负责宏观控制如何进行数据交换,然后向下,以指定的`Transport`协议进行数据传输,同样的,`Transport`也会向下指定`Network`进行对应的数据封装形成`packet`,并同样向下要求`Link`传输包到下一跳(事实上`Application`和`Transport`多半也是封装包的过程,只是封装的内容除了接收者,其他中继的硬件看见了也没有任何意义,如果中继硬件能够看到,反倒会使中继硬件维护/设计成本增加,也不够解耦,所以中继硬件被设计成非常傻瓜解耦的仅支持寻找地址+转发的模式)
* 所以说,对于数据的发送者而言,这四层其实就是一个层层打包的过程
* 而对于接收者而言,则就是层层解包的过程

* 在这里我们就有必要提一提"端到端"(end-to-end)和"跳到跳"(hop-to-hop)的概念了
* 端到端本质的服务对象其实是数据的发送者和接收者,即通信链路的两端,端到端思想本身不在乎中间经过了多少跳,而只在乎数据是否完整,数据符合什么应用层协议
* 跳到跳服务的对象则是所有作为跳的中继硬件,即通信链路属于中间的部分,该思想不在乎具体有没有丢失数据,也不在乎怎么处理数据,只负责定位+转发
* 所以说,本质上围绕端到端的是`Application`和`Transport`,而围绕跳到跳的则是`Network`和`Link`

* 我们视野拉开些看,目前我们所知道的协议

* `Application`: `HTTP`,`Bittorrent`等等
* `Transport`: `TCP`,`UDP`等等

* 我们知道,一个数据在`Network`被打包的时候会添加进目的地址(当然,其实还会添加发送地址),这个过程我们称为`IP`(Internet protocol)协议,`IP`协议不保证一定能不丢失数据,不保证顺序正确,也不保证数据不会重复,并且,整个`Network`就只有这一个协议,没有其他个性化的方案,因为仅使用这个方案就完全足够了,简单,统一,傻瓜,易用!

* 至于`Link`,也有很多其他的协议,比方说`4G`,`5G`,`WIFI`等等

* 所以宏观来看,整个自上而下的四层就像是一个漏斗一样,上下都可以走各式各样功能丰富的协议,但中间的`Network`一定只能走`IP`协议
* 这也是`IP`为什么这么重要的原因

#### 1.4 浅谈`IP`协议

* 在了解`IP`协议本身之前,我们先来谈谈`IP`协议的几个特点(虽然上一小节已经谈论过一部分了),以及这些特点为`IP`协议带来了什么

* 显著的是,`IP`协议是面向跳到跳的协议,`IP`协议只负责转发相关的内容,完全不负责数据中存储了什么,也不负责如何处理数据
* 并且,`IP`协议不可靠,`IP`不会保证一定能不丢失数据,不保证一定不会重复数据,他只能尽可能保证数据正确,除非阻塞严重,一旦拥塞严重,`IP`协议认为丢失该包也是正常操作,它不会做检查,也不会重发
* 同时也正因如此,我们常说路由器参照`IP`协议用于转发包,但实际上路由器也可能会因为设置错误而导致转发到不该转发的机器上(本质上,关于路由器如何知道该怎么转发这一点,路由器自身内部有一个转发表,用于判断应该往哪个方向转发,但这个表终归还是人类设计的,不可能不出错对吧),所以`IP`协议也不能保证转发一定成功

* 所以,如你所见,这个我们所称的"`IP`协议"似乎一点也不"协议",它一点也不复杂,甚至说有些懒惰,它啥也不检查,啥也不关心,只是自顾自地转发数据报,转发不了就丢弃
* 但正是因为足够简单,足够傻瓜,才能让其能变成全球通用的互联网协议,才能让其能遍布全球,轻而易举地变成"网络"
* 同时因为足够简单,所以对于网络中的中继硬件来说,其构造也会足够简单,也会更容易维护,更加容易进行升级,至于更多的功能,放到传输的两个端点去进行吧

* 当然,这里我们提到了数据报(datagram),我们需要对其做一些解释
* 我们在之前的小节中提到过,数据在发送之前,会经过四层打包,最开始在`application`,`datagram`仅由需要传输的数据构成,本质上就是一个字符串或者说二进制串,向`transport`打包后,字符串的头会被添加一串字符/数据,用于标示使用的什么`transport`协议,同样的,在`Network`层,也会添加一串字符/数据用于标示数据来源(`IPSA` "IP source address")和目的地(`IPDA` "IP destination address"),`Link`层也是如此,添加一串用于标示传输方式的字符/数据
* 我们称数据报自上而下四层打包,最后在链路层被打包为`frame`(帧)

* 同时,`IP`协议其实也不在乎`Link`层是怎样传输的,能传输就行,所以,CS144课程中提到,你甚至可以用信鸽作为传输介质hh

* 我们简单谈一谈`IP`协议的一些细节问题
* 我们知道,数据包在网络中传输,所以势必的,可能就会出现无限循环传输的情况,所以`IP`协议用一个字段描述还剩下多少次跳转机会,称为`TTL`(Time To Live),初始值为`64`/`128`/`...`,每次跳转就会`-1`,如果为`0`时还没有送达到,那么这个`data packet`(数据包)就会被丢弃
* 同时,`IP`协议也会尽可能保证`data packet`被正确路由,为此`IP`协议再次添加了一个字段用于简单校验
* `IP`协议现在有两种,一种是`32 bit`的`IPV4`,另一种是`128 bit`的`IPV6`,因为网络发展非常快,所以现在,`IPV4`地址已经快要用完了,目前更多人都在转移到`IPV6`
* 当然,`IP`协议也不是不可扩展功能的,它也留有了一定字段允许扩展其功能,只是几乎没有人会这么干就是了

#### 1.5 简单看看网络中的"包"

* 如你所见,在上一小节中我们提到了很多类似于"包"的专有名词,我觉得有必要了解一下这些名词的区别,否则看懂上一节其实会相对困难一点点

1. `message`: 报文,这是我们最原始的数据,是最初的还没有被网络部分做任何打包的数据,可能由字符流或者二进制流构成,对于目标主机的对应进程而言,它是完全可读的
2. `datagram`: 数据报,对于`Transport`和`Network`这两层而言,`datagram`是基本传输单位,当然我们只是叫他这个名字而已,实际运用还是很简单的,所以根据协议类型,我们可以在`Transport`中分为`UDP datagram`之类的(严格来说没有`TCP datagram`),然后向下被打包成`IP datagram`
3. `frame`: 帧,这是`Link`传输的基本单位,由`datagram`打包而成
4. `data packet`: 数据包,这其实是一个泛称,用来指所有在网络中传输的东西

#### 1.6 包是怎样传输的

* 我们知道,`data packet`会从某个主机发送给另一个主机,当然这个`data packet`可能多半是一个`frame`,因为`frame`是`Link`层的基本传输单位

* 当我们将其传输到一个路由中,路由会将其解包(本质上其实不算是解包,而是读某一段固定区间),然后路由会取出其中的`IPDA`,并查一个叫路由表的东西

* 这个表并不会记录完整的`IP`地址,而是记录一个相对模糊的方向,类似于这样

|类型|目标链路|
| :---: | :---: |
| default | Link0 |
| 类型1 | Link1 |
| 类型2 | Link2 |
| 类型3 | Link3 |
| 类型4 | Link4 |
| 类型5 | Link5 |

* 然后路由器会根据`IP`,找到最匹配的类型,然后发送给对应的下一跳或者对应的目标链路
* 但是,总会有完全不符合所有匹配类型的情况
* 此时,路由器会将其匹配到默认路由,也就是`default`,会将其发送给更大的网络以期望其能够正确匹配目标链路

* 我们就拿CS144课程的例子来说

* 一个`data packet`从学校机房中发出,他会经过机房的路由,路由中可能记录了学校内的部分其他路由,比方说餐厅的路由或者是图书馆的路由
* 如果我的目标就是学校内的其他设备,那我可以直接使用路由表中设定的类型,并下一跳到餐厅或者图书馆之类的路由,再由它们进行直接转达

* 但如果我的目标地址不是学校中的设备,且路由表中找不到任何能够匹配的类型,那么下一跳就会走默认路由,可能会发送给运营商的路由/数据中心的路由以期望在下一跳中能获取到更全面的路由表

#### 1.7 `TCP`协议在数据传输中的作用

* 在前面几个小节中,我们已经了解过了,`TCP`是一种可靠字节流的传输协议,底层的`IP`协议为其提供服务
* 你可能在学习或者一些科技向视频中有了解过,构建一个`TCP`传输"通道"之前,需要进行三次握手
* 就类似于这样：
	1. 客户端发送`SYN`(synchronize)标志位给服务器,表示我想和你建立连接
	2. 服务器发送`SYN`标志位和`ACK`(acknowledge)标志位回客户端,表示我也想和你建立连接,并且我已经准备好了
	3. 客户端发送`ACK`标志位给服务器,表示我也准备好了
* 至此,客户端和服务端就建立了可靠的`TCP`连接(当然,`TCP`的"可靠"不全部源自于三次握手,三次握手只是保障可靠的重要条件之一)

* 另一个问题,我们需要搞清楚"端口"(`port`)
* 我们已经知道,我们可以通过一个`IP`地址找到一个主机,但主机上可能跑着很多服务,我们怎么知道要访问哪个服务呢?
* 于是我们需要端口帮我们进行区分
* 同一个`IP`下,不同的`Transport`协议的不同端口可能对应着的不同的服务,这里我们仅拿`TCP`进行举例
* 比方说在`80`号端口,就是默认的`HTTP`服务的端口,又或者说我访问油管,其服务的默认端口可能是`443`这种

* 换句话说,我们需要获取到一个对应的服务,应该使用`IP`和`port`的组合,才能允许获取对应服务,至于具体是怎么获取到这个`IP`和`port`的,我们暂时不需要特别清楚,但可以提的是,这两个东西是通过解析域名得到的


#### 1.8 分组交换(Packet switching)

* 如你所见,如果我们直翻"Packet switching",那么应该叫包交换,但实际上这个词和中文语境下的"交换"没有啥关系,同时,"包"这个词在这里也有些出入
* 首先输出一个结论
	1. 在这个思想中,"包"是手段,"分组"是目的
	2. 在计算机网络的语境中,这里的"交换"其实指数据的转发

* 分组交换是现代计算机网络的设计思想
* 在更加早期的数据传输技术中,人们普遍是用电话线进行数据传输,换句话说就是打电话
* 电话线优势很明显,就是一旦建立连接,就几乎不存在数据中断,但缺点也很明显,这条电话线会被两个通信端点独占,其他任何人都没法共享这个电话线,那么,电话线这个资源就是不可分割的,即便你打电话的时候一句话都不说,电话线也会被你一直占用,这就导致资源的浪费,这种浪费在当今网络是非常致命的
* 试想一下,假设路由器的网络带宽也是一个不可分割资源,那么一旦你的室友在下载电影或者下载游戏,那么你的电脑就访问不到任何网络,只能等待你的室友断开网络连接
* 所以我们需要一种方式,能让信号的传输介质变得可共享
* 于是,分组交换思想就应运而生了
* 我们将数据切割成小块,然后打包,发送
* 于是,就会有一个现象,当你空闲的时候,路由就会停止向我转发数据包,如果此时有其他人需要路由转发数据包,那么路由就可以轻松帮助他转发
* 同时,如果两个人同时需要路由,那么路由器也会尽可能公平,他会尽可能保证公平地转发数据包,比方说当前`ms`可能向我转发数据包,那么下一`ms`,就会向共享路由的另一个人转发数据包,再下一次又是向我转发数据包
* 所以你发现了吗,路由此时在人类眼里看来,就像是一个可以分配的资源一样,或者说就像是蛋糕一样,可以被切分给所有共享者,这种将单一资源以概率或统计的方式在多个用户中共享的思想被称为"统计复用"(Statistic Multiplex)
* 我们换一个更加简单的场景,我们将路由器想象成`CPU`一样的资源,那么如果实现多线程,多线程会平分这个`CPU`资源,所以,核心思想其实一直都没有变,都是为了尽可能减少资源浪费,尽可能始终让设备一直高效运行,从而提高整体的运行效率
* 拆分成包的另一个优势是,我们在端点,不需要在乎组成一个文件的所有包,都是怎样在中途转发过来,换句话说,我们不需要在乎各个包在哪条路径上转发的,甚至不需要在乎包是否按顺序到达,只需要在端点解包并将打散的数据重排就行(重排是`Transport`层协议关心的事情)
* 并且,哪怕两端主机已经建立了TCP链接,实际数据包在中途的传输中,也不会按照既定线路,而可能会分发到多个路由,最后汇总到目标地址

* 来自维基百科:
![[Packet_Switching.gif]]

* 并且,`IP`协议就是严格按照该思想设计的
* 这使得每一跳的逻辑都很简单,路由也可以很简单,但却可以在底层这么简单的情况下构建成一个庞大,复杂,却又安全的网络

* 于是你会发现很有趣的事实,就是网络中可能会存在多个数据包并行地向你传输,就像是千万滴水汇聚的河流一样,我们称这种通信中的数据包集合为一种"流"(flow)


#### 1.9 分层(Layering)

* 那么,简单输出一个结论/事实,"分层思想"在现代程序设计亦或是计算机设计中,绝对有着不可或缺的作用,你能看到数不胜数的程序基于分层思想进行设计,我们简单打个比方

![[image-7.png]]

* 如你所见,这是`Linux`的系统层级
* 如果你深入了解过`Linux`,那么一定很熟悉这个东西
* 分层设计思想,对于开发者亦或是用户来说,都是极为重要的思想
* 我们聊聊CS144中的例子
* 假设我想邮寄一本书给朋友,那么势必会通过以下几个步骤:
	1. 将书打包并贴好发件地址和收件地址
	2. 将书投放进邮筒,书会在邮筒中等待邮递员
	3. 邮递员取到书,将书给到我附近的邮件中转站
	4. 中转站会通过各种方式发往朋友附近的邮件中转站
	5. 朋友附近的邮件中转站则会派邮递员向朋友住址的邮箱投递邮件
	6. 邮件会在邮箱中等待直到,朋友拿到邮件
	7. 朋友确认邮件无误后进行拆包
	8. 朋友获得这本书

* 于是你会发现一个很有意思的事情
* 我们在发邮件的过程中,所有组成部分只需要干好自己的活就行,我们无需关心底层究竟是怎样运作的

* 我们放在网络中,就是四层分层,放在`OS`中,就是图中展示的这六层

* 另一个有趣的事实是,一旦某个组件需要进行更新,那么其余所有的层其实都不需要变化,所以分层能让功能之间解耦
* 但同时也有缺点,你会发现如果有了分层,虽然对于用户而言,隐藏了绝大部分的底层信息,对用户而言降低了复杂性与学习成本,但实际上这样做会极大地损失灵活性,这里我们聊聊CS144课程的另一个例子

* 如果你使用过`Python`或者说`Java`之类的语言,你会发现很多接口都全部封装好了,所有的底层细节用户都不必了解,用户只需要知道怎么使用顶层接口就行了
* 但C语言则完全不一样,你甚至可以在`.c`文件中穿插汇编语言,因为比方说`Linux`的内核代码中,就会有部分代码是用汇编写的,因为C语言允许你更灵活地使用一些功能,这就使得C语言的灵活性非常高,理论上你可以用C语言手搓一个C++,亦或是Python,但相对的,很多东西都要手动造轮子,所有的底层细节都需要我去注意,这就导致开发效率低,学习成本直线上升
* 换句话说就是过渡的封装会降低复杂性,降低学习成本,但同时灵活性也会大大降低

* 我之前和一个很厉害的后端工程师聊过,他说做后端的最高境界,就是能管理好项目的所有后端服务以及做这些服务的人,他说服务和服务之间有着很复杂的依赖关系,这种将项目拆分成各个服务,并进行层层依赖,本质上也是分层思想的具体体现


#### 1.10 封装(Encapsulation)

* 在网络中,封装也是一种常见思想
* 这里我们可以说得简单一些,因为在学习语言的过程中,我们或多或少学习过该思想

* 我们知道,一个`massage`,或者说数据,会从`Application`层层封装到`Link`,就像是这样
![[Pasted image 20250905110009.png]]

* 因为有这样的封装,所以每到一个设备中,该设备就只需要访问自己该访问的部分,就像是路由器,它只需要访问在`Network`和`Link`封装的头和尾,其他关于`massage`或者是其他层的细节不需要知道,依旧是解耦的思想,简单傻瓜易维护,但是不灵活
![[Pasted image 20250905110022.png]]

* 这里我们可以了解一个技术,当然这个技术的名字我们肯定是知道的,但具体做了什么,我们曾经可能从来没有了解过,这里我们借用这个技术来感受一下封装的优势
* 假设我们想在外部网络访问公司内网的服务器,我们可以在公司放一个既接通了外部网络,又连接公司内网的中继服务器
* 我们发送一个这样的包给中继服务器
![[Pasted image 20250905111735.png]]

* 对于中继服务器而言,他不知道具体要转发什么内容,他只知道接收的这个`packet`的`massage`中,存放了一个完整的`packet`,他要将这个"内部"`packet`解析一下,然后转发到内部网络
* 这种技术叫做"虚拟专用网络隧道"(Virtual Private Network,也就是我们知道的`VPN`技术)

#### 1.11 `IPv4`地址

* 相信你一定在某些电子游戏中遇见过要用`IP`地址访问某个服务器的情况,当然,你肯定知道这个`IP`地址代表着某一台服务器,不同服务器的地址是不一样的,而本小节将会详细解读一下`IPv4`地址的构成

* `IPv4`地址是由`32`个`bit`构成的一串数字,我们看`IPv4`地址的时候要将其按`8bit`拆分成4各部分看,即`a.b.c.d`的形式
* 这意味着一个`IP`地址最大可以是`255.255.255.255`,也可以是`0.0.0.0`

* 比方说`192.168.0.100`,`25.66.10.1`,`172.45.0.111`,这些都是一个`IPv4`地址

* 另一个值得要注意的东西叫子网掩码,他和我们在用的`IP`有很大的联系
* 我们输入以下命令会返回一堆东西,我们可以慢慢看(为了服务器的安全,我还是得打一下码的)
```shell
oldking@iZwz9b2bj2gor4d8h3rlx0Z:~/CS144-2024-winter-backup$ ifconfig
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 1o.x.x.x  netmask 255.x.x.x  broadcast 1x.x.x.x
        inet6 x::x:x:x:x  prefixlen x  scopeid 0x20<link>
        ether x:x:x:x:x:x  txqueuelen 1000  (Ethernet)
        RX packets 35883058  bytes 6550064423 (6.5 GB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 34958182  bytes 8303867503 (8.3 GB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```

* 我这个阿里云服务器有两个地址,一个`IPv4`,一个`IPv6`
* 其中`1o.x.x.x`就是`IPv4`地址,`255.x.x.x`则是子网掩码

* 子网掩码这个东西怎么用?我来实例一下
* 假设我的子网掩码是`255.255.255.0`,假设我的设备的`IPv4`地址是`192.168.1.100`,我舍友的设备的`IPv4`地址是`192.168.1.201`
* 那么将我的设备`IPv4`地址按位与(`&`)上子网掩码得到`192.168.1.0`,我室友的`IPv4`地址做同样操作,也会得到`192.168.1.0`,那么证明我们两台设备的在同一个位置下,则表示我们两个设备可以不经过路由器,可以直接进行连接通信

* 事实上,路由器在做转发的时候,也是会参考子网掩码的,他会优先选择可直连的设备转发

* 关于`IP`分配问题
* 最初,`IPv4`地址的分配其实规定得很死,`IPv4`地址被分为三个类别,其中具体的值被划分成了`Network`部分和`Host`部分

* 该图截自CS144课程
![[Pasted image 20250908103039.png]]

* `Network`部分表示所处在多大的网段,或者说处于同一区域下的`Host`有多少
* `Host`部分则表示具体的主机
* 换句话说,就是`Network`位数少就意味着`Host`位数多,表示该网段下的设备很多
* 换句话说,子网掩码就是一个"边界",用于划分哪个部分是`Network`,哪个部分是`Host`

* 关于网段,我们可以这样理解
* 我们知道公网`IP`其实是非常有限的,所以我们做不到为所有人都分配一个公网`IP`,那么该怎么让人人都用上网络呢?
* 于是我们可以在公网下搞一个私有地址,比方说我的小区的某个路由的公网`IPv4`地址是`205.104.36.5`,其中`205.104.36`表示`Network`部分,`.5`表示`Host`部分
* 表示这个设备是`205.104.36.0`这个区间中的第`5`个设备
* 但实际我们为每栋用户分配的却不是这个公网`IP`,因为公网`IP`有限,所以我们为整个小区分配了一个私有地址,这个私有地址`192.168.0.0`(`Network`部分),只有小区自己内部可以使用
* 所有的用户与公网的交流,全部通过这个拥有公网`IP`的路由器代为转发

* 所以,在这个场景中,`205.104.36.0`是一个"公有网段",而`192.168.0.0`则是一个私有的网段

* 但你一定也发现了一个问题,如果小区的网段是`205.104.36.0`,但我的小区只有`5`个路由,这不就导致有两百多个`Host`被浪费掉了吗?答案是,是的,全部被浪费掉了!

* 所以,当人们发现`IPv4`开始不太够用的时候,提出了一个新的方案,叫做`CIDR`(无类别域间路由, Classless Inter-Domain Routing)

* 这个方案让`Network`的长度可以不受原来的三种类型约束,而是可以自定义其长度,我们回到小区的例子来看看他是怎样做的
* 原先,小区分配的是`205.104.36.0`,表示该网段下可以分配大约两百多个公网`IP`设备,但现在我们知道该小区只有`5`个公网用的路由,于是我可以改成分配成`205.104.36.160/27`,这意味着这个网段可以分配`2^(32-27) = 32`个公网`IPv4`地址,换句话说,这个`/27`表示前`27`位属于`Network`,后面的`5`位表示`Host`地址,同时`/27`也代表着子网掩码,那第`5`个路由的`IP`可以表示为`205.104.36.5/27`

* 那么最后,我们来规范一下,类似于`205.104.36.0`这种,他一般只是被称为一个`IPv4`地址,但语义不明确,而类似于`205.104.36.0/24`这种,称为`CIDR`网络前缀

#### 1.12 最长前缀匹配(Longest Prefix Match, `LPM`)

* 前段时间我们聊过路由转发`packet`需要查路由表,寻找最匹配的路径进行转发,这里我们就来补全这个空缺,来深入聊一聊路由是如何做最匹配路径的寻找的

* 我们先来看看路由表的具体构造如何

| dest | link |
| :---: | :---: |
| 0.0.0.0/0 (default) | 1 |
| 172.10.0.0/16 | 1 |
| 172.10.8.0/24 | 2 |
| 26.64.0.0/16 | 2 |
| 79.0.0.0/8 | 3 |
| 13.230.9.0/24 | 2 |
| 174.25.0.0/16 | 4 |

* 其中,所有的`0`其实都表示此处是一个通配符,拿到的目标`IP`地址和该表中的地址后,依照子网掩码位数,比较最前位就可以找到最匹配的路径,如果没有最匹配的,就会走默认路由

* 我们举个例子,假设现在路由器拿到了一个`172.10.8.2`的包并需要将其转发
* 其中:
	1. 第一个地址不取任何数字,因为他是默认路由,一定是和需要转发的地址匹配的,然后做好记录,表示这个路径匹配过了
	2. 第二个地址取前`16`位和需要转发地址的前`16`位进行比较,发现也符合,那也把这个路径记录下来
	3. 第三个地址取前`24`位和需要转发地址的前`24`位进行比较,发现也符合,那也把这个路径记录下来
	4. 剩下的如法炮制...

* 于是最后发现,所有记录的`3`个匹配项中,`172.10.8.0/24`这个地址存在`24`位与需转发地址匹配,那么就会走`link 2`进行转发

#### 1.13 地址解析协议(Address Resolution Protocol, `ARP`)

* 在了解`ARP`之前,我们首先还需要了解一些前置知识

* 首先,`IP`地址是一个`Network`层地址,但实际传输却是在`Link`层传输,而`Link`层其实无权访问`Network`层的任何内容,所以势必的,`Link`层也需要有自己的"地址",这个地址我们称为`MAC`地址
* 另一个问题,公网`IP`地址其实不是物理意义上存在的,而是"受分配的",是虚拟的一个地址(只有某些互联网服务才可以申请某个固定的公网`IP`,造成这种受分配情况的原因还是因为`IPv4`地址太过于稀缺了),而`MAC`地址却是一个物理意义上存在的地址,是网卡出厂的时候就烧录进网卡的,所以理论上这个地址才是全球唯一的网卡地址
* 所以实际上,我们会将`datagram`在`Link`层中打包成帧,然后实际在`Link`层中转发的都是帧

* 另一个有意思的点是,一个路由器可以有多个网卡,并且可以有多个`IP`地址
* 首先我们要知道,因为路由器本质是在做转发操作,而一个网卡只能关联他所在的网段,所以如果我要从一个网段发送内容到路由器关联的另一个网段,就必须要用两个网卡

* 那么,以上是前置知识,现在我们将会举一个来自CS144的例子

1. A: 一台主机,`IP`地址为`192.168.10.100`,`mac`地址(用于辨认哪个网卡,属于链路层地址)为`AA:AA:AA:AA:AA:AA`
2. B: 一台主机,`IP`地址为`172.100.10.100`,`mac`地址(用于辨认哪个网卡,属于链路层地址)为`BB:BB:BB:BB:BB:BB` 
3. C: 一个网关,拥有两张网卡
	1. 一张网卡连接着A,该网卡的`IP`地址为`192.168.10.101`,mac地址为`CC:CC:CC:CC:CC:CC`
	2. 另一张网卡连着B,该网卡的地址为`172.100.10.101`,mac地址为`DD:DD:DD:DD:DD:DD`
	
* 那么,如果A需要发包给B,首先会参考子网掩码(A的子网掩码是`255.255.255.0`),但显然这里B不会和A在同一个网段下,那么此时A开始封装`packet`,源IP地址是A自己的,源`mac`地址也是A自己的,但目标IP地址是B的`IP`地址,目标`mac`地址是网关的`CC:CC:CC:CC:CC:CC` 发送帧给网关之后,网关会解包,并封装自己的`mac`地址(`DD:DD:DD:DD:DD:DD`)作为源`mac`地址放进帧的链路层中,还会封装B的`mac`地址作为目标`mac`地址放进帧的链路层中

* 这里这个网关其实就是路由啦

* 那么此时有一个很重要的问题出现了,A怎么知道网关的`mac`地址?当然不知道!所以我们需要`ARP`协议帮助我们获取网关的`mac`地址
* 此时,A会在当前网段中广播它所有能广播到的设备,向这些设备提问:"谁是`192.168.10.101`?告诉我你的`mac`地址!",在广播的时候,他会顺便把自己的`mac`地址附带进去,方便接收到的设备回传,那么C收到这个广播之后就会发回(非广播形式,或者说"私聊")它的`mac`地址给A,此时A就可以正确封装`packet`了,然后发送到C手上,然后C也做同样的事情获取B的`mac`地址,然后发包给B

* 注意,这里是在广播所有能广播到的当前网段设备,这意味着?!
* 我们是不是可以欺骗这个A,让A以为我们是一个路由器,而实际上我们是另外一台主机?!
* 当然可以!
* A中将会维护一张缓存表,映射C的`IP`和`mac`地址,只要在还没有实现映射的时候,抢在网关应答之前应答A,并把自己的`mac`地址当作一个网关`mac`地址发回给A,那么他就会把这个伪装的网关真的当作一个路由发包
* 恭喜你学会了`ARP`欺骗

* 现在我们来聊一聊一个`ARP`包的组成
* 如你所见,这个包由以下几个部分组成(虽然这个图看起来很立体,不说实际传输的时候却是一个连续的字符串)
![[Pasted image 20250909120836.png]]

* 解释:
	1. `Hardware`: 表示链路层协议类型
	2. `Protocol`: 表示网络层协议类型
	3. `Hardware Length`: 表示链路层协议的长度
	4. `Protocol Length`: 表示网络层协议的类型
	5. `Opcode`: 设置代码,表示该包的属性,是请求(`1`),还是发回(`2`)
	6. `Src Hardware Address`: 发送方链路层地址 
	7. `Src Protocol Address`: 发送方网络层地址
	8. `Dst Hardware Address`: 接收方链路层地址
	9. `Dst Protocol Address`: 接收方网络层地址

* 回到例子
* A请求的时候应该是这样的:
	1. `Hardware`: `0x 00 01` (表示以太网协议)
	2. `Protocol`: `0x 08 00` (表示`IP`协议)
	3. `Hardware Length`: `0x 06` (表示链路层协议有`6 Bytes`)
	4. `Protocol Length`: `0x 04` (表示网络层协议有`4 Bytes`)
	5. `Opcode`: `0x 01` (表示请求)
	6. `Src Hardware Address`: `0x AA AA AA AA AA AA` (源链路层地址)
	7. `Src Protocol Address`: `0x C0 A8 0A 64` (源网络层地址)
	8. `Dst Hardware Address`: `0x 00 00 00 00 00 00` (目标链路层地址,因为这里是请求地址,所以地址还不知道,所以填空)
	9. `Dst Protocol Address`: `0x C0 A8 0A 65` (目标网络层地址)

* 实际发送的时候,还会封装成一个以太网帧进行发送,因为广播行为是封装在以太网帧中的,所以实际发送的时候是这样

* 我们还得简单看看以太网帧是怎样封装的
![[Pasted image 20250909124206.png]]

* 所以实际发包的时候是这样的:
	1. `Dst Mac Address`: `0x FF FF FF FF FF FF` (全`F`表示广播)
	2. `Src Mac Address`: `0x AA AA AA AA AA AA`
	3. `Ether Type`: `0x 08 06` (表示发的是`ARP`协议的包)
	4. `Payload`: `...`(`48 bytes`,这里面放的是`ARP`协议的包)
	5. `FCS`: 一个校验码,根据算法生成的,用于检错,我们现阶段不用太在乎里面装的什么 

* C发回以太网帧的时候应该是这样的:
	1. `Dst Mac Address`: `0x AA AA AA AA AA AA`
	2. `Src Mac Address`: `0x CC CC CC CC CC CC`
	3. `Ether Type`: `0x 08 06`
	4. `Payload`:
		1. `Hardware`: `0x 00 01` (表示以太网协议)
		2. `Protocol`: `0x 08 00` (表示`IP`协议)
		3. `Hardware Length`: `0x 06` (表示链路层协议有`6 Bytes`)
		4. `Protocol Length`: `0x 04` (表示网络层协议有`4 Bytes`)
		5. `Opcode`: `0x 02` (表示发回)
		6. `Src Hardware Address`: `0x CC CC CC CC CC CC` (源链路层地址)
		7. `Src Protocol Address`: `0x C0 A8 0A 65` (源网络层地址)
		8. `Dst Hardware Address`: `0x AA AA AA AA AA AA` (目标链路层地址,因为这里是请求地址,所以地址还不知道,所以填空)
		9. `Dst Protocol Address`: `0x C0 A8 0A 64` (目标网络层地址)
	5. `FCS`: 现阶段不在乎 


### 2 `Transport`层

* 在本小节中,我们将会了解`Transport`层中各个协议的作用以及结构

#### 2.1 `TCP`

##### 2.1.1 `TCP`协议的作用

* 在前面的章节中,我们提到过`TCP`协议为应用层服务,绝大多数`Application`层协议都需要`TCP`协议的服务,因为其能够在一定程度上保证数据一定送达,不会丢失数据,也不会顺序错乱

* 同时,网络的设计使得`TCP`是端到端的,那么意味着没人会在某一跳读你`TCP`相关的内容,`TCP`只关心发送方和目标主机的交流,不关心中间是如何跳的

* 同时正因为`TCP`协议是端到端的,所以它必须保证传输的数据一定是有序的,所以所有以`TCP`发送的,分散的,乱序的包,都会再经过一次目标主机的`TCP`协议,他负责将这些乱数据重组成`Application`层读得懂的内容

* 同时,本质上`TCP`不管在发送方和接收方来看,都是一个字节流,所以本质上在发送方,就是分割字节流再打包发送,而在接收方,本质就是解包后重组字节流,这也是为什么我们可以像读写文件一样读写一个`TCP Socket`,因为它和内存里的字节流没啥区别,只是多了几个校验,重传,重组等等几个步骤,而这些步骤都是`TCP`需要干的


##### 2.1.2 `TCP`协议的封装

* 和所有`Transport`协议一样,`TCP`协议需要封装来自`Application`的数据,然后形成一个`TCP Segment`,即`TCP`段
* 然后交由`Network`封装`IP Datagram`
* 最后交由`Link`封装对应协议的`Frame`

##### 2.1.3 建立连接与断开连接

* 建立连接的过程我们之前已经了解过了,即三次握手,这里我们回顾一下

* 如果A要和B建立连接:
	1. 首先A会发送一个`SYN`给B表示请求同步
	2. 然后B会发回`ACK`给A表示同意同步,并附带`SYN`给A表示请求同步
	3. 然后A会发回`ACK`给A表示同意同步

* 至此,两台主机已经建立了可靠的`TCP`连接了

* 那么如何断开连接呢?

* 如果A请求和B断开连接:
	1. 首先A会发送一个`FIN`给B表示`finish`,表示A要准备断开链接了
	2. 此时B如果还有数据没有传输完毕,就会可能会发回一部分数据,末尾会携带一个`ACK`,表示我同意断开连接,但是我的数据还没有传输完毕,要等待一会儿
	3. 当B如果完成传输了,那么就会发回一个`FIN`给A,表示我也完事儿了,可以断开连接了
	4. A会发回一个`ACK`给B表示同意断开连接

* 至此,这两台主机就断开连接了
* 这就是我们所说的"四次挥手"

* 那么好,如果B在进行第二次挥手的时候,恶意地不发回`ACK`,此时怎么办,难道A会无限地等待下去吗?
* 当然不会,`TCP`设计了超时机制,如果B不发回`ACK`,A就会持续地发送`FIN`,到达一定次数之后,如果B还是不做回应,那么A就会强制与B断开连接

##### 2.1.4 尽可能保证数据正确送达

* 注意,虽然`TCP`协议能在`IP`协议的基础上"确保"能够送达,但这种"确保"不是一定会送达,比方说难道网络断开连接了也能送达吗,显然不可能
* 所以`TCP`的"确保"送达更像是一种兜底机制,如果连`TCP`都没法送达了,那估计换其他的协议估计也不太行
* 所以换句话说,没人会愿意自己的数据不被送达,所以在`IP`协议这里就已经在尽最大可能让数据送达了,至于`TCP`更像是一种添加了重排的兜底机制,`IP`协议尽最大可能送达,但自己却不会做绝大多数的完整性检查等等,所以`TCP`帮助数据在两端做完整性检查,做重发,做重排,以保证传输过程中不会因为一些非人为错误导致数据混乱或者发送失败,但归根结底底层还是用的`IP`协议,所以连`TCP`其实也是没法保证"一定"能够送达的

* 现在我们来谈谈`TCP`是怎样做到尽可能保证数据正确送达的:
	1. "应答机制":当一个`packet`被接收之后,目标主机应该发回一个`ACK`来告诉发送方已经正确接收了,不需要重发
	2. "校验和"(checknum):它是一串数字,用于送达之后校验数据是否正确,确保不会因为某一跳导致数据缺失了一部分
	3. "序列号"(Sequence number):之前我们提到过,本质上送达的是字节流,所以本质上就是个数组,所以我们需要记录每个数据段在这个数组中最开始的下标,以方便我们送达之后恢复成字节流,同时,如果某个部分丢失,目标主机也能够知道它丢失的是哪个部分
	4. "流量控制"(Flow-control):如果发送方比接收方发包的速度快非常多,那么接收方的缓冲区可能会在一瞬间被塞满,这时候发送方如果接着发送就可能会导致数据没法写进缓冲区,此时就需要通过同步接收方的缓冲区,以保证不把缓冲区塞满的情况

##### 2.1.5 一个`TCP Header`的结构

* 一个`TCP Header`包含如图的内容
![[Pasted image 20250910164055.png]]

* 以下来详细做些解释:
	1. `Src Port`:发送方端口号,用于指代发送方的某个进程/服务
	2. `Dst Port`:接收方端口号,用于指代接收方的某个进程/服务
	3. `Sequence`:序列号,我们会在后面详细解释这个东西
	4. `Acknowledge Sequence`:确认号,我们一样会在后面详细解释这个东西
	5. `Head Length`:表示该`TCP Header`的大小
	6. `RSVD`:保留位,一般不使用
	7. `Flag`:
		1. `CWR`:用于`ECN`机制,暂时不用了解
		2. `ECE`:同样用于`ECN`机制,暂时不用了解
		3. `URG`:表示紧急提示,为`1`则会处理`Urgent Pointer`部分现在一般不建议使用
		4. `ACK`:表示确认
		5. `PSH`:建议接收方立即响应送达信息,比方说送达的是延迟敏感的数据,那么就几乎不会走缓冲区,而是立刻应答
		6. `RST`:`Reset`,立刻重置连接,一般用在不可逆的严重错误中
		7. `SYN`:表示请求,用于建立连接
		8. `FIN`:表示结束连接请求
	8. `Window Size`:窗口大小,这个就是用于告诉发送方剩余的缓冲区大小的,防止数据堆积
	9. `Checksum`:校验和
	10. `Urgent Pointer`:紧急指针,几乎不用
	11. `TCP Options`:这是一个可选项,可以自定义`TCP`的一些功能,不过几乎没人会自定义功能
	12. `TCP Data`:`TCP`数据

##### 2.1.6 `Sequence`和`Acknowledge Sequence`

* 本小节会比较复杂,个人觉得`TCP`协议中最复杂的也是这个了

* 首先我们得带入一个场景
* 假设现在有A和B两台主机,A已经和B建立了`TCP`连接,那么A向B发送了一个包
* 现在这个包在传输途中,遇到了拥塞或者其他什么的问题,总之就是包没法正确递达
* 按理来说,A发送了一个包,B会应答这个包已经到了,A应该会收到一个来自B的应答信息,但这里没有
* 于是A认为`TCP`连接已经断开,于是开始和B做重连(重连这个步骤其实是`Application`层做的,`TCP`本身不会做重连)
* 那么很顺利,重连很快完成了,A重新发送了一个包给B,B也成功拿到了这个包
* 但很不巧,原来那个因为拥塞而没有递达的包,现在突然不拥塞了,于是这个包传递给了B
* B如何判断这个包该不该接收?B只看四个东西:
	1. 源`IP`
	2. 源`port`
	3. 目的`IP`
	4. 目的`port`

* 之后我们聊到`TCP`的封装的时候会详细聊一下这个
* 那么很显然,这个本应该丢弃的包传递到了B手上,这四个东西都能对的上,那么B理应接受这个包,一旦这个包被接受了,那么就会变成一个未定义行为

* 所以现在,我们需要一个标识符用来区分一个包是旧包还是新包
* 所以我们现在可以搞一个规定,规定发送方必须发送一个类似于随机匹配码的东西
* 当A和B三次握手连接的过程中,双方都会随机生成匹配码,且双方必须确认各自的随机匹配码
* 每次发包的时候都必须携带这个匹配码才可以发包

* 这个匹配码就是一个`ISN`(初始序列号),初始状态下是随机分配的
* 那么好,此时以后就几乎不会再误收包了

* 那么`Sequence`和`Acknowledge Sequence`还解决了另一个问题,即包重排问题
* 那么,`ISN`是随机的,但只在他身上附加随机的属性未免有点太浪费了,于是我们想到了一个很好的解决办法
* 一个随机数本身具有随机属性,那么一个随机数加上一个固定的数,也具有随机性
* 所以,我们可以规定一个`ISN`,但同时当作我们传输可靠数据的虚拟的起点位置,每做完一次传输,其加上传输的可靠数据的大小

* 所以,`Sequence`最开始在三次握手阶段会初始化并交换`ISN`,这个`ISN`作为特殊的`Sequence`发送给对方

* 我们可以想象成这是一个虚拟的队列,这个队列中的每一个字节都是可靠的,且队列中的每一个包都附带了编号
* 但这个队列实际不存在,我们仅仅只是给包进行了编号而已

* 同时,因为每个有效的数据都需要可靠传输,那么三次握手的`SYN`本质上也是有效数据,需要尽可能保障不被丢失,所以每次发送一个`SYN`都会让`Sequence``+1`
* 那么为什么`ACK`包不需要让`Sequence``+1`?因为`ACK`只是一个应答信息,就像是我询问你,你给个`OK`一样,其实是不包含有效信息的,如果迟迟收不到应答信息,那么发送方会直接尝试重新链接,所以完全不需要在`ACK`包的`Sequence``+1`

* 所以实际传输中,`Sequence`和`Acknowledge Sequence`该怎么设置呢?我们实际看个例子:
	1. 三次握手阶段:
		1. A发送带有以下信息的包给B:
			1. `Sequence`:设置为属于A的随机的`ISN`,我们假设设为了`5000`,表示我的`ISN`从`5000`开始
			2. `Acknowledge Sequence`:为空
			3. `SYN`:`1`
			4. `ACK`:`0`
		2. B接收到之后发送带有一下信息的包给B:
			1. `Sequence`:设置为属于B的随机的`ISN`,我们假设设为了`2300`,表示我的`ISN`从`2300`开始
			2. `Acknowledge Sequence`:`5001`,表示应答,你是从`5001`发包给我,期待你的`5001`
			3. `SYN`:`1`
			4. `ACK`:`1`
		3. A收到来自B的包之后发送一个应答信息给B
			1. `Sequence`:`5001`,我这里从`5001`发送给你(或者说准备从`5001`发东西给你了)
			2. `Acknowledge Sequence`:`2301`,确认了,你是从`2301`发包给我,期待你的`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		4. 至此成功建立`TCP`连接
	2. 实际传输数据阶段:
		1. A发送一个`200 Bytes`的包给B:
			1. `Sequence`:`5001`,我这个包在我这里是从`5001`开始编号
			2. `Acknowledge Sequence`:`2301`,期待你的`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		2. B应答A:
			1. `Sequence`:`2301`,我这个包从`2301`开始(当然,回应的包本身不包含有效数据,所以不会`+1`)
			2. `Acknowledge Sequence`:`5201`,我收到了你从`5001`~`5200`的内容,期待你的`5201`
			3. `SYN`:`0`
			4. `ACK`:`1`
		3. 至此完成一次发包
	3. 四次挥手阶段
		1. A发送关闭请求给B:
			1. `Sequence`:`5201`,我这个包从`5201`开始
			2. `Acknowledge Sequence`:`2301`,期待你的`2301`
			3. `FIN`:`1`
			4. `ACK`:`1`
		2. B回应A:
			1. `Sequence`:`2301`,表示我这个包从`2301`开始(回应不占空间,我还可以从`2301`补充内容给你)
			2. `Acknowledge Sequence`:`5202`,收到你的`5201`~`5201`了,期待你的`5202`
			3. `FIN`:`0`
			4. `ACK`:`1`
		3. B没有东西要补充给A了,所以也发送请求给A:
			1. `Sequence`:`2301`,我这个包从`2301`开始
			2. `Acknowledge Sequence`:`5202`,期待你的`5202`
			3. `FIN`:`1`
			4. `ACK`:`1`
		4. A应答B
			1. `Sequence`:`5202`,我这个包从`5202`开始(应答信息没有有效数据不占空间)
			2. `Acknowledge Sequence`:`2302`,期待你的`2302`
			3. `FIN`:`0`
			4. `ACK`:`1`
		5. 至此连接关闭

* 所以,我们简单来说:
	1. `Sequence`:我这个包从我的哪里起始
	2. `Acknowledge Sequence`:期待你从哪里开始的包

* 至于`Sequence`的重排功能,我们可以理解为一个包到达之后,其实不会立刻被放进字节流中,而是需要先放进缓冲区中,`TCP`会检查顺序,我们举个例子,假设现在A和B已经建立连接了,A的`ISN`是`5000`从`5001`发包,B的`ISN`是`2300`,从`2301`开始发包:
	1. 第一次A给B发包:
		1. A发送`200 Bytes`的包给B:
			1. `Sequence`:`5001`
			2. `Acknowledge Sequence`:`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		2. 但这个包因为一些原因没有送达
	1. 第二次A给B发包:
		1. A发送`400 Bytes`的包给B:
			1. `Sequence`:`5201`
			2. `Acknowledge Sequence`:`2301`
			3. `SYN`:`0`
			4. `ACK`:`1`
		2. B对`5201`做检查,发现`5001`~`5200`这一段缺失了,所以暂时先把`5201`放进缓冲区,不放进字节流
		3. B回应A(这个步骤可能会重复1~3次甚至更多,意思是反复询问):
			1. `Sequence`:`2301`
			2. `Acknowledge Sequence`:`5001`,意思是,布什戈门,你的`5001`咋没了?
			3. `SYN`:`0`
			4. `ACK`:`1`
	2. B收到了A第一次延迟的包:
		1. B会一次性回应A的两次发包:
			1. `Sequence`:`2301`
			2. `Acknowledge Sequence`:`5601`,我收到你的`5201`了,期待你的`5601`
			3. `SYN`:`0`
			4. `ACK`:`1`

* 所以你发现了吗,`Sequence`用于表示当前包的起始字节的编号,然后接收端会根据这个包的有效数据大小和起始字节编号计算出我接下来期待哪个字节


##### 2.1.7 `TCP`的封装再谈

* 我们知道,四层结构是层层封装的,在`Network`层只存在一个`IP`协议,这意味着这个`TCP`段一定会封装进一个`IP`数据报中

![[Pasted image 20250911180315.png]]

* 一般一个机器是否会获取一个`TCP/IP`的包,取决于这个包中的这四个东西,其中`Src Port`和`Dst Port`来自于`TCP Header`,而`Src IP`和`Dst IP`来自于`IP Header`,当然准确来说需要取决于五个东西,最后一个是`Protocol ID`,用于检查这个`IP`数据报中存放的是什么类型的`Transport`层协议


#### 2.2 `UDP`

* 前面我们有简单提到过,`UDP`是一个不可靠传输协议,在本章节我们会详细了解一下

* 不过输出一个结论,`UDP`有点像是一个极其精简版的`TCP`,阉割了`TCP`中90%的机制,仅用于区分应该传输到目标机器的那个应用程序,其他的功能一概没有

##### 2.2.1  一个`UDP Header`的结构

* 可以先看一下这个图
![[Pasted image 20250921172153.png]]

* 没错,`UDP`就是这么简单,除了用于区分应该传输到目标主机的进程,几乎其他功能,我们现在来详细看一下:
	1. `Src Port`: 源端口号,可以告诉目标进程如果要回复的话应该往哪个进程回复
	2. `Dst Port`: 目标端口号,用于区分应该传输到目标主机的哪个进程
	3. `Checksum`: 检验和,用于校验数据是否损坏,这个在`IPv4`是可选的,但在`IPv6`是必须有的
	4. `Length`: 表示`UDP Header`+`UDP Data`的长度
	
* 为什么`UDP`要有`Checksum`?
* 主要是因为数据错误比错误丢失更可怕,数据错误可能会造成一些不可预见的问题,因为你都不知道递达的数据究竟会是什么样的,与其这样,不如直接丢弃数据,所以`UDP`还是有`Checksum`,目的是保证递达的数据要么绝对正确并接收,要么不正确并丢弃

* 另外,为什么`IPv4`可以没有`Checksum`,而`IPv6`一定要有`Checksum`呢?
* 因为`IPv4`协议自身就会校验自己的`IP Header`,而`IPv6`完全不会校验自己的`IP Header`,需要依赖`Transport`层的协议校验`IPv6`协议的`Header`

##### 2.2.2 多路分解协议

* 所以你能看到,`UDP`几乎只有"分辨要传给哪个端口"的功能,以及极其轻量化的校验机制
* 所以这个协议被理解成在目标主机用于"多进程划分数据"的协议也是可以的

##### 2.2.3 总结

* 所以,对于`UDP`来说,有以下几个性质:
	1. 不保证可靠传输,或者说可靠性没有`TCP`那么强
	2. 没有重排机制,所以如果一定要重排的话,得在`Application`层自己搞协议重排
	3. 没有重传通知机制,同样的,重传也得在`Application`层自己搞协议重传
	4. 没有建立连接机制,没有确认机制

* 那么那些地方用到了`UDP`呢,比方说`DNS`解析就用到了`UDP`,主要是轻量,相应快速,没有成功就在`Application`搞重传机制


#### 2.3 `ICMP`

* 这是一个`Network`层协议,用于反馈错误,全称是"Internet Control Message Protocol","互联网控制消息协议"

* 比方说,我试图在一个内部网络访问外部网络,于是主机会发包给路由器,但路由器因为没连接到外部网络,转发表里任何一个目标地址都不匹配,那么这个包就只能丢失,于是路由器会通过`ICMP`协议通知用户到底发生了什么故障导致传输失败

##### 2.3.1 一个`ICMP`消息的一生

* 我们回到例子,当一个路由器发现一个`IP`协议的包没法转发时,他会把这个`IP`的`Header`取出,并且顺带把`IP Data`的前面`8 Bytes`也取出,作为一个`ICMP`协议的`Data`
* 同时`ICMP`会在自己的`Header`中塞入`Type`和`Code`这两个东西,其中`Type`用于表示发生了什么类型的错误,`Code`表示在`Type`这个大类型之下具体发生了什么问题
* 然后将这个`ICMP`包封装进`IP`然后发回给源主机

* 大概就是这张图表示的这样
![[Pasted image 20250921190323.png]]

* 如你所见,`ICMP`会截取`IP Data`的原因在于,它可以通过这种方式,告诉源主机应该把这个错误信息发给哪个进程

* 这里再截一张来自于维基百科的图,这里列举了一些常见的错误信息
![[QQ图片20250921190757.png]]

* 路由器通过将`ICMP`数据报封装进`IP`数据报中实现发回问题给源主机的效果


##### 2.3.2 `ICMP`的应用

###### 2.3.2.1 `ping`命令

* 我们经常用的`ping`命令就是利用了`ICMP`协议实现"尝试通话"这个操作的
* 我们可以仔细看看常见错误信息的这个图,其中类型`8`就是我们所关注的核心,这个类型表示请求一个目标主机用`ICMP`回复源主机
* 所以源主机会打包一个几乎是空的的`ICMP`数据报,其中`Type`是`8`,`Code`是`0`,并封装进`IP`数据报中,然后发送给目标主机
* 目标主机接收之后就会发回一个`Type`是`0`,`Code`是`0`的`ICMP`数据报给源主机表示相应回显

###### 2.3.2.2 `Traceroute`工具

* 这个工具可以用于检测当前主机到目标主机会经过多少跳
* 他的实现方式也很简单,她用了一个很巧妙地技巧
* 我们知道,`IP`协议中会存一个叫`TTL`(Time To Live)的字段,用于描述这个包还能跳多少次
* 如果一个包因为`TTL`减到`0`而导致被丢弃,那么路由器会发送`ICMP`协议的包(`Type=11`表示`ICMP`超时,`Code=0`表示`TTL`超时)回来
* 所以我们可以利用这个机制,发送携带固定数字`TTL`的包(`UDP`+`IP`协议)出去,并等待接收`ICMP`协议的包回来,就可以知道现在是第几跳
* 比方说第一次发送`TTL=1`的包出去,那么回复的肯定是第一跳,第二次发送`TTL=2`的包出去,第二次回复的肯定是第二跳,循环往复我们就能找出来我们到目标主机到底经过了多少跳
* 那我们怎么知道什么时候到了目标主机了呢,这时候我们会用另一个巧妙的办法
* 每次我们发出去的包,其中`UDP`指定的目标端口号都是一个实际一定不会存在的端口号,于是目标主机识别到这个端口号发现这是一个完全错误的端口号,于是会通过`ICMP`+`IP`协议(`Type=3`表示目的不可达,`Code=3`表示目标端口不可达)发回给源主机
* 源主机的`Traceroute`接收到目标主机的包之后,他也就知道本次检测已经完成了,就会自己退出

##### 2.3.3 附加

* 不过本质上`ICMP`其实并不是一个`Transport`层的协议,而是`IP`协议的子协议,但他会返回`Transport`层的错误回来,服务于`Transport`层,就有点像是这个协议是一个`Transport`层协议的感觉


#### 2.4 `End-to-End`(端到端原则)

* 这里我们重谈一下端到端原则

* 所以,为什么我们的每一跳都要设计得这么简单?为什么一定不能添加其他的功能?为什么不添加功能反倒能保证数据要么能够完整递达,要么被丢弃?

* 原先斯坦福大学的学生试图每一跳中添加安全检查,用来防止出现传输中的错误,但事实证明在每一跳添加安全检查是一个完全错误的选择,因为当时出了一个问题,虽然每一跳都会做安全检查,但是检查的都是传输时发生的问题,而在每一跳的机器的内存中出的问题这个没法在中途进行检测,但当时他们认为,在中途检测之后,两端就不需要进行检测,对于程序设计来讲会更加简单,所以实际上他们也确实这么做了,但结果就是,他们无法规避某一跳的内存中的`bug`所导致的数据出错,又因为摒弃了两端检查,所以就导致了递达的数据是错误的,而且还实际使用了错误的数据
* 所以实际上,每一个机器的每一个内存,每一个传输过程,都有可能导致数据出错,这个没法避免,所以,我们必须在两端进行检查,既然都在两端进行检查了,那么在中间任何一跳进行检查都没有任何意义了

#### 2.5 跳到跳错误检测

* 虽然我们一直强调端到端原则,不过实际上,在跳到跳我们也还是会用一些错误检测机制,之前我们聊过的`Checksum`就是这种检测机制
* 值得注意的是,虽然跳到跳有检测机制,但实际上我们依旧需要在端到端做错误检测,特别是在`Application`,必须手动做检测,否则可能会出现我们上一小节聊到过的情况,特别是安全敏感场景,比方说银行系统,甚至需要做非常多种的检测才能保证完全不出错

##### 2.5.1 `Checksum`校验和

* 校验和用了一种非常简单的机制用于错误检测
* 该机制将数据分为一个个的`16 Bits`的段,然后将每个段相加得到`Sum`,并将`Sum`取反就得到了`Checksum`
* 比方说,我要发送一个`0xABCD77668080`,我们将其分为`3`个`16 Bits`段并相加,即`0xABCD + 0x7766 + 0x8080 = 1A3B3`,因为`Checksum`最大只有`16 Bits`,所以实际上如果超出的话会重新从`0`开始计算,此时就会变成`A3B4`,然后将其取反得到`Checksum = 5C4B`
* 那么接收端如果要使用`Checksum`进行检测,其方式也非常简单,只需要把所有数据按`16 Bits`相加,并同时加上`Checksum`就行,如果得到的结果是`0xFFFF`,那么表示数据没出错(不一定)
* 那么,为什么相加之后,如果没错就一定会等于`0xFFFF`?
* 因为我们之前把所有段相加得到的数是`Sum`,而`Checksum`是这个数的取反,那么相加之后就一定是`0xFFFF`,相加数据相当于再次计算一遍`Sum`

* 但细心的你肯定发现了,这种校验方式简单,但不是特别保证安全
* 假设我通过银行程序转账给别的账户,如果我转出的金额是`0x8000`,但传输过程中最前面的字节和最后面的字节发生了交换,此时我的求和是没有发生任何改变的,`Sum`依旧是`1`,这就导致接收端会认为数据没出错,但实际上数据已经从三万多变成了一块钱了

* 这种校验方式能检测出奇数个错误,不保证能检测出偶数个错误,不过虽然嘴上说这个校验算法非常简单也非常菜,但是实际上即便是这样,也能够检测出99%的错误了

##### 2.5.2 `CRC`循环冗余校验

* 我们先了解一下这个算法的原理,稍后详细解释为什么这么做
* 首先,我们知道,一个被除数除以一个除数可以得到一个结果和一个余数,如果这个被除数被改变了,那么得到的余数也会不一样
* `CRC`的本质就是这个,发送方与接收方约定一个除数,发送方将数据除以这个除数,得到一个余数,将这个余数作为校验码一并发给接收方,然后接收方再次计算一边得到的数据,对比一下校验码就知道数据有没有丢失了

* 接下来我们来详细解释一下原理
* 这里可能会有一点点复杂
* 我们将要传的数据转换成二进制,会得到一串类似于这样的二进制串
* `b_k-1 b_k-2 ... b_0`,这里的`b_k-p`代表第`k-p`个二进制数字
* 我们将其带入一个多项式,这个多项式不需要被算出来,因为我们只需要计算其系数,不需要算实际的值
* 将以上这个式子转换成这样:`b_k-1*X^(k-1) + b_k-2*X^(k-2) + ... + b_0*X^0 = M(X)`
* 我们假设双方约定了这样一个除数(也是一个多项式):`X^5 + X^2 + 1 = G(X)`
* 那么我们需要将`M(X)`左移`6`位(这个地方可能看起来很奇怪,不过我们会在后面进行解释)
* 发送方将这个`M(X) % G(X)`得到一个余数多项式,令这个余数多项式为`R(X)`,`R(X)`的表示形式也和`M(X)`一样,所以它也可以转化成一个普通的二进制序列
* 那么发送方只需要把`M(X) + R(X)`转化成的二进制序列发送给接收方,接收方就可以自己除一下判断有没有问题了

* 我们举个例子(这里所有的式子都用二进制序列表示)
* 假设发送方要发送`1001 1101`,双方约定了`100101`作为除数,那么左移后取模得到余数为`010101`
* 因为除数是一个`6`位数字,所以余数最多可以有`6`位,所以我们把要发送的左移`6`位,这样除数可以跟在发送数据的后面
* 所以最终会发送`0010 0111 0101 0101`给发送方
* 发送方根据约定的除数,判断后`6`位是余数,因为`0010 0111 0100 0000`除以`100101`后会得到一个余数,那么`0010 0111 0100 0000 + 010101`后,再除以`100101`,就一定不会得到余数,此时一定会整除,那么如果没有整除成功,证明有数据丢失

* 那么,我们将理论的时候,用的是多项式相除,为什么实际可以是二进制相除呢?
* 很简单,你令多项式的`X=2`,不就是二进制了吗(这里其实这么理解是不完全对的,本质上其实是:`CRC`的运算不是普通整数除法，而是在 `GF(2)`上的多项式除法)

* 这里要着重提的是,这个`G(X)`的选择其实很有讲究,因为不同的`G(X)`能够判断的数据丢失类型是不同的,强大的`G(X)`很长很长,能够判断几乎99.9999999999%的错误
* 这里的这个`G(X)`我们就称为`CRC`
* 这里贴一下维基百科关于`CRC`的表
![[QQ截图20250922180409.png]]

##### 2.5.3 `MAC`(Message authentication code, 消息认证码)

* 简单来说,`MAC`是一个密钥检测机制
* `MAC`的思想源自于密码学,也和数学相关,我们不会在本小节深入算法细节,因为这确实很麻烦
* 核心思想是这样的:
* 假设现在有两台主机`A`与`B`,两者存在一个相同的密钥`K`,当`A`准备发送包给`B`的时候,他会通过`MAC`算法,通过数据唯一的包`M`和唯一的密钥`K`计算出一个唯一的随机编码`T1`,严格来说这个`T`不是随机的,它是由`M`和`K`生成的,当`B`接收到`M`之后,他会做相同的操作,通过`M`和`K`计算出随机编码`T2`,通过比对`T1`和`T2`,就可以判断这个包在传输中途有没有被篡改

* 但因为这个随机编码`T`是通过算法算出来的,我们也不可以保证某种特定情况下,在发出方和接收方的`M`不同的情况下,依旧能生成同样的`T`,所以`MAC`不保证能检测到任何一种数据错误



#### 2.6 `FSM`(finite-state machine, 有限状态机)

* 简单来说,`FSM`是一个图,这个图描述了很多状态,方便程序员将简单的图例转化成复杂的逻辑,换句话说,就是让逻辑更清晰更可控一点
* 我们简单的描述一下一个`FSM`包含了什么,首先先看一下这个图例

![[Pasted image 20250926193410.png]]

* 类似于这种图示,我们就可以称作是有限状态机
* 一个状态因为某个事件变成了另一个状态,同时会做出一些操作或者行为
* 当然,这个对象接收到的事件可能是一个未定义的事件,那么这个行为的转换也是一个未定义行为,但我们这里是"有限"状态机,所以对于这种未定义行为肯定要做出一些限制
* 当然,一个状态机描述的状态可能会非常复杂,状态量非常多,直接画图可能会显得很乱,所以很多时候会省略一些不太常见的状态,仅描述核心的,常见的状态,至于其他状态可能会备注一些补充说明什么的
* 当然,对于未定义行为,你也可以专门为其设计一个状态,这个状态直接由用户规范他的事件和行为,这也是可行的

* 老实说,在学习这个部分的时候我觉得使用"状态机"这种东西其实可以用于写另一个"玩意",你可能听说过这个"玩意",叫做"元胞自动机",这是由冯诺依曼提出的模型,感兴趣的话可以搜一下(当然,实际上冯诺依曼提出的元胞自动机其实并没有实现出来,因为状态太复杂了)

* 接着我们可以来看一下`TCP`的`FSM`

![[Pasted image 20250926192210.png]]

* 我们来详细解说一下`client`和`server`的状态:
	1. `client`处于`CLOSED`状态,表示其连接关闭,`server`处于`LISTEN`状态,表示其正在监听是否有`client`发送请求
	2. `client`现在发送`SYN`请求,也就是做"Step 1 of the 3-way-handshake"这个步骤,也就是进入事件`CONNECT`,行为是发送`SYN`,然后`client`进入`SYN SENT`状态
	3. `server`收到事件`SYN`,然后做出发送`SYN+ACK`的行为,并转换状态到`SYN RECEIVED`
	4. `client`收到事件`SYN+ACK`,做出发送`ACK`的行为,并将状态转换到`ESTABLISHED`,表示连接已确立
	5. `server`收到事件`ACK`,不做出任何行为,将状态转换到`ESTABLISHED`,表示连接已确立
	6. `client`进入事件`CLOSE`,于是做出发送`FIN`的行为,并转化到状态`FIN WAIT 1`
	7. `server`接收到事件`FIN`,于是做出发送`ACK`的行为,并转换到状态`CLOSE WAIT`
	8. `client`接收到事件`ACK`,不做出任何行为,转换到状态`FIN WAIT 2`
	9. `server`也进入事件`CLOSE`,于是做出发送`FIN`的行为,并转化到状态`LAST ACK`
	9. `client`接收到事件`FIN`,于是做出发送`ACK`的行为,并转换状态到`TIME WAIT`
	10. `server`接收到事件`ACK`,不做出任何行为,转换状态到`CLOSED`
	11. `client`因为超时而转换状态到`CLOSED`

* 至此,一个完整的`TCP`过程结束


#### 2.7 流量控制

* 老实说,其实我们之前已经谈过流量控制的一部分内容了,只是当时大家还不太了解谈的东西关乎于流量控制

* 流量控制有两种策略:
	1. `Stop & Wait`: 基于一问一答模式的流量控制,优势是简单,不容易出错,缺点是效率过低
	2. `Sliding Window`: 基于滑动窗口的流量控制,优势是效率可以动态变化,效率可以非常高,缺点是更加复杂更容易出错

* 需要流量控制的原因也很简单,因为接收方接收的带宽可能是有限的,如果发送方的带宽过大,就会导致接收方来不及接收这么多数据,于是就会导致网络传输了毫无意义一定会被丢弃的数据,造成了资源的损耗

* 接下来我们详细聊一聊

##### 2.7.1 `Stop & Wait`

* 这个策略非常简单
* 就像是对讲机的一问一答一样,当发送方的数据包传输到之后,接收方会表示收到,然后发送方会发送下一个包
* 这样,对于这两台机器来说,发送方和接收方之间建立的网络连接中,只存在一个包在传输,这样就一定不会有资源损耗了

* 我们说得更复杂些:
	1. 发送方发送了包1
	2. 接收方接收了包并回复`ACK`
	3. 发送方发送了包2但是因为网络问题没有送达
	4. 超时之后发送方会重发包2
	5. 接收方接收了包2并回复`ACK`
	6. 发送方发送了包3
	7. 接收方接收了包3并回复`ACK`
	8. 回复的`ACK`因为网络问题没有送达
	9. 发送方以为没有送达,所以超时之后重发包3
	10. 接收方接收了包3并回复`ACK`
	11. 发送方发送了包4 
	12. 接收方接收了包4并回复`ACK`
	13. 回复的`ACK`因为网络问题没有送达
	14. 发送方以为没有送达,所以超时之后重发包4
	15. 接收方接收了包4并回复`ACK`
	16. 发送方发送了包5
	17. 突然间,之前没有接收成功的`ACK`突然恢复正常了,突然就被发送方接收了,那么发送方无法判断包5是否被接收!

* 以上,我们详细了解了可以解决的三种问题,即:
	1. 正常发送正常回复
	2. 发送失败
	3. 回复失败

* 现在有一个无法解决的问题: 即回复失败之后突然恢复正常

* 解决方式很简单,因为我们没法区分回复的`ACK`是针对哪个包的,所以只需要做区分就好了
* 发送方每次发送携带一个专用的识别码
* 接收方每次回复的时候携带相同的识别码回去
* 所以我们回到例子:
	1. 发送方发送了包4 
	2. 接收方接收了包4并回复`ACK`
	3. 回复的`ACK`因为网络问题没有送达
	4. 发送方以为没有送达,所以超时之后重发包4
	5. 接收方接收了包4并回复`ACK`
	6. 发送方发送了包5
	7. 突然间,之前没有接收成功的`ACK`突然恢复正常了,突然就被发送方接收了,那么发送方对比识别码发现这个识别码是一个已经应答的包4的识别码,所以发送方选择忽略这次重复`ACK`

* 那么,有没有办法给这个策略提速呢?肯定是有的,不过我们得谈谈导致这个策略速度慢的本质
* 我们知道网络是有延迟的
* 在这个策略中,我们采用的其实是串行传输,所以两个包发送的间隔取决于回复速度
* 而回复速度其实取决于延迟,毕竟发包的速度很快,慢的是传输嘛
* 所以解决速度慢问题的最简单的方式就是降低延迟

##### 2.7.2 `Sliding Window`

* 这种控制方式就比较麻烦了,不过这可以联系上我们之前了解过的`Sequence`和`Acknowledge Sequence`字段

* 先来讲讲滑动窗口方面(滑动窗口是一个很常用的算法,这里我们不深究算法内容)
* 为什么需要滑动窗口?
* 因为,传输延迟是不可避免的!所以不管你再怎么优化,远距离传输中`Stop & Wait`的上限其实并不是非常高
* 所以有了滑动窗口,因为滑动窗口策略是并行传输的!
* 滑动窗口策略允许两个端之间的网络中存在多个包!
* 对于发送方来说,他存在一个窗口,这个窗口中会维护多个包,也就是我们在`Sequence`和`Acknowledge Sequence`小节中提到过的`ISN`,这个窗口的下标会基于`ISN`设计
* 发送方会按顺序一次性发送窗口中维护的多个包
* 接收方接收的包不一定会按顺序抵达
* 假设发送方窗口大小是`6`,因为`ISN`导致窗口的起始位置是`1000`,单个包的大小是`2`,接收方窗口大小也是`6`,窗口起始位置是`3000`:
	1. 发送方发送`1000~1001`,`1002~1003`,`1004~1005`
	2. 此时接收方已经接受到了`1000~1001`,回复`ACK`并表示期待`1002`,同时其窗口后移接受到的包的大小,此时窗口起始位置是`3002`
	3. `1002~1003`传输过程中被遗失了,但接收方依旧收到了`1004~1005`,此时接收方会`ACK``1002`表示期待你的`1002`(或者说你的`1002`为什么没到?!),此时窗口里虽然有值(`1004~1005`那个包),但是因为窗口前面有空着的`3002~3003`,所以窗口不移动
	4. 发送方超时后,检查最后一个收到的`ACK`发现对方还在等我的`1002`,于是发送方重发一边`1002~1003`
	5. 这次接收方正常接收了,于是接收方回复`ACK``1006`,表示我期待你的`1006`且前面的内容我都已经收到了,于是窗口后移到`3006`
	6. 接收方接收了`ACK`后发现维护的窗口的所有内容对方都已经接受到了,所以也后移自己的窗口到`1006`

* 我们称"窗口前部有连续的存在字节就移动窗口"的这种策略为"累积确认"

* 那么,换句话说,其实接收方发送的期待值,其实某种角度也代表着自己的窗口的起始位置
* 另外发送方和接收方的窗口大小其实并不固定,接收方会告诉发送方自己还有多少剩余空间,也就是我们在`TCP Header`中学习的`Window Size`字段的功能
* 所以这个窗口大小其实是可以动态调整的

* 那么理论上,发送方应该维护这几个变量:
	1. `Send Window Size`(`SWS`): 即发送的包的窗口大小
	2. `Last Acknowledgement Received`(`LAR`): 最后一个回应的位置,即接收方最后期待的位置
	3. `Last Segment Sent`(`LSS`): 最后一个发送的位置

* 所以理论上,最差的情况就是其他包都到了,只有第一个包没有到,所以一定有`LSS - LAR <= SWS`

* 同时,接收方应该维护这几个变量:
	1. `Revive Window Size`(`RWS`): 即接收方的窗口大小
	2. `Last Acceptable Segment`(`LAS`): 即最后一个期待包的位置
	3. `Last Segment Received`(`LSR`): 即最后一个接收的包的位置

* 所以在最差的情况下,一定也会有`LSR - LAS <= RWS`

#### 2.8 重传策略

* 重传策略一般分为两种:
	1. `Go-Back-N`("回退N",`GBN`)
	2. `Selective Repeat`("选择重传",`SR`)

* 前者是一个极其悲观的策略,窗口中有任何一个包丢失,该策略都会直接重传整个窗口的所有包
* 后者则是非常乐观的策略,仅重传丢失的某个固定的包

* 我们在使用滑动窗口做流量控制的时候,一般会采用第二种策略,但如果接收端窗口大小是`1`,那么将会退化为第一种策略
* 主要原因是,如果接收端窗口为`1`,那么他无法缓存处于丢失的包之后的包(`index`位置的"之后"),所以如果丢包了,那么之后传的任何包丢直接丢失了,因为不在接收端窗口内

* 两种策略各有优劣 
* `GBN`更适合网络通信不太好的情况,因为他的重传检测很快,如果网络总是丢很多包,那么这种策略的"命中概率"会很高,那么可以节约很多关于`ACK`回复的延迟等待的时间,不过宏观来看,这种策略还是非常保守 
* `SR`则适合网络通信良好不容易丢包的场景,可以节约网络资源,如果网络不太好还使用`SR`,那么每个包都得一个个重传,同时还得一个个等待`ACK`,每等待一个`ACK`,都会造成一次端到端通信的延迟,那么宏观的看,就会造成很大的延迟,浪费时间


### 3 分组交换(`Packet Switching`)

#### 3.1 网络的历史

* 在CS144课程中花了一些篇幅聊网络的历史,固然这段历史很重要,但归根结底并不是这篇笔记的核心,所以我们仅作了解

#### 3.2 我们为什么需要分组交换

* 虽然在之前我们有简单了解过分组交换的相关概念,但在本章节我们会更加深入地理解分组交换的实质

* 在深入分析"我们为什么需要分组交换"这个话题之前,我觉得还是有必要讲一讲CS144中提到的例子,这对我们后续理解分组交换的意义有很大的帮助

##### 3.2.1 电话线路交换

* 不清楚你是否知道有个职业叫做"接线员",现在这个职业已经被彻底取代了,如果你是00后,哪怕你听说过这个职业,也可能不太清楚这个职业具体是做什么的

* 在发明线路电话的时候,很明显,一条电话线会被两个处于端点的人拥有
* 但很显然,我们无法为所有人分配一条电话线,毕竟这很昂贵,如果每个人都有电话线的话,那么每添加一个联系人,就需要新增一整条电话线
* 所以,后期的做法是,每个人会拥有一条电话线,但不是完整的,在没有拨通电话的时候,这条电话线连接的是"转接服务中心"
* 如果我要打给某个人,我就得告诉"服务中心的接线员"我要打给谁,然后接线员会在物理上帮我接电话线到对方
* 然后在通话的过程中,我和对方会独占这条电话线

* 所以你会发现一个有趣的事情,接线这个操作,本质上不就是"路由"吗?

* 而对于现代电话通信中,"路由"的操作通常就不是由人类来进行了,同时是通过电路来路由目的地,同时,传输过程中也不仅仅是只经过一次"路由",而可能会经过多次路由

* 另外,虽然现代电话线路中,其线路物理上可以被多个人共享,但是本质上所有的线路依旧被两个端点独占,所以我们依旧按照传统方式看待现代电话线路

* 但势必的,如果一条线路会被短暂独占,那么就需要为所有的路由增加"状态",一般我们简单地把路由看作有三个状态:
	1. 拨号
	2. 通话
	3. 断开

* 虽然新增状态可以让拨号这个操作变得自动化,但是可维护性却大大下降了

##### 3.2.2 网络中的分组交换

* 网络中的分组交换其实本质上也是路由,看起来比"电话路由"要更加复杂,但实际情况是,网络的交换其实更加简单,这点你应该可以在之前的小节中窥见
* 不使用电话的交换方式的主要原因其实很简单:电话线路交换需要维护状态!
* 换句话说,电话线路交换中,每条线路会维护单一的状态,那么一旦这么做,会导致线路被独占
* 那么,网络独占线路有什么错吗?这点我们之前也提到过,你正在打游戏,已经匹配上了,结果就因为室友在下电影,所以哪怕匹配进游戏了,也没法直接开打
* 更深入的说,互联网的连接讲究一个突发性,需要有很高的时效性,那么独占的思路必然是有问题,所以必须采用共享线路的思路
* 另外,一旦线路有了状态,那么维护线路将会是一个很麻烦的事情,并且维护状态造成的性能开销也可能会让延迟增加
* 同时,这也造成电话线路的灵活性较差,比方说通话过程中某个线路突然断开了,那么通话就直接没了,如果采用分组交换的话,就可一定程度上使用别的线路(本质就是使用转发表的其他下一跳来规避问题线路)

* 当然,另外一个需要提到的点是,因为路由器发包是串行的,所以如果路由器同时收到两个包,他得先存一个包,然后发另一个包,等到另一个包发完了才会发这个存的包,所以路由器或者说传输中间的任何一跳都是一定会有缓存的

#### 3.3 延迟&丢包

* 因为网络是一个突发敏感的传输方式,所以计算延迟是一个非常重要的步骤
* 我们来看看计算网络延迟大概需要哪些内容

##### 3.3.1 三种延迟

* 首先是物理延迟,或者说信号在介质中传输的延迟
* 要知道,电信号一般的传输速度都接近光速,我们按照`2 * 10^8 m/s`计算 
* 按照CS144课程中的例子,如果传输介质长`1000km`,在不考虑其他因素的前提下,那么信息从发送方传输到接收方所需时间大概是`1000km / (2 * 10^8 m/s) = 5ms`,那么,延迟至少是`5ms`起步

* 另一个值得注意的是"分组延迟",这个延迟其实很有意思
* 我们知道数据被转化成`0`&`1`,然后变成高低电平,也就是电信号,这些信号是串行的,因为某个时刻,某个数据线中的某一段的电平不可能有高低两种状态
* 所以发送方把数据传递给信号线也是需要时间的,我们把发送方从开始传递第一个`bit`到结束传递最后一个`bit`的过程称为"分组延迟"
* 换句话说,你知道你的电脑的网卡也是有旗舰款,中端款和低端款吗?
* 款式越低,那么网卡传递信号出去的效率也会越慢,然后分组延迟也就会越高
* 一般分组延迟是这样计算的,如果我我们知道网卡设备将数据塞进传输设备的速度,这里同样用CS144的例子,假设速度是`100Mb/s`,那么将一个`64byte`的包放进介质中需要约`64byte / 100Mb/s = 5.12μs`
* 如果速度是`1kb/s`,将`1kbit`的包放进介质中则需要约`1.024s`

* 所以,就以上两种延迟,我们来画个图(原图依旧是来自CS144)
![[Pasted image 20251002223038.png]]

* 在这个图中,我们假设有两台主机,中间有一台路由,`A`需要经过路由发包给`B`

* 那么,发送方不会在一瞬间就发送完整个包,于是就会有一种情况,在某个时刻,链路上存在着一个不完整的包,因为包还没有完全发送完毕
* 同时也会存在一个时刻,`A`认为自己已经发完了包,路由认为`A`啥也没发给他,因为包还在路上
* 同时也会存在一个时刻,会有一部分不完整的包还在链路中,剩下的内容已经被路由拿到了
* 只有当路由中的包完整了,路由才会选择转发出去

* 那么,一个包被路由接收之后,一定会立马被转发出去吗?
* 当然不会,如果这个路由在某个瞬间接收了太多包了,那么你的包有可能需要在路由的缓存中排队一段时间,然后才被发送到下一跳
* 那么,此时咱们的图就有可能变成这样
![[Pasted image 20251002231247.png]]

* 当然,如果这个路由在一瞬间有超出路由缓存上限的包试图进入路由,那么路由有可能会直接丢弃包, 如果你的学校人比较多的话,一般在大型的且没有意义的活动上可能就会这样,明明连接着5G,却什么也访问不了像是断网了一样,这时候我们可以尝试着切换到4G,这样排队的人会相对较少,至少能上网了

* 所以说,如果你交换信息的目标地址离你的物理距离特别远,那么传输介质的长度会很长,同时中间需要经过的跳的数量也会有极大概率显著增加,那么遇到排队的概率也会显著增加,这就也是我们访问远端主机的时候延迟非常大的原因之一

* 所以,就我们**现在了解的内容**综合来看,一个包的延迟为"传输延迟"+"分组延迟"+"可能的排队延迟"

##### 3.3.2 接收端缓冲

* 使用网络有着很多不同种类的场景
* 有些场景对于延迟极其敏感,而对于延迟敏感的场景,我们又可以分为需要与其他主机同步的场景与不需要与主机同步的场景
* 比方说网络游戏就对延迟非常敏感,并且需要与他人同步状态,所以对于网络的要求非常苛刻
* 又比方说在流媒体网站观看视频,如果体现在用户上,这种场景一样对于延迟非常敏感,但因为不需要与其他用户同步,所以他可以通过缓存来极大地提升体验
* 另外也有完全不在乎延迟的场景,比方说文件下载或者是网页加载这种
* 本小节着重了解第二种场景

* 我们假设视频文件的发送方按照某个固定速率发送视频,比方说发送方以`1Mb/s`的速率发送视频过来,用户也以`1Mb/s`的速率播放视频
![[Pasted image 20251003161041.png]]

* 那么,接收方接收到数据之后不会立马使用,就比方说我们在看长视频的时候,视频也不会立马播放,他可能会缓冲大概半秒钟左右才会播放
* 此时就是该进程正在接收数据并缓存的过程
* 缓存到一定程度之后,才会开始播放,此时就不会造成用户的卡顿
* 某个时刻,用户可能才看到大概第`1`分钟,但程序在后台已经缓存到大概第`2`分钟了

* 如果网络延迟太高,或者丢包率太高,就有可能会造成以下情况
![[Pasted image 20251003162158.png]]

* 当缓存量已经不满足用户播放的需求量时,就会造成赤字,于是用户就会卡顿直到留有一定缓存才会播放

* 所以换句话说,我们可以尽可能保证平均到达速率和播放速度差不多,或者说平均到达速度大于播放速度,但我们没法保证某个短时间内的到达速率(或者也可以说某个瞬间的接收端斜率)一定大于等于播放速度,所以我们需要缓存来提升用户体验,避免因为网络波动造成的卡顿

##### 3.3.3 排队模型(`queue models`)

* 这个小节的内容其实很简单,甚至说你可以通过之前学过的内容直接推断出来,所以本小节实际上几乎仅作为结论的输出
* 简单来说就是在路由中存在一个缓存,该缓存会被当作一个队列来使用:
* 这个队列会有的属性,包括某时刻的输入总量(可能来自不同机器),某时刻的缓存量,某时刻的输出总量,输出速率,根据这几个属性画了一个横坐标是时间,纵坐标是数据量的折线图,包括该缓存的接收折线与输出折线,于是我们可以根据这两个折线分析该缓存的属性与状态 
![[Pasted image 20251003212224.png]]
* 为什么包越小,延迟会越小?那么原因其实很简单,因为包越小,就越可以接近并行传输,缓存可以在接收一个包的时候发送另一个包 
![[Pasted image 20251003211936.png]]
* 另外,通过一个更复杂的折线图,我们可以了解到,只要一个缓存在某一时间段内的平均接收速率小于输出速率,且缓存始终没有吃满,那么就不会丢包,但可能会缓存,如果一个缓存的在某一时间段内的峰值接收速率小于输出速率,那么甚至连缓存都没有,一般可以直接输出

![[Pasted image 20251003213809.png]]
![[Pasted image 20251003213816.png]]

* 那么我们假设在`v2`开始缓存之前,`v1`缓存的数据已经全部被输出掉了,那么假设`v2`的大小已经大于了能够缓存的上限了,那么超出的部分将会被直接丢弃,也就是丢包了

##### 3.3.4 "随机"与延迟与泊松分布

* 首先复述一个之前我们已经了解过的结论
* 对于一个路由/交换机来说,包的抵达是一个非常随机的事情,如果有非常多的包在同一时间抵达,那么延迟就会非常高,甚至于丢包,以下我们会通过一个例子来说明这个问题

* 假设在一个路由中,`5s`内,平均`1s`就会有一个包到达,这里假设所有的包的大小都相同,假设一个包从介质中抵达路由需要`0.2s`(实际肯定要短得多,这里只是许个例子),一个包被路由输出的时间为`0.4s`
* 那么最好的情况应该是每隔`1s`就正好有`1`个包到达,那么在这`1s`中,前`0.2s`将会是接收包的过程,紧接着的`0.4s`应该是发送包的过程,剩下的`0.4s`,路由器什么都不做,处于等待/监听状态
* 在这种情况中,不会有包需要排队
* 但是,如果`5s`内,这`5`个包全部在同`1s`内全部被路由接收,那么先进的包不需要排队,第二个包需要等待`0.2s`,第三个包需要等待`0.4s`,如此递推
* 虽然平均接收的包并不多,但是仍然造成了延迟

* 我们很难估量某个时间段内会有多少数据包抵达,因为包的抵达几乎是纯随机的,所以我们需要借助泊松分布来衡量

* 因为我的数学其实学得并不是很好,甚至说非常差,所以在本小节我不会详细推导泊松分布(但会简单推导一下),但我会讲解为什么我们需要泊松分布公式,为什么他可以用在这里

* 简单来说,泊松分布用于计算"某一段时间内可能会发生若干次数的某个随机事件的概率",换句话说,就是计算"在这个时间段内,发生多少次这个事件的概率大概是多少"
* 他是怎样做到的?
* 因为事件在这个时间内会发生多次,所以事件不是独立的
* 所以我们可以通过把时间分片,以实现某个时间片中要么只发生一次时间,要么不发生,这样事件就是独立的了,然后可以用二项分布求概率,于是我们可以得到一个公式,用于表示在“在`n`个独立的小片中,每个小片事件发生概率为`p`,那么总共发生`k`次的概率是多少”

![[Pasted image 20251004235053.png]]

* 但时间片具体要分多细,这个我们不知道,所以我们最后要求极限,就可以假设时间片无限细的情况下,某一段时间内某随机事件发生的概率了,于是可以得到以下公式用于表示"在趋近于无限个独立的小片中,每个小片事件发生概率为`p`(因为时间片太多了,所以`p`这个概率会无限趋近于`0`),那么总共发生`k`次的概率是多少"
![[Pasted image 20251004235134.png]]
* PS:n->∞,p->0,np=λ

* 难道网络中的所有的包都可以是泊松的吗?
* 不能,因为泊松描述的是"随机",然而从宏观来看,网络中包数量的多少并不是泊松的
* 我们打个比方
* 我们知道有几个著名的时间段,人们会在这个时间段通过网购买特别多的东西,比方说618或者双十一
* 这几个时期是固定的,那么此时购物平台需要收发的数据包的数量将会提升几十甚至上百倍,所有卖家,买家,运营商,银行,购物平台,支付平台的数据包收发都会有风险因此垮掉,所以他们会针对这个时间段,像是应对大BOSS一样需要在短时间内应对如此大的流量
* 难道他们还属于泊松吗,显然是不可能的,这种情况是人为的,一定不属于泊松

* 所以说,从微观来看,比方说在几分钟或者说几秒内,包的传输无限趋近于泊松,但是宏观来看,包的传输很难称得上泊松
